<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ELK+Filebeat+Kafka+ZooKeeper 构建海量日志分析平台【转】]]></title>
    <url>%2F2018%2F09%2F12%2FELK%2BFilebeat%2BKafka%2BZooKeeper%20%E6%9E%84%E5%BB%BA%E6%B5%B7%E9%87%8F%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E3%80%90%E8%BD%AC%E3%80%91%2F</url>
    <content type="text"><![CDATA[ELK+Filebeat+Kafka+ZooKeeper 构建海量日志分析平台 原文链接：http://blog.51cto.com/tchuairen/1861167 什么要做日志分析平台？ 随着业务量的增长，每天业务服务器将会产生上亿条的日志，单个日志文件达几个 GB，这时我们发现用 Linux 自带工具，cat grep awk 分析越来越力不从心了，而且除了服务器日志，还有程序报错日志，分布在不同的服务器，查阅繁琐。 待解决的痛点: 1、大量不同种类的日志成为了运维人员的负担，不方便管理; 2、单个日志文件巨大，无法使用常用的文本工具分析，检索困难; 3、日志分布在多台不同的服务器上，业务一旦出现故障，需要一台台查看日志。 为了解决以上困扰: 接下来我们要一步步构建这个日志分析平台，架构图如下: 架构解读 : （整个架构从左到右，总共分为 5 层） 第一层、数据采集层 最左边的是业务服务器集群，上面安装了 filebeat 做日志采集，同时把采集的日志分别发送给两个 logstash 服务。 第二层、数据处理层，数据缓存层 logstash 服务把接受到的日志经过格式处理，转存到本地的 kafka broker+zookeeper 集群中。 第三层、数据转发层 这个单独的 Logstash 节点会实时去 kafka broker 集群拉数据，转发至 ES DataNode。 第四层、数据持久化存储 ES DataNode 会把收到的数据，写磁盘，建索引库。 第五层、数据检索，数据展示 ES Master + Kibana 主要协调 ES 集群，处理数据检索请求，数据展示。 笔者为了节约宝贵的服务器资源，把一些可拆分的服务合并在同一台主机。大家可以根据自己的实际业务环境自由拆分，延伸架构。 开 工 ! 操作系统环境 : CentOS release 6.5 各服务器角色分配 : jdk-8u101-linux-x64.rpm logstash-2.3.2.tar.gz filebeat-1.2.3-x86_64.rpm kafka_2.11-0.10.0.1.tgz zookeeper-3.4.9.tar.gz elasticsearch-2.3.4.rpm kibana-4.5.3-linux-x64.tar.gz 一、安装部署 Elasticsearch 集群 布置 ES Master 节点 10.10.1.244 1、安装 jdk1.8，elasticsearch-2.3.4oracle 官网 jdk 下载地址: http://www.oracle.com/technetwork/java/javase/downloads/index.html elasticsearch 官网: https://www.elastic.co/ 安装命令 yum install jdk-8u101-linux-x64.rpm elasticsearch-2.3.4.rpm -y ES 会被默认安装在 /usr/share/elasticsearch/ 2、系统调优，JVM 调优# 配置系统最大打开文件描述符数 vim /etc/sysctl.conf fs.file-max=65535 配置进程最大打开文件描述符 vim /etc/security/limits.conf # End of file \* soft nofile 65535 \* hard nofile 65535 # 配置 JVM 内存 vim /etc/sysconfig/elasticsearch ES\_HEAP\_SIZE=4g # 这台机器的可用内存为 8G 3、编写 ES Master 节点配置文件 # /etc/elasticsearch/elasticsearch.yml # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: bigdata # ------------------------------------ Node ------------------------------------ node.name: server1 node.master: true node.data: false # ----------------------------------- Index ------------------------------------ index.number\_of\_shards: 5 index.number\_of\_replicas: 0 index.refresh\_interval: 120s # ----------------------------------- Paths ------------------------------------ path.data: /home/elk/data path.logs: /var/log/elasticsearch/elasticsearch.log # ----------------------------------- Memory ----------------------------------- bootstrap.mlockall: true indices.fielddata.cache.size: 50mb #------------------------------------ Network And HTTP -------------------------- network.host: 0.0.0.0 http.port: 9200 # ------------------------------------ Translog ---------------------------------- index.translog.flush\_threshold\_ops: 50000 # --------------------------------- Discovery ------------------------------------ discovery.zen.minimum\_master\_nodes: 1 discovery.zen.ping.timeout: 200s discovery.zen.fd.ping\_timeout: 200s discovery.zen.fd.ping.interval: 30s discovery.zen.fd.ping.retries: 6 discovery.zen.ping.unicast.hosts: [&amp;quot;10.10.1.60:9300&amp;quot;,&amp;quot;10.10.1.90:9300&amp;quot;,&amp;quot;10.10.1.244:9300&amp;quot;,] discovery.zen.ping.multicast.enabled: false # --------------------------------- merge ------------------------------------------ indices.store.throttle.max\_bytes\_per\_sec: 100mb 注: path.data、path.logs 这两个参数指定的路径，如果没有需要自己创建，还要赋予权限给 elasticsearch 用户。（后面的 ES DataNode 也同样） 4、安装 head、kopf、bigdesk 开源插件 安装方法有两种 : 1、使用 ES 自带的命令 plugin# head /usr/share/elasticsearch/bin/plugin install mobz/elasticsearch-head # kopf /usr/share/elasticsearch/bin/plugin install lmenezes/elasticsearch-kopf # bigdesk /usr/share/elasticsearch/bin/plugin install hlstudio/bigdesk 2、自行下载插件的源码包安装 我们通过 plugin 命令安装的插件，其实是安装到了这个路径:/usr/share/elasticsearch/plugins 而 plugin install 命令后面跟的这一串 mobz/elasticsearch-head 其实是 github 上的一个地址。 前面加上 github 的官网地址就是 https://github.com/mobz/elasticsearch-head 可以复制到浏览器中打开，找到该插件的源码仓库。 现在知道了，想要找插件自己可以去 github 上搜一下出来一大堆。随便选一个然后取后面那串路径，用 ES 自带的命令安装。 如果安装失败了，那么就手动下载该插件的源码包。 解压后直接整个目录 mv 到 ES 的插件安装路径下。 也就是这里: /usr/share/elasticsearch/plugins/ 那如何访问安装好的插件呢？ http://ES\_server\_ip:port/\_plugin/plugin\_name Example: http://127.0.0.1:9200/\_plugin/head/ http://127.0.0.1:9200/\_plugin/kopf/ 这时，ES Master 已经配置好了。 布置 ES DataNode 节点 10.10.1.60安装和系统调优方法同上，插件不用安装，只是配置文件不同。 编写配置文件 # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: bigdata # ------------------------------------ Node ------------------------------------ node.name: server2 node.master: false node.data: true # ----------------------------------- Index ------------------------------------ index.number\_of\_shards: 5 index.number\_of\_replicas: 0 index.refresh\_interval: 120s # ----------------------------------- Paths ------------------------------------ path.data: /home/elk/data,/disk2/elk/data2 path.logs: /var/log/elasticsearch/elasticsearch.log # ----------------------------------- Memory ----------------------------------- bootstrap.mlockall: true indices.fielddata.cache.size: 50mb #------------------------------------ Network And HTTP -------------------------- network.host: 0.0.0.0 http.port: 9200 # ------------------------------------ Translog ---------------------------------- index.translog.flush\_threshold\_ops: 50000 # --------------------------------- Discovery ------------------------------------ discovery.zen.minimum\_master\_nodes: 1 discovery.zen.ping.timeout: 200s discovery.zen.fd.ping\_timeout: 200s discovery.zen.fd.ping.interval: 30s discovery.zen.fd.ping.retries: 6 discovery.zen.ping.unicast.hosts: [&amp;quot;10.10.1.244:9300&amp;quot;,] discovery.zen.ping.multicast.enabled: false # --------------------------------- merge ------------------------------------------ indices.store.throttle.max\_bytes\_per\_sec: 100mb 10.10.1.60 也准备好了。 布置另一台 ES DataNode 节点 10.10.1.90 编写配置文件 # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: bigdata # ------------------------------------ Node ------------------------------------ node.name: server3 node.master: false node.data: true # ----------------------------------- Index ------------------------------------ index.number\_of\_shards: 5 index.number\_of\_replicas: 0 index.refresh\_interval: 120s # ----------------------------------- Paths ------------------------------------ path.data: /home/elk/single path.logs: /var/log/elasticsearch/elasticsearch.log # ----------------------------------- Memory ----------------------------------- bootstrap.mlockall: true indices.fielddata.cache.size: 50mb #------------------------------------ Network And HTTP -------------------------- network.host: 0.0.0.0 http.port: 9200 # ------------------------------------ Translog ---------------------------------- index.translog.flush\_threshold\_ops: 50000 # --------------------------------- Discovery ------------------------------------ discovery.zen.minimum\_master\_nodes: 1 discovery.zen.ping.timeout: 200s discovery.zen.fd.ping\_timeout: 200s discovery.zen.fd.ping.interval: 30s discovery.zen.fd.ping.retries: 6 discovery.zen.ping.unicast.hosts: [&amp;quot;10.10.1.244:9300&amp;quot;,] discovery.zen.ping.multicast.enabled: false # --------------------------------- merge ------------------------------------------ indices.store.throttle.max\_bytes\_per\_sec: 100mb 5、现在三台 ES 节点已经准备就绪，分别启动服务# 10.10.1.244 /etc/init.d/elasticsearch start # 10.10.1.60 /etc/init.d/elasticsearch start # 10.10.1.90 /etc/init.d/elasticsearch start 6、访问 head 插件，查看集群状态 此时 Elasticsearch 集群已经准备完成 二、配置位于架构图中第二层的 ZooKeeper 集群 配置 10.10.1.30 节点 1、安装，配置 zookeeper zookeeper 官网: http://zookeeper.apache.org/ # zookeeper 依赖 java，如果之前没安装过 JDK，则需要安装. rpm -ivh jdk-8u101-linux-x64.rpm # 解压程序 tar xf zookeeper-3.4.9.tar.gz 编写配置文件 # conf/zoo.cfg # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=/u01/zookeeper/zookeeper-3.4.9/data # the port at which the clients will connect clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 server.11=10.10.1.30:2888:3888 server.12=10.10.1.31:2888:3888 server.13=10.10.1.32:2888:3888 # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc\_maintenance # # The number of snapshots to retain in dataDir # autopurge.snapRetainCount=3 # Purge task interval in hours # Set to &amp;quot;0&amp;quot; to disable auto purge feature # autopurge.purgeInterval=1 同步配置文件到其他两台节点 注: zookeeper 集群，每个节点的配置文件都是一样的。所以直接同步过去，不需要做任何修改。 不熟悉 zookeeper 的朋友，可以参考这里: http://tchuairen.blog.51cto.com/3848118/1859494 scp zoo.cfg 10.10.1.31:/usr/local/zookeeper-3.4.9/conf/ scp zoo.cfg 10.10.1.32:/usr/local/zookeeper-3.4.9/conf/ 2、创建 myid 文件 # 10.10.1.30 echo 11 \&amp;gt;/usr/local/zookeeper-3.4.9/data/myid # 10.10.1.31 echo 12 \&amp;gt;/usr/local/zookeeper-3.4.9/data/myid # 10.10.1.32 echo 13 \&amp;gt;/usr/local/zookeeper-3.4.9/data/myid 3、启动服务 &amp; 查看节点状态 # 10.10.1.30 bin/zkServer.sh start bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg Mode: leader # 10.10.1.31 bin/zkServer.sh start bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg Mode: follower # 10.10.1.32 bin/zkServer.sh start bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg Mode: follower 此时 zookeeper 集群配置完成 三、配置位于架构图中第二层的 Kafka Broker 集群Kafka 官网: http://kafka.apache.org/ 不熟悉 Kafka 的朋友可以参考: http://tchuairen.blog.51cto.com/3848118/1855090 配置 10.10.1.30 节点 1、安装，配置 kafka # 解压程序 tar xf kafka\_2.11-0.10.0.1.tgz 编写配置文件 ############################# Server Basics ############################# broker.id=1 ############################# Socket Server Settings ############################# num.network.threads=3 # The number of threads doing disk I/O num.io.threads=8 # The send buffer (SO\_SNDBUF) used by the socket server socket.send.buffer.bytes=102400 # The receive buffer (SO\_RCVBUF) used by the socket server socket.receive.buffer.bytes=102400 # The maximum size of a request that the socket server will accept (protection against OOM) socket.request.max.bytes=104857600 ############################# Log Basics ############################# log.dirs=/usr/local/kafka/kafka\_2.11-0.10.0.1/data num.partitions=6 num.recovery.threads.per.data.dir=1 ############################# Log Flush Policy ############################# # The number of messages to accept before forcing a flush of data to disk #log.flush.interval.messages=10000 # The maximum amount of time a message can sit in a log before we force a flush #log.flush.interval.ms=1000 ############################# Log Retention Policy ############################# log.retention.hours=60 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 ############################# Zookeeper ############################# zookeeper.connect=10.10.1.30:2181,10.10.1.31:2181,10.10.1.32:2181 zookeeper.connection.timeout.ms=6000 注: 其他两个节点的配置文件也基本相同，只有一个参数需要修改 broker.id 。 它用于唯一标识节点，所以绝对不能相同，不然会节点冲突。 同步配置文件到其他两台节点 scp server.properties 10.10.1.31:/usr/local/kafka/kafka\_2.11-0.10.0.1/config/ scp server.properties 10.10.1.32:/usr/local/kafka/kafka\_2.11-0.10.0.1/config/ # 修改 broker.id # 10.10.1.31 broker.id=2 # 10.10.1.32 broker.id=3 2、配置主机名对应 IP 的解析 vim /etc/hosts 10.10.1.30 server1 10.10.1.31 server2 10.10.1.32 server3 # 记得同步到其他两台节点 3、启动服务 bin/kafka-server-start.sh config/server.properties # 其他两台节点启动方式相同 Kafka+ZooKeeper 集群配置完成 四、配置位于架构图中第二层的 Logstash 服务 配置 10.10.1.30 节点 1、安装，配置 logstash # 解压程序 tar xf logstash-2.3.2.tar.gz 配置 GeoLiteCity ， 用于地图显示 IP 访问的城市 官网地址: http://dev.maxmind.com/geoip/legacy/geolite/ 下载地址: http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz 解压 gunzip GeoLiteCity.dat.gz 编写配置文件 input { beats { port =\&amp;gt; 5044 codec =\&amp;gt;&amp;quot;json&amp;quot; } } filter {if[type]==&amp;quot;nginxacclog&amp;quot;{ geoip { source=\&amp;gt;&amp;quot;clientip&amp;quot;# 与日志中访问地址的 key 要对应 target =\&amp;gt;&amp;quot;geoip&amp;quot; database =\&amp;gt;&amp;quot;/usr/local/logstash/GeoLiteCity.dat&amp;quot; add\_field =\&amp;gt;[&amp;quot;[geoip][coordinates]&amp;quot;,&amp;quot;%{[geoip][longitude]}&amp;quot;] add\_field =\&amp;gt;[&amp;quot;[geoip][coordinates]&amp;quot;,&amp;quot;%{[geoip][latitude]}&amp;quot;] } mutate {convert =\&amp;gt;[&amp;quot;[geoip][coordinates]&amp;quot;,&amp;quot;float&amp;quot;] } } } output { kafka { workers =\&amp;gt; 2 bootstrap\_servers =\&amp;gt;&amp;quot;10.10.1.30:9092,10.10.1.31:9092,10.10.1.32:9092&amp;quot; topic\_id =\&amp;gt;&amp;quot;peiyinlog&amp;quot; } } 2、启动服务 /usr/local/logstash/bin/logstash agent -f logstash\_in\_kafka.conf &amp;amp; 10.10.1.31 节点的这块配置，与上述完全相同。（略） 位于第二层、数据处理层的 Logstash 配置完成 五、配置数据采集层，业务服务器 +Filebeat1、定制 Nginx 日志格式 log\_format json &amp;#39;{&amp;quot;@timestamp&amp;quot;:&amp;quot;$time\_iso8601&amp;quot;,&amp;#39; &amp;#39;&amp;quot;slbip&amp;quot;:&amp;quot;$remote\_addr&amp;quot;,&amp;#39; &amp;#39;&amp;quot;clientip&amp;quot;:&amp;quot;$http\_x\_forwarded\_for&amp;quot;,&amp;#39; &amp;#39;&amp;quot;serverip&amp;quot;:&amp;quot;$server\_addr&amp;quot;,&amp;#39; &amp;#39;&amp;quot;size&amp;quot;:$body\_bytes\_sent,&amp;#39; &amp;#39;&amp;quot;responsetime&amp;quot;:$request\_time,&amp;#39; &amp;#39;&amp;quot;domain&amp;quot;:&amp;quot;$host&amp;quot;,&amp;#39; &amp;#39;&amp;quot;method&amp;quot;:&amp;quot;$request\_method&amp;quot;,&amp;#39; &amp;#39;&amp;quot;requesturi&amp;quot;:&amp;quot;$request\_uri&amp;quot;,&amp;#39; &amp;#39;&amp;quot;url&amp;quot;:&amp;quot;$uri&amp;quot;,&amp;#39; &amp;#39;&amp;quot;appversion&amp;quot;:&amp;quot;$HTTP\_APP\_VERSION&amp;quot;,&amp;#39; &amp;#39;&amp;quot;referer&amp;quot;:&amp;quot;$http\_referer&amp;quot;,&amp;#39; &amp;#39;&amp;quot;agent&amp;quot;:&amp;quot;$http\_user\_agent&amp;quot;,&amp;#39; &amp;#39;&amp;quot;status&amp;quot;:&amp;quot;$status&amp;quot;,&amp;#39; &amp;#39;&amp;quot;devicecode&amp;quot;:&amp;quot;$HTTP\_HA&amp;quot;}&amp;#39;; # 在虚拟主机配置中调用 access\_log /alidata/log/nginx/access/access.log json; 2、安装 Filebeat Filebeat 也是 Elasticsearch 公司的产品，在官网可以下载。 # rpm 包安装 yum install filebeat-1.2.3-x86\_64.rpm -y 3、编写 Filebeat 配置文件 ################### Filebeat Configuration Example ######################### ############################# Filebeat ###################################### filebeat: prospectors: - paths: - /var/log/messages input\_type: log document\_type: messages - paths: - /alidata/log/nginx/access/access.log input\_type: log document\_type: nginxacclog - paths: - /alidata/www/logs/laravel.log input\_type: log document\_type: larlog - paths: - /alidata/www/logs/500\_error.log input\_type: log document\_type: peiyinlar\_500error - paths: - /alidata/www/logs/deposit.log input\_type: log document\_type: lar\_deposit - paths: - /alidata/www/logs/call\_error.log input\_type: log document\_type: call\_error - paths: - /alidata/log/php/php-fpm.log.slow input\_type: log document\_type: phpslowlog multiline: pattern: &amp;#39;^[[:space:]]&amp;#39; negate: true match: after registry\_file: /var/lib/filebeat/registry ############################# Output ########################################## output: logstash: hosts: [&amp;quot;10.26.95.215:5044&amp;quot;] ############################# Shipper ######################################### shipper: name: &amp;quot;host\_6&amp;quot; ############################# Logging ######################################### logging: files: rotateeverybytes: 10485760 # = 10MB 4、启动服务 /etc/init.d/filebeat start 数据采集层，Filebeat 配置完成。 现在业务服务器上的日志数据已经在源源不断的写入缓存了。 六、配置位于架构图中的第三层，数据转发层Logstash 安装上面已经讲过（略） 编写 Logstash 配置文件 # kafka\_to\_es.conf input{ kafka { zk\_connect =\&amp;gt;&amp;quot;10.10.1.30:2181,10.10.1.31:2181,10.10.1.32:2181&amp;quot; group\_id =\&amp;gt;&amp;quot;logstash&amp;quot; topic\_id =\&amp;gt;&amp;quot;peiyinlog&amp;quot; reset\_beginning =\&amp;gt;false consumer\_threads =\&amp;gt; 50 decorate\_events =\&amp;gt;true } } # 删除一些不需要的字段 filter {if[type]==&amp;quot;nginxacclog&amp;quot;{ mutate {remove\_field =\&amp;gt;[&amp;quot;slbip&amp;quot;,&amp;quot;kafka&amp;quot;,&amp;quot;domain&amp;quot;,&amp;quot;serverip&amp;quot;,&amp;quot;url&amp;quot;,&amp;quot;@version&amp;quot;,&amp;quot;offset&amp;quot;,&amp;quot;input\_type&amp;quot;,&amp;quot;count&amp;quot;,&amp;quot;source&amp;quot;,&amp;quot;fields&amp;quot;,&amp;quot;beat.hostname&amp;quot;,&amp;quot;host&amp;quot;,&amp;quot;tags&amp;quot;] } } } output {if[type]==&amp;quot;nginxacclog&amp;quot;{# stdout {codec =\&amp;gt; rubydebug} elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-nginxacclog-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 50000 idle\_flush\_time =\&amp;gt; 10 workers =\&amp;gt; 2 } } if[type]==&amp;quot;messages&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-messages-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 50000 idle\_flush\_time =\&amp;gt; 30 workers =\&amp;gt; 1 } } if[type]==&amp;quot;larlog&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-larlog-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 2000 idle\_flush\_time =\&amp;gt; 10 } } if[type]==&amp;quot;deposit&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-deposit-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 2000 idle\_flush\_time =\&amp;gt; 10 } } if[type]==&amp;quot;phpslowlog&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-phpslowlog-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 2000 idle\_flush\_time =\&amp;gt; 10 } } } 启动服务 /usr/local/logstash/bin/logstash agent -f kafka\_to\_es.conf &amp;amp; 数据转发层已经配置完成 这时数据已经陆陆续续的从 kafka 取出，转存到 ES DataNode。 我们登陆到任意一台 kafka 主机，查看数据的缓存和消费情况 七、修改 ES 的索引模版配置 为什么要做这一步呢？ 因为 logstash 写入数据到 ES 时，会自动选用一个索引模版。 我们可以看一下 这个模版其实也挺好，不过有一个参数，我标记出来了。 &quot;refresh_interval&quot;:&quot;5s&quot; 这个参数用于控制，索引的刷新频率。 索引的刷新频率越快，你搜索到的数据就实时。 这里是 5 秒。 一般我们日志场景不需要这么高的实时性。 可以适当降低该参数，提高 ES 索引库的写入速度。 上传自定义模版 curl -XPUT http://10.10.1.244:9200/\_template/logstash2 -d &amp;#39; { &amp;quot;order&amp;quot;:1, &amp;quot;template&amp;quot;:&amp;quot;logstash-\*&amp;quot;, &amp;quot;settings&amp;quot;:{ &amp;quot;index&amp;quot;:{&amp;quot;refresh\_interval&amp;quot;:&amp;quot;120s&amp;quot;} }, &amp;quot;mappings&amp;quot;:{ &amp;quot;\_default\_&amp;quot;:{ &amp;quot;\_all&amp;quot;:{&amp;quot;enabled&amp;quot;:false} } } }&amp;#39; 由于这个自定义模版，我把优先级 order 定义的比 logstash 模版高，而模版的匹配规则又一样，所以这个自定义模版的配置会覆盖原 logstash 模版。 我这里只是简单描述。 如果要详细理解其中道理，请查看我的 ES 调优篇。 八、配置 Kibana 数据展示层10.10.1.244 节点 Kibana 是 ELK 套件中的一员，也属于 elasticsearch 公司，在官网提供下载。 安装tar xf kibana-4.5.3-linux-x64.tar.gz # 很简单，只要解压就可以用。 修改配置文件 # vim kibana-4.5.3-linux-x64/config/kibana.yml # Kibana is served by a back end server. This controls which port to use. server.port: 5601 # The host to bind the server to. server.host: &amp;quot;0.0.0.0&amp;quot; # The Elasticsearch instance to use for all your queries. elasticsearch.url: &amp;quot; # 修改这三个参数就好了 启动服务 打开浏览器访问: http://10.10.1.244:5601/ 定制 Elasticsearch 索引的 Index pattern 默认情况下，Kibana 认为你要访问的是通过 Logstash 导入 Elasticsearch 的数据，这时候你可以用默认的 logstash-* 作为你的 index pattern。 通配符（*）匹配索引名中任意字符任意个数。 选择一个包含了时间戳的索引字段（字段类型为 date 的字段），可以用来做基于时间的处理。Kibana 会读取索引的 映射，然后列出所有包含了时间戳的字段。如果你的索引没有基于时间的数据. 关闭 Index contains time-based events 参数。 如果一个新索引是定期生成，而且索引名中带有时间戳，选择 Use event times to create index names 选项， 然后再选择 Index pattern interval 。这可以提高搜索性能，Kibana 会至搜索你指定的时间范围内的索引。在你用 Logstash 输出数据给 Elasticsearch 的情况下尤其有效。 由于我们的索引是用日期命名，按照每天分割的。 index pattern 如下 数据展示 完 工 !]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 私库 Nexus3 搭建使用]]></title>
    <url>%2F2018%2F06%2F20%2FMaven%E7%A7%81%E5%BA%93Nexus3%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Maven 私库 nexus3 搭建使用docker 安装 sonatype/nexus31. 创建挂载目录 mkdir -p v-nexus/data 并修改目录权限 chown -R 200 v-nexus/data 2. 创建部署脚本 # 默认用户名 admin/admin123 version: &apos;3.2&apos; services: nexus: restart: always image: sonatype/nexus3 ports: #自定义端口 - target: 8081 published: 18081 #只有 worker 能访问该端口 protocol: tcp mode: host #版本要求 3.2 volumes: - &quot;/dockerdata/v-nexus/data:/nexus-data&quot; deploy: replicas: 1 restart_policy: condition: on-failure placement: constraints: [node.hostname == lfadmin] 3. 测试访问http://192.168.1.213:18081/ 然后输入 admin 和 admin123 进行登陆即可 ##win10 下 maven 安装 1. 下载 apache-maven-3.5.4-bin.zip 然后解压 2. 添加环境变量, 新建系统环境变量 Maven_HOME 值为解压路径，编辑 path 环境变量添加 %Maven_HOME%\bin 3. 命令窗口测试 mvn -v，只支持 cmd 4. 修改 apache-maven-3.5.4\conf\settings.xml 文件 &lt;!--jar 本地缓存地址 --&gt; &lt;localRepository&gt;D:\MavenRepository&lt;/localRepository&gt; 完整的 setting.xml 设置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;!-- jar 本地缓存地址 --&gt; &lt;localRepository&gt;D:\MavenRepository&lt;/localRepository&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;servers&gt; &lt;!-- 配置权限, 使用默认用户 --&gt; &lt;server&gt; &lt;!-- 这里的 id 要和项目里的 pom.xml 的 id 一致 --&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;MyNexus&lt;/id&gt; &lt;activation&gt; &lt;jdk&gt;1.4&lt;/jdk&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;!-- 私有库地址 --&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;&gt;Nexus3 Repository&lt;/name&gt; &lt;!-- 注意修改成对应的 IP, 在 nexus 里面复制 public 里面的地址 --&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;!-- snapshots 默认是关闭的，需要手动开启 --&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!-- 插件库地址 --&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 激活 profile--&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;MyNexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;/settings&gt; 6. 在项目的 pom.xml 修改或添加如下配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project ...&gt; .... &lt;!-- 配置 maven 地址 --&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;!-- 这里的 id 要和 maven 里的的 settings.xml 的 id 一致 --&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; ... &lt;/project&gt; 7. 编译在 cmd 执行 mvn install 发布上传 jar 执行 mvn deploy，可以到 nexus 地址进行检查 8. 使用私库下载和上传是一样的 nexus3 配置阿里云代理仓库1. 点击Create Repository-&gt;maven2(proxy) 2. 添加名字 aliyun-proxy 设置阿里云 url 地址http://maven.aliyun.com/nexus/content/groups/public 3. 设置阿里云优先级，在 maven-public 里面的 group 把刚刚创建的添加过去并移到 maven-central 上面 4. 设置允许发布 release, 在 maven-release 的 hosted 里面选择 allow redeploy 发布上传 jar 包到 nexus语法： mvn deploy:deploy-file \ -DgroupId=&lt;group-id&gt; \ -DartifactId=&lt;artifact-id&gt; \ -Dversion=&lt;version&gt; \ -Dpackaging=&lt;type-of-packaging&gt; \ -Dfile=&lt;path-to-file&gt; \ -DrepositoryId=&lt; 这里的 id 要和 maven 里的的 settings.xml 的 id 一致 &gt; \ -Durl=&lt;url-of-the-repository-to-deploy&gt; 实战 mvn deploy:deploy-file \ -Dfile=spring-boot-starter-druid-0.0.1-SNAPSHOT.jar \ -DgroupId=cn.binux \ -DartifactId=spring-boot-starter-druid \ -Dversion=0.0.1-SNAPSHOT \ -Dpackaging=jar \ -DpomFile=spring-boot-starter-druid-0.0.1-SNAPSHOT.pom \ -DrepositoryId=nexus-snapshots \ -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ 上传 jar 包到私有 maven 仓库 mvn deploy:deploy-file -Dfile=spring-boot-starter-druid-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-druid -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar -DpomFile=spring-boot-starter-druid-0.0.1-SNAPSHOT.pom -DrepositoryId=nexus-snapshots -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ mvn deploy:deploy-file -Dfile=spring-boot-starter-dubbox-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-dubbox -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar -DpomFile=spring-boot-starter-dubbox-0.0.1-SNAPSHOT.pom -DrepositoryId=nexus-snapshots -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ mvn deploy:deploy-file -Dfile=spring-boot-starter-redis-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-redis -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar -DpomFile=spring-boot-starter-redis-0.0.1-SNAPSHOT.pom -DrepositoryId=nexus-snapshots -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ #这个不是 snapshots 要发布到 releases，注意设置 nexus 为允许发布，看 jar 报后缀，没有 `SNAPSHOT` 就是 release mvn deploy:deploy-file -Dfile=dubbo-2.8.4.jar -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4 -Dpackaging=jar -DrepositoryId=nexus-releases -Durl=http://192.168.1.213:18081/repository/maven-releases/ mvn deploy:deploy-file -Dfile=fastdfs-1.24.jar -DgroupId=org.csource -DartifactId=fastdfs -Dversion=1.24 -Dpackaging=jar -DrepositoryId=nexus-releases -Durl=http://192.168.1.213:18081/repository/maven-releases/ mvn deploy:deploy-file -Dfile=examples-1.0.jar -DgroupId=com.haikang -DartifactId=examples -Dversion=1.0 -Dpackaging=jar -DrepositoryId=nexus-releases -Durl=http://192.168.1.230:18081/repository/maven-releases/ 本地安装 jar 包到本地 maven 仓库 mvn install:install-file -Dfile=spring-boot-starter-druid-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-druid -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar mvn install:install-file -Dfile=spring-boot-starter-dubbox-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-dubbox -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar mvn install:install-file -Dfile=spring-boot-starter-redis-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-redis -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar mvn install:install-file -Dfile=dubbo-2.8.4.jar -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4 -Dpackaging=jar mvn install:install-file -Dfile=fastdfs-1.24.jar -DgroupId=org.csource -DartifactId=fastdfs -Dversion=1.24 -Dpackaging=jar 问题 下载了找不到包，解决，删除项目重新导入，重新 maven 依赖 刚上传或添加了新的 jar 到私库，无法下载，解决，删除本地仓库的该包目录]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 3 爬取百度经验数据]]></title>
    <url>%2F2018%2F05%2F24%2FPython%203%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%BB%8F%E9%AA%8C%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[安装环境准备 直接使用 win10 的 wsl 沙盒 Ubuntu 系统，自带 python3.5 安装 apt install python3-pip pip3 install rsa 注意事项IndentationError: unexpected indent 检查缩进是否一致，空格和 Tab 符号注意区分 ## 实战 通过 cookie 爬百度数据1. 登陆百度，通过浏览器设置 - 内容管理 -cookie，找到百度的 BDUSS 的内容复制 2. 编写脚本 login.py import requests #需要爬数据的 url url = &apos;http://i.baidu.com/&apos; #浏览器访问网站的 cookie 信息 cookie = {&quot;BDUSS&quot;:&quot;----------------------------------------------------AAAAAAAAAAA----------------AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA--&quot;} #requests 请求，获取登录网站页面的内容 html = requests.get(url,cookies=cookie).content #print(html) #把内容保存为文件 with open(&quot;baidu.html&quot;, &apos;wb&apos;) as f: f.write(html) f.close() 3. 在 Ubuntu bash 执行 python3 login.py，会生成一个文件 baidu.html 在当前目录, 打开如果能看到个人信息就证明获取成功 爬百度翻页数据 上面已经登陆成功了，下面直接用 cookie 进行爬数据会被重定向，还需要添加请求头，以及翻页参数 import requests #需要爬数据的 url url = &apos;https://jingyan.baidu.com/user/nucpage/content&apos; #浏览器访问网站的 cookie 信息 cookie = {&quot;BDUSS&quot;:&quot;-----QAAAAAAAAAAAEAAA--1QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA---&quot;} #提供你所使用的浏览器类型、操作系统及版本、CPU 类型、浏览器渲染引擎、浏览器语言、浏览器插件等信息的标识 user_agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot; # 从那个连接来的 referer=&quot;https://jingyan.baidu.com/user/nucpage/content&quot; # 设置请求头 headers = { &quot;User-Agent&quot;: user_agent, &quot;Referer&quot;: referer } # url 参数 # https://jingyan.baidu.com/user/nucpage/content?tab=exp&amp;expType=published&amp;pn=20 params = { &apos;tab&apos;: &apos;exp&apos;, &apos;expType&apos;: &apos;published&apos;, &apos;pn&apos;: &apos;30&apos; } #requests 请求，获取登录网站页面的内容 html = requests.get(url,cookies=cookie,headers=headers).content #print(html) #把内容保存为文件 with open(&quot;baidu.html&quot;, &apos;wb&apos;) as f: f.write(html) f.close() 最终版爬百度经验的个人经验数据import requests #正则 import re #需要爬数据的 url url = &apos;https://jingyan.baidu.com/user/nucpage/content&apos; #浏览器访问网站的 cookie 信息 cookie = {&quot;BDUSS&quot;:&quot;--AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA-&quot;} #提供你所使用的浏览器类型、操作系统及版本、CPU 类型、浏览器渲染引擎、浏览器语言、浏览器插件等信息的标识 user_agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot; # 从那个连接来的 referer=&quot;https://jingyan.baidu.com/user/nucpage/content&quot; # 设置请求头 headers = { &quot;User-Agent&quot;: user_agent, &quot;Referer&quot;: referer } #requests 请求, 获取发布数量 published = requests.get(url,cookies=cookie,headers=headers).content #&lt;li&gt;&lt;a class=&quot;on&quot; href=&quot;/user/nucpage/content&quot;&gt; 已发布 (505)&lt;/a&gt;&lt;/li&gt; reg=r&apos;&lt;li&gt;&lt;a class=&quot;on&quot; href=&quot;/user/nucpage/content&quot;&gt; 已发布 \((.*?)\)&lt;/a&gt;&lt;/li&gt;&apos; publishedNum=re.search(reg,published.decode(),re.I|re.M|re.S).group(1) #group(0) 匹配的串，group(1) 匹配的串中第一个括号 print(publishedNum) #算页数, 实际篇数 -1 pages=int((int(publishedNum)-1)/20)+1 print(pages) #把内容保存为文件,&apos;w&apos; 是写，&apos;wb&apos; 是写入 byte with open(&quot;jingyan.md&quot;, &apos;w&apos;) as f: for page in range(0,pages): pn=page*20 print(pn) # url 参数 # https://jingyan.baidu.com/user/nucpage/content?tab=exp&amp;expType=published&amp;pn=20 params = { &apos;tab&apos;: &apos;exp&apos;, &apos;expType&apos;: &apos;published&apos;, &apos;pn&apos;: pn } #requests 请求，获取登录网站页面的内容 html = requests.get(url,cookies=cookie,headers=headers,params=params).content #过滤 reg=r&apos;&lt;a class=&quot;f14&quot; target=&quot;_blank&quot; title=(.*?)&gt;&apos; #re.I 使匹配对大小写不敏感 #re.M 多行匹配，影响 ^ 和 $ #re.S 使 . 匹配包括换行在内的所有字符 #这个是查找此字符串中所有符合条件的内容并返回一个列表 list=re.findall(reg,html.decode(),re.I|re.M|re.S) #写入文件并替换为 markdown 格式 for item in list: item=item.replace(&apos;&quot; href=&quot;&apos;,&apos;](https://jingyan.baidu.com&apos;) item=item.replace(&apos;.html&quot;&apos;,&apos;.html)&apos;) item=item.replace(&apos;&quot;&apos;,&apos;[&apos;) f.write(&quot;%s\n&quot; % item) f.close() 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考： Python：网页的抓取、过滤和保存]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-JVM 参数详解]]></title>
    <url>%2F2018%2F04%2F10%2FJava-JVM%2F</url>
    <content type="text"><![CDATA[JVM 基本参数 -Xmx: 运行最大内存（memory maximum） 是指设定程序运行期间最大可占用的内存大小。如果程序运行需要占用更多的内存，超出了这个设置值，就会抛出 OutOfMemory 异常。堆的最大内存数，等同于 -XX:MaxHeapSize -Xms：启动内存(memory startup) 是指设定程序启动时占用内存大小。一般来讲，大点，程序会启动的快一点，但是也可能会导致机器暂时间变慢。堆的初始化初始化大小 -Xmn：(memory nursery/new) 堆中新生代初始及最大大小，如果需要进一步细化，初始化大小用 -XX:NewSize，最大大小用 -XX:MaxNewSize -Xss：(stack size) 线程栈大小，等同于 -XX:ThreadStackSize jvm 设置的值查看 执行 ps -ef | grep tomcat 或ps -ef | grep java输出如下 root 1882 1 0 8 月 02 ? 01:39:42 /root/SoftwareInstall/jdk/bin/java -Djava.util.logging.config.file=/usr/local/tomcat-geoserver/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms3072M -Xmx3072M -Xmn512M -Xss512k -XX:+AggressiveOpts - ..... org.apache.catalina.startup.Bootstrap start 如果没有设置，默认是不会有 -Xms3072M -Xmx3072M -Xmn512M -Xss512k 值打印 docker-compose 设置 jvmenvironment: - JAVA_OPTS= &apos;-Xmx3072m&apos; JVM 问题总结 geoserver 添加图层预览时提示java.lang.OutOfMemoryError: GC overhead limit exceeded 该错误 解决把 -Xmx 设置更大]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZABBIX 忘记登录密码【转】]]></title>
    <url>%2F2017%2F07%2F29%2FZABBIX%20%E5%BF%98%E8%AE%B0%E7%99%BB%E5%BD%95%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[摘要 有些童鞋会忘记 zabbix 的登陆密码，今天给大家写一篇找回登陆密码~ 做运维由于账号比较多，脑子容易瓦特. 结果忘记自己的 zabbix 登录密码下面是找回登录密码的例子 未修改之前 (忘记登录密码) [root@abcdocker ~]# mysql -uroot -p -e &quot;select * from zabbix.users\G&quot; Enter password: *************************** 1. row *************************** userid: 1 alias: Admin name: Zabbix surname: Administrator passwd: ab66b6e18854fa4d45499d0a04a47b64 url: autologin: 1 autologout: 0 lang: en_GB refresh: 30 type: 3 theme: default attempt_failed: 0 attempt_ip: 14.130.112.2 attempt_clock: 1501141026 rows_per_page: 50 登录 MySQL 修改密码 [root@abcdocker ~]# mysql -uroot -p 由于密码是 md5 加密的，我们可以查看默认的 zabbix 密码的 md5 mysql&gt; use zabbix; mysql&gt; update users set passwd=&apos;5fce1b3e34b520afeffb37ce08c7cd66&apos; where userid=&apos;1&apos;; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 解释：5fce1b3e34b520afeffb37ce08c7cd66 = zabbix 因为 zabbix 默认密码就是 zabbix 登录 Web 用户名：Admin 密码：zabbix 提示 ：登陆上请马上修改密码 完！ 转自：ZABBIX 忘记登录密码]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZABBIX 3.2 监控服务器 TCP 连接状态【转】]]></title>
    <url>%2F2017%2F07%2F29%2FZABBIX%203.2%20%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1%E5%99%A8TCP%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[ZABBIX 3.2 监控服务器 TCP 连接状态TCP 11 种状态图 (我也记不住所有的) TCP 连接可以使用命令获取 [root@abcdocker ~]# netstat -an|awk &apos;/^tcp/{++S[$NF]}END{for(a in S) print a,S[a]}&apos; TIME_WAIT 99 CLOSE_WAIT 44 FIN_WAIT1 1 FIN_WAIT2 5 ESTABLISHED 275 LAST_ACK 1 LISTEN 25 可以使用 man netstat 查看 TCP 的各种状态信息描述 LISTEN - 侦听来自远方 TCP 端口的连接请求； SYN-SENT - 在发送连接请求后等待匹配的连接请求； SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； FIN-WAIT-1 - 等待远程 TCP 的连接中断请求，或先前的连接中断请求的确认； FIN-WAIT-2 - 从远程 TCP 等待连接中断请求； CLOSE-WAIT - 等待从本地用户发来的连接中断请求； CLOSING - 等待远程 TCP 对连接中断的确认； LAST-ACK - 等待原来发向远程 TCP 的连接中断请求的确认； TIME-WAIT - 等待足够的时间以确保远程 TCP 接收到连接中断请求的确认； CLOSED - 没有任何连接状态； 一、编写配置文件[root@abcdocker zabbix]# grep &quot;Include&quot; zabbix_agentd.conf Include=/etc/zabbix/zabbix_agentd.d/*.conf 我们查看我们设置的 Include 目录，这下面的 *.conf 文件都是可以读取的 编写配置文件 [root@abcdocker zabbix_agentd.d]# cat status.conf UserParameter=tcp.status[*],/etc/zabbix/zabbix_agentd.d/tcp_status.sh &quot;$1&quot; 咳咳，注意听讲(敲黑板) UserParameter= 后面是 key 的名称 /etc/zabbix/zabbix_agentd.d 存放脚本的路径 以前的文章有写过，大家可以看我的 zabbix 板块 复制脚本 [root@abcdocker zabbix_agentd.d]# cat tcp_status.sh #!/bin/bash #this script is used to get tcp and udp connetion status #tcp status metric=$1 tmp_file=/tmp/tcp_status.txt /bin/netstat -an|awk &apos;/^tcp/{++S[$NF]}END{for(a in S) print a,S[a]}&apos; &gt; $tmp_file case $metric in closed) output=$(awk &apos;/CLOSED/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; listen) output=$(awk &apos;/LISTEN/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; synrecv) output=$(awk &apos;/SYN_RECV/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; synsent) output=$(awk &apos;/SYN_SENT/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; established) output=$(awk &apos;/ESTABLISHED/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; timewait) output=$(awk &apos;/TIME_WAIT/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; closing) output=$(awk &apos;/CLOSING/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; closewait) output=$(awk &apos;/CLOSE_WAIT/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; lastack) output=$(awk &apos;/LAST_ACK/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; finwait1) output=$(awk &apos;/FIN_WAIT1/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; finwait2) output=$(awk &apos;/FIN_WAIT2/{print $2}&apos; $tmp_file) if [&quot;$output&quot; == &quot;&quot;];then echo 0 else echo $output fi ;; *) echo -e &quot;\e[033mUsage: sh $0 [closed|closing|closewait|synrecv|synsent|finwait1|finwait2|listen|established|lastack|timewait]\e[0m&quot; esac 提示： 脚本来源于网络 因为脚本是把 tcp 的一些信息存放在 /tmp/ 下，为了 zabbix 可以读取到我们设置 zabbix 可以读的权限 [root@abcdocker zabbix_agentd.d]# chmod +x tcp_connection_status.sh [root@abcdocker zabbix_agentd.d]# chown zabbix.zabbix /tmp/tcp_status.txt 重点： 这里要添加执行权限和 tcp_status 的 属主 和属组 执行脚本测试 既然脚本写完了，我们就需要执行一下 [root@abcdocker zabbix_agentd.d]# zabbix_get -s 127.0.0.1 -k tcp.status[established] 8 [root@abcdocker zabbix_agentd.d]# zabbix_get -s 127.0.0.1 -k tcp.status[lastack] 0 [root@abcdocker zabbix_agentd.d]# zabbix_get -s 127.0.0.1 -k tcp.status[finwait1] 0 [root@abcdocker zabbix_agentd.d]# zabbix_get -s 127.0.0.1 -k tcp.status[timewait] 101 如果没有 zabbix_get 需要 yum 安装 二、WEB 界面配置1. 创建模板 2. 设置模板 3. 添加监控项 添加完基本上就是下面这样 为了方便大家添加，我已经将 name 和 key 整理如下. 手动添加即可 Name Key CLOSED tcp.status[closed] CLOSE_WAIT tcp.status[closewait] CLOSING tcp.status[closing] ESTABLISHED tcp.status[established] FIN WAIT1 tcp.status[finwait1] FIN WAIT2 tcp.status[finwait2] LAST ACKtcp.status[lastack] LISTEN tcp.status[listen] SYN RECVtcp.status[synrecv] SYN SENTtcp.status[synsent] TIME WAIT tcp.status[timewait] 我这里提供模板：链接：http://pan.baidu.com/s/1sle6oNj 密码：oqgs可以直接使用模板导入即可 4. 添加图表 我们所有的操作都在 TCP 模板下面添加和设置的，大家不要设置错了 添加完之后我们点击update 三、添加主机 进行查看 四、出图结果 小结： 因为 tcp 连接数不太好设置触发器，因为业务不同，具体设置多少还是要根据需求来。因为我这是个人博客监控所以连接数是多少都可以！ 关于 tcp 最大连接可以参考下面的文章http://www.cnblogs.com/fjping0606/p/4729389.html 关于 ZABBIX 更多相关文章请前往 ZABBIX 板块 参考 http://john88wang.blog.51cto.com/2165294/1586234/ 转自：ZABBIX 3.2 监控服务器 TCP 连接状态]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins 自动化部署上线【转】]]></title>
    <url>%2F2017%2F03%2F23%2FJenkins%20%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[摘要 jenkins 自动化部署项目, 通过 jenkins 部署来节省运维时间, 不需要手动 cp 上线及版本发布 一、Jenkins 是什么 Jenkins 是一款自包含的开源自动化服务, 可用于自动执行与构建, 测试和交付或部署软件有关的各种任务。 Jenkins 目前可以通过本地系统软件包 Docker 进行安装, 甚至可以通过任何安装了 Java 运行环境的计算机独立运行 二、上线流程图 既然我们说到自动化上线, 我们就不得不说说一个项目上线的流程. 只有规范起来才可以做到不出事故！ 上线流程图如下图所示 三、Jenkins 安装配置 Jenkins 依赖 Java 环境, 我们需要安装 Java 环境以及相关的环境准备 ### 关闭防火墙 $ iptables -F $ iptables -X $ systemctl stop firewalld $ systemctl disable firewalld ### 安装 yum 源 $ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo $ wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo $ yum clean all &amp;&amp; yum makecache 1. 下载 Jdk 包 下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 上传 jdk 包到服务器 ### 解压拷贝 jdk $ tar xf jdk-8u171-linux-x64.tar.gz -C /usr/local/ $ ln -s /usr/local/jdk1.8.0_171/ /usr/local/jdk $ ln -s /usr/local/jdk/bin/java /usr/bin/java ### 设置环境变量 $ vim /etc/profile export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$JAVA_HOME/bin:$PATH $ source /etc/profile 2. 安装 Jenkins$ wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo $ rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key $ yum install jenkins -y $ systemctl start jenkins ## 如果我们启动 Jenkins 出现错误可以直接使用 systemctl status jenkins 查看错误 jenkins 相关目录释义： (1)/usr/lib/jenkins/：jenkins 安装目录，war 包会放在这里。 (2)/etc/sysconfig/jenkins：jenkins 配置文件，“端口”，“JENKINS_HOME”等都可以在这里配置。 (3)/var/lib/jenkins/：默认的 JENKINS_HOME。 (4)/var/log/jenkins/jenkins.log：jenkins 日志文件。 检查端口是否存在 3. 配置 Jenkins Jenkins 有安全策略, 我们按照提示拷贝验证码即可 将验证码复制到 Web 框里 我们这里使用推荐就可以了，因为后期我们都可以在安装 安装插件中，有的插件会因为网络问题无法安装成功 我们这里可以创建一个管理员，或者直接使用 admin 我们最好不要直接使用admin 安装完成访问地址：iP:8080 到这里我们 Jenkins 已经安装成功, 剩下的就是配置插件和配置环境 因为我们目前什么都没有需要安装插件, 点击下步安装插件 为了模拟环境我们需要安装 Jenkins 一些相关插件 下面 2 个 maven 插件都需要勾选 插件名称:maven lntergration 我们勾选安装重启 安装完成后如下图所示 默认是没有下面的 maven 项目的 4.Jenkins 配置项目 配置 SVN 地址 因为我是新建的 Jenkins 目录, 没有权限, 所以需要创建一个用于认证. 填写 SVN 地址，因为我这里的 svn 已经链接到 ldap, 所以不需要输入 svn 的密码, 默认这里是 svn 的用户和密码 具体文章可以参考 VisualSVN 迁移至 Linux SVN+Apache+ssl 集成 LDAP 认证成功之后 了解 maven 配置 首先我们的 svn 分支下面需要有 pom.xml 继续往下 ↓↓↓↓ 因为我们只安装 maven 的插件，并没有安装 maven 服务，所以这里需要我们配置 我们就在这里添加一个名字，maven 就自动安装了 Maven 安装完成了，需要依赖吧都是从 maven.apache.org 下载会比较慢，所以我们指定私服的地址, 因为在实际生产中也都是使用私服的。 在 maven 的配置文件里面也需要配置 配置文件 conf/settings.xml 因为我们所使用的是 Jenkins 的自动安装，而不是指定路径所以我们要查到这个配置文件 maven 自动安装的配置路径 配置 Maven 仓库地址 这里配置的都是私服地址 相关文章 Jenkins+Maven+SVN+Nexus 搭建持续集成环境 配置 Maven 镜像地址 配置 Maven 编译参数 [研发都会] 相关文章：maven 编译命令 这个 pom.xml 里面配置是私服的地址 因为代码里面有很多东西是需要拉去依赖包，这些依赖包就存放在本地的私有仓库里(Nexus) 代码中 pom.xml 配置如下 私有仓库的地址 5. 构建测试 控制台输出说明 6.Jenkins 工程目录 可以通过修改 Jenkins 主目录 Jenkins 打包好后的目录，这个 war 包就是我们需要拷贝的 tomcat 下面的 四、Jenkins 自动化部署项目案例 因为目前环境原因，我这里只是截图 Jenkins 发布的流程(本次演示只是针对测试环境日常发布版本) (1) Java 环境演示 [Jenkins 和 Tomcat 在一台服务器上]1.Jenkins 配置 SVN 部分配置 maven 及脚本设置 2. 不发脚本配置如下： 相关参考：Jenkins 可用环境变量列表 脚本的存放路径可以在 系统管理 -&gt; 全局配置 -&gt;Jenkins 路径 Last login: Thu Jun 28 18:01:59 2018 from 172.16.29.39 [root@tomcat ~]# cat /jenkins/deploy.sh #!/bin/bash # # Jenkins 工程构建通用 TOMCAT 部署脚本 # @author abcdocker # @create_time 2017-08-19 # # 在 Jenkins 内配置部署单元参数 # 参数格式：MAVEN_MODULE_NAME:TOMCAT_ABSOLUTE_PATH MAVEN 模块名称: 需要部署的目标 TOMCAT 绝对路径 # 只有单个部署单元且没有 Maven 子模块时，模块名称参数可以没有，参数格式为：TOMCAT_ABSOLUTE_PATH # # 注意： # 在本部署脚本内会执行 TOMCAT 启动脚本，为避免 Jenkins 在构建成功以后杀掉所有衍生的后台进程，需要在 Jenkins 内配置全局环境变量 BUILD_ID 值为 allow_to_run_as_daemon # # DEPLOY_TARGET_TOMCAT=$TOMCAT #校验部署参数，不能为空 if [-z &quot;$DEPLOY_TARGET_TOMCAT&quot;] then echo echo 部署参数为空，部署失败！ echo &quot;#####################################################################&quot; echo echo 单个部署单元参数格式： echo MAVEN_MODULE_NAME:TOMCAT_ABSOLUTE_PATH MAVEN 模块名称: 需要部署的目标 TOMCAT 绝对路径 echo echo 多个部署单元参数格式：（多个部署单元使用空格分割） echo MAVEN_MODULE_NAME:TOMCAT_ABSOLUTE_PATH MAVEN_MODULE_NAME:TOMCAT_ABSOLUTE_PATH echo echo &quot;#####################################################################&quot; exit 1 fi echo echo 部署参数：${DEPLOY_TARGET_TOMCAT} TOMCAT_ARR=${DEPLOY_TARGET_TOMCAT//;/} ARR=($TOMCAT_ARR) ARR_LEN=${#ARR[*]} echo 共 ${ARR_LEN} 个部署单元 i=1 #获取 Jenkins 传入的目标 TOMCAT 组 for T in $TOMCAT_ARR do echo echo 开始 处理第 ${i} 个部署单元 echo 第一个部署单元：$T #获取目标 TOMCAT 的 WAR 路径和 TOMCATA 的绝对路径 TOMCAT_PARAM=(${T//:/}) MODULE_NAME=${TOMCAT_PARAM[0]} TARGET_TOMCAT_PATH=${TOMCAT_PARAM[1]} WAR_PATH=&quot;$WORKSPACE/$MODULE_NAME/target/*.war&quot; echo 部署单元模块名称：&quot;${MODULE_NAME}&quot; echo 部署 WAR 包路径：&quot;${WAR_PATH}&quot; echo 部署 TOMCAT 路径：&quot;${TARGET_TOMCAT_PATH}&quot; #需要考虑 MAVEN 单模块下的部署问题 #if [&quot;${#ARR[*]}&quot; -eq 1 -a -z &quot;$TARGET_TOMCAT_PATH&quot; ] if [&quot;$ARR_LEN&quot; -eq 1 -a -z &quot;$TARGET_TOMCAT_PATH&quot;] then #MAVEN 过程没有子模块，单个部署单元 TARGET_TOMCAT_PATH=$MODULE_NAME MODULE_NAME=&quot;NULL&quot; fi #校验参数，WORKSPACE 变量来自于 Jenkins 环境变量 if [-z &quot;$MODULE_NAME&quot; -o ! -f $WAR_PATH] then echo 错误：MAVEN 部署模块名称 参数为空 或 找不到 WAR 包！ echo 部署失败！ exit 1 fi if [-z &quot;$TARGET_TOMCAT_PATH&quot; -o ! -d &quot;$TARGET_TOMCAT_PATH&quot;] then echo 错误：目标 TOMCAT 绝对路径 参数为空 或 该 TOMCAT 目录不存在！ echo 部署失败！ exit 1 fi echo 开始清理目标 TOMCAT 启动进程... TOMCAT_PID=`ps -ef |grep &quot;$TARGET_TOMCAT_PATH&quot; |grep &quot;start&quot; |awk &apos;{print $2}&apos;` if [-n &quot;$TOMCAT_PID&quot;] then echo TOMCAT_${i}，PID${TOMCAT_PID}，正在结束该进程... kill -9 $TOMCAT_PID &amp;&amp; echo PID${TOMCAT_PID} 已被干掉！ else echo TOMCAT_${i} 进程未启动！ fi echo 开始清理目标 TOMCAT 缓存... rm -rf $TARGET_TOMCAT_PATH/webapps/* rm -rf $TARGET_TOMCAT_PATH/logs/* rm -rf $TARGET_TOMCAT_PATH/work/* echo 开始部署 WAR 包... cp -a $WAR_PATH $TARGET_TOMCAT_PATH/webapps/ROOT.war &amp;&amp; echo WAR 包部署完毕。 echo 开始启动目标 TOMCAT 服务... sleep 10 /bin/bash $TARGET_TOMCAT_PATH/bin/startup.sh echo 开始配置 web 目录的 FTP 权限... #启动过程会自动解压 WAR 包，所以在这里需要等待 WAR 包解压完成再调整目录权限 sleep 30 chown -R vftpuser.vftpuser ${TARGET_TOMCAT_PATH}/webapps/ &amp;&amp; echo 目录权限配置完毕。 echo 部署成功 echo 完成 第 ${i} 个部署单元处理。 echo ((i++)) done 3. 构建效果如下图所示： (2) Java 环境演示 [Jenkins 和 Tomcat 不在一台服务器上]上面的脚本是针对 Jenkins 和 Tomcat 都在相同的目录, 有的时候我们测试环境会存在不在一台服务器的情况, 脚本如下 只是脚本简单的修改 [root@tomcat ~]# cat /jenkins/ysc.sh #!/bin/bash # # Jenkins 工程构建通用 TOMCAT 部署脚本 # @author 刘曙 # @create_time 2017-08-19 # # 在 Jenkins 内配置部署单元参数 # 参数格式：MAVEN_MODULE_NAME:TOMCAT_ABSOLUTE_PATH MAVEN 模块名称: 需要部署的目标 TOMCAT 绝对路径 # 只有单个部署单元且没有 Maven 子模块时，模块名称参数可以没有，参数格式为：TOMCAT_ABSOLUTE_PATH # # 注意： # 在本部署脚本内会执行 TOMCAT 启动脚本，为避免 Jenkins 在构建成功以后杀掉所有衍生的后台进程，需要在 Jenkins 内配置全局环境变量 BUILD_ID 值为 allow_to_run_as_daemon # # DEPLOY_TARGET_TOMCAT=$YSC HOST=root@172.16.1.35 #校验部署参数，不能为空 if [-z &quot;$DEPLOY_TARGET_TOMCAT&quot;] then echo echo 部署参数为空，部署失败！ echo &quot;#####################################################################&quot; exit 1 fi echo echo 部署参数：${DEPLOY_TARGET_TOMCAT} TOMCAT_ARR=${DEPLOY_TARGET_TOMCAT//;/} ARR=($TOMCAT_ARR) ARR_LEN=${#ARR[*]} echo 共 ${ARR_LEN} 个部署单元 i=1 #获取 Jenkins 传入的目标 TOMCAT 组 for T in $TOMCAT_ARR do echo echo 开始 处理第 ${i} 个部署单元 echo 第一个部署单元：$T #获取目标 TOMCAT 的 WAR 路径和 TOMCATA 的绝对路径 TOMCAT_PARAM=(${T//:/}) MODULE_NAME=${TOMCAT_PARAM[0]} TARGET_TOMCAT_PATH=${TOMCAT_PARAM[1]} #WAR_PATH=&quot;/jenkins/workspace/ysc-all/${MODULE_NAME}/target/*.war&quot; WAR_PATH=&quot;${WORKSPACE}/${MODULE_NAME}/target/*.war&quot; echo 部署单元模块名称：&quot;${MODULE_NAME}&quot; echo 部署 WAR 包路径：&quot;${WAR_PATH}&quot; echo 部署 TOMCAT 路径：&quot;${TARGET_TOMCAT_PATH}&quot; #判断 IP 是否有相关目录 ssh 172.16.1.35 &quot;[-d $TARGET_TOMCAT_PATH]&quot; &gt;/dev/null 2&gt;&amp;1 if [$? != 0];then echo 错误 else echo 正确 fi #校验参数，WORKSPACE 变量来自于 Jenkins 环境变量 if [-z &quot;$MODULE_NAME&quot; -o ! -f $WAR_PATH] then echo 错误：MAVEN 部署模块名称 参数为空 或 找不到 WAR 包！ echo 部署失败！ exit 1 fi #scp 软件包 ssh $HOST /etc/init.d/${MODULE_NAME} stop ssh 172.16.1.35 &quot;[-d $TARGET_TOMCAT_PATH/webapps/ROOT/]&quot; &gt;/dev/null 2&gt;&amp;1 if [$? = 0];then ssh 172.16.1.35 rm -rf $TARGET_TOMCAT_PATH/webapps/ROOT if [$? = 0];then scp $WAR_PATH root@172.16.1.35:$TARGET_TOMCAT_PATH/webapps/ROOT.war &amp;&amp; echo WAR 包部署完毕。 echo $TARGET_TOMCAT_PATH is OK else echo 删除 $TARGET_TOMCAT_PATH is error fi else echo &quot;not found $TARGET_TOMCAT_PATH/webapps/ROOT&quot; scp $WAR_PATH root@172.16.1.35:$TARGET_TOMCAT_PATH/webapps/ROOT.war &amp;&amp; echo WAR 包部署完毕。 ssh $HOST /etc/init.d/${MODULE_NAME} restart fi #################### 启动文件 done #scp /home/config.properties/ysc/${MODULE_NAME}.js root@172.16.1.35:$TARGET_TOMCAT_PATH/webapps/ROOT/web/js/basePath.js ssh $HOST /etc/init.d/${MODULE_NAME} restart Jenkins 配置如下修改 修改完成后我们构建演示 提示：这种环境下配置文件都是通过 maven build 进行控制，也就是通过研发控制配置文件 + (3) Java 环境演示 [上线脚本]线上环境演示 我们的上线流程如下： Jenkins 配置如下： 1. 首先测试环境脚本： [root@tomcat ~]# cat /server/scripts/.upgrade-smscenter.sh #!/bin/bash WAR=”/jenkins/workspace/portal-smscenter/bxg-sms-center-web/target/*.war” Path=”/data/hub/bxg-smscenter/date +%Y%m%d/“ scp_war(){ if [! -d $Path];then ssh root@file-server mkdir -p $Path scp $WAR root@file-server:$Path else scp $WAR root@file-server:$Path fi } ssh_file(){ ssh root@file-server &quot;/bin/bash /server/script/bxg/bxg-smscenter.sh&quot; } scp_war ssh_file 2. 跳板机脚本修改 [root@File-server1 ~]# cat /server/script/bxg/bxg-smscenter.sh #!/bin/bash HOST=online-server2 WAR=&quot;/data/hub/bxg-smscenter/`date +%Y%m%d`&quot; DIR=&quot;/application/smscenter/webapps/ROOT/&quot; function scp_file {if `ssh root@$HOST &quot;[ ! -d $WAR]&quot;`;then ssh root@$HOST &quot;mkdir -p $WAR&quot; fi scp $WAR/*.war root@$HOST:$WAR/ echo &quot;scp $WAR/*.war root@$HOST:$WAR/&quot; } ssh_deploy(){ssh root@$HOST &quot;/bin/bash /server/scripts/deploy_smscenter.sh&quot;} scp_file ssh_deploy 3.web 服务器脚本 [root@online-server2 ~]# cat /server/scripts/deploy_smscenter.sh #!/bin/bash WAR=&quot;/data/hub/bxg-smscenter/`date +%Y%m%d`&quot; OBJECT=&quot;/application/smscenter/webapps/ROOT/&quot; Backup=&quot;/data/tomcat/bxg-smscenter-`date +%Y%m%d`&quot; SCR_D=&quot;/application/smscenter/webapps/ROOT&quot; #config=&quot;/data/bak&quot; backup_tar(){ tar zcvf $Backup.tar.gz $SCR_D/ echo &quot; 为了防止意外 cp 整个项目目录存放 &quot; cp -a $SCR_D/ $Backup rm -rf $OBJECT/* } cp_war(){unzip $WAR/*.war -d $SCR_D/} cp_config(){ cat $Backup/WEB-INF/classes/application-prod.properties &gt;$SCR_D/WEB-INF/classes/application-prod.properties /etc/init.d/smscenter restart } backup_tar cp_war cp_config [root@online-server2 ~]# 相关文章 企业必会技能 tomcat + (4) NodeJs 环境演示 [上线脚本]node 环境上线流程Jenkins 配置如下 [node 项目不适用 maven, 所以可以不用创建 maven 项目, 直接在 Jenkins 创建普通项目就可以] 1. 测试环境脚本 [root@tomcat ~]# cat /server/scripts/mobile/mobile.sh #!/bin/bash source /etc/profile HOST=file-server BASE_DIR=/server/scripts/mobile/m url=$1 server=$2 DATE=`date +%Y%m%d` tar(){ rm -rf $BASE_DIR [-d $BASE_DIR] || mkdir $BASE_DIR cd $BASE_DIR echo &quot;##########################################################&quot; echo &quot; 代码拉取中！！！&quot; svn co -q $url/ . echo &quot;##########################################################&quot; } cp(){cd ${BASE_DIR} /bin/tar -zcvf m_${DATE}.tar.gz ./* echo &quot;##########################################################&quot; echo &quot; 文件已经打包完成！ 正在拷贝中！！！&quot; echo &quot;##########################################################&quot; sleep 5 scp m_${DATE}.tar.gz root@$HOST:/data/hub/bxg-mobile/ echo &quot;##########################################################&quot; echo &quot; 文件已经拷贝完成！ 正在上传服务器中！！！&quot; echo &quot;##########################################################&quot; ssh root@file-server &quot;/bin/bash /server/script/bxg/bxg-mobile.sh $server&quot; } tar cp [root@tomcat ~]# 2. 跳板机脚本 [root@File-server1 ~]# cat /server/script/bxg/bxg-mobile.sh #!/bin/bash HOST=$1 Mobile_tar=&quot;/data/hub/bxg-mobile&quot; DIR=&quot;/application/node&quot; DATE=`date +%Y%m%d` scp_file(){if `ssh root@$HOST &quot;[ ! -d $Mobile_tar]&quot;`;then ssh root@$HOST &quot;mkdir -p $Mobile_tar&quot; fi scp $Mobile_tar/m_${DATE}.tar.gz root@$HOST:$DIR/ sleep 3 echo &quot; &quot; echo &quot;##########################################################&quot; echo &quot;File-server 正在拷贝 ${HOST}！！！&quot; sleep 3 echo &quot;##########################################################&quot; } ssh_deploy(){ echo &quot;Hi&quot; ssh root@$HOST &quot;/bin/bash /server/scripts/bxg/bxg-mobile.sh&quot; } scp_file ssh_deploy 3.web 发布脚本 [root@iZbp11tefvghtcfn5mudgdZ ~]# cat /server/scripts/bxg/bxg-mobile.sh #!/bin/bash source /etc/profile DIR=&quot;/application/node&quot; DATE=`date +%Y%m%d` Backup=&quot;/application/node/m/&quot; BAK=&quot;/data/hub/bxg-mobile&quot; backup_tar(){ echo &quot; 为了防止意外 cp 整个项目目录存放 &quot; cp -ar $Backup ${BAK}/mobile_$DATE echo &quot;online-server 原目录拷贝备份完成！&quot; } cp_war(){ /etc/init.d/mobile stop #mv $Backup /tmp/m_${DATE} &amp;&amp; rm -rf /tmp/m_${DATE} rm -rf $Backup mkdir $Backup &amp;&amp; cd /application/node/ tar xf m_${DATE}.tar.gz -C $Backup } npm_config(){ cd $Backup cnpm install npm run build-prod npm run start-prod &amp;&gt;/var/log/mobile_${DATE}.log &amp; } C(){ echo &quot;++++++++++++++++++++++++++++++++++++++++++++++++++++&quot; curl -I 127.0.0.1:3000 echo &quot;###################################################&quot; echo &quot; 若是 200 服务启动正常！ 可以启动另一台！&quot; echo &quot;###################################################&quot; } backup_tar cp_war npm_config C 相关文章 Node.js 环境搭建 总结：Jenkins 自动化不是运维一个人就可以完成的, 需要研发的参与, 本文只是给大家展示一下我公司的自动化, 我眼里所谓的自动化. 希望大家不喜勿喷, 对文章有意见或建议请在评论留言哦~ 转自：Jenkins 自动化部署上线]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins+Maven+SVN+Nexus 搭建持续集成环境【转】]]></title>
    <url>%2F2017%2F03%2F22%2FJenkins%2BMaven%2BSVN%2BNexus%20%E6%90%AD%E5%BB%BA%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[摘要 Jenkins 只是一个平台，真正运作的都是插件。这就是 jenkins 流行的原因，因为 jenkins 什么插件都有。Hudson 是 Jenkins 的前身，是基于 Java 开发的一种持续集成工具，用于监控程序重复的工作，Hudson 后来被收购，成为商业版。后来创始人又写了一个 jenkins，jenkins 在功能上远远超过 hudson 一、DevOps DevOps 是“开发”和“运维”的缩写。 DevOps 是一组最佳实践强调 (IT 研发、运维、测试) 在应用和服务生命周期中的协作和沟通，强调整个组织的合作以及交付和基础设施变更的自动化，从而实现持续集成、持续部署和持续交付 DevOps 平台四大模块1. 项目管理 (创建项目—&gt;&gt; 项目需求)2. 运维平台 (监控–日志收集—等)3. 持续交付 (提交完代码—&gt; 自动打包—&gt; 构建)4. 代码托管 (gitlab—-&gt; 代码提交)————————————————————&gt;&gt;DevOps 平台 针对 DevOps 开源项目1. 项目管理—(JIRA 非开源但是用的人比较多)、(Redmine 使用 ruby 写的)2. 代码托管—(SVN–usvn 有 web 管理界面)、(GitLab)3. 持续交付—(主流 Jenkins)、(GitLab gitlab-ci 也可以做交付)4. 运维平台—(国内的开源运维平台可能就是腾讯蓝鲸) 二、服务介绍 很多事情不是光运维就可以决定的，还需要跟研发交流，我这里只是演示一个大概的持续交付的流程~ 2.1 Jenkins 介绍 Jenkins 只是一个平台，真正运作的都是插件。这就是 jenkins 流行的原因，因为 jenkins 什么插件都有 Hudson 是 Jenkins 的前身，是基于 Java 开发的一种持续集成工具，用于监控程序重复的工作，Hudson 后来被收购，成为商业版。后来创始人又写了一个 jenkins，jenkins 在功能上远远超过 hudson 2.2 Maven 介绍 maven 的用途maven 是一个项目构建和管理的工具，提供了帮助 管理 构建、文档、报告、依赖、scms、发布、分发 的方法。可以方便的编译代码、进行依赖管理、管理二进制库等等。maven 的好处在于可以将项目过程规范化、自动化、高效化以及强大的可扩展性 利用 maven 自身及其插件还可以获得代码检查报告、单元测试覆盖率、实现持续集成等等。 maven 的核心概念介绍 Pom pom 是指 project object Model。pom 是一个 xml，在 maven2 里为 pom.xml。是 maven 工作的基础，在执行 task 或者 goal 时，maven 会去项目根目录下读取 pom.xml 获得需要的配置信息 pom 文件中包含了项目的信息和 maven build 项目所需的配置 Artifact 这个有点不好解释，大致说就是一个项目将要产生的文件，可以是 jar 文件，源文件，二进制文件，war 文件，甚至是 pom 文件。每个 artifact 都由 groupId:artifactId:version 组成的标识符唯一识别。需要被使用 (依赖) 的 artifact 都要放在仓库 (见 Repository) 中 Repositories Repositories 是用来存储 Artifact 的。如果说我们的项目产生的 Artifact 是一个个小工具，那么 Repositories 就是一个仓库，里面有我们自己创建的工具，也可以储存别人造的工具，我们在项目中需要使用某种工具时，在 pom 中声明 dependency，编译代码时就会根据 dependency 去下载工具（Artifact），供自己使用。 Build Lifecycle 是指一个项目 build 的过程。maven 的 BuildLifecycle 分为三种，分别为 default（处理项目的部署）、clean（处理项目的清理）、site（处理项目的文档生成）。他们都包含不同的 lifecycle。Build Lifecycle 是由 phases 构成的 …. 参考：关于 Maven 常用参数及说明 2.3 SVN 介绍SVN 是近年来崛起的非常优秀的版本管理工具，与 CVS 管理工具一样，SVN 是一个固态的跨平台的开源的版本控制系统。SVN 版本管理工具管理者随时间改变的各种数据。这些数据放置在一个中央资料档案库 repository 中，这个档案库很像一个普通的文件服务器或者 FTP 服务器，但是，与其他服务器不同的是，SVN 会备份并记录每个文件每一次的修改更新变动。这样我们就可以把任意一个时间点的档案恢复到想要的某一个旧的版本，当然也可以直接浏览指定的更新历史记录。 本站相关文章 SVN 服务实战应用指南 VisualSVN 迁移至 Linux SVN+Apache+ssl 集成 LDAP 2.4 Nexus 介绍maven 的仓库只有两大类：1. 本地仓库 2. 远程仓库，在远程仓库中又分成了 3 种： 1 中央仓库 2 私服 3 其它公共库。 私服是一种特殊的远程仓库，它是架设在局域网内的仓库服务，私服代理广域网上的远程仓库，供局域网内的 Maven 用户使用。当 Maven 需要下载构件的时候，它从私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，缓存在私服上之后，再为 Maven 的下载请求提供服务。我们还可以把一些无法从外部仓库下载到的构件上传到私服上。 Maven 私服的 个特性： 1. 节省自己的外网带宽：减少重复请求造成的外网带宽消耗 2. 加速 Maven 构件：如果项目配置了很多外部远程仓库的时候，构建速度就会大大降低 3. 部署第三方构件：有些构件无法从外部仓库获得的时候，我们可以把这些构件部署到内部仓库 (私服) 中，供内部 maven 项目使用 4. 提高稳定性，增强控制：Internet 不稳定的时候，maven 构建也会变的不稳定，一些私服软件还提供了其他的功能 5. 降低中央仓库的负荷：maven 中央仓库被请求的数量是巨大的，配置私服也可以大大降低中央仓库的压力 因此我们在实际的项目中通常使用私服来间接访问中央仓库，项目通常不直接访问中央仓库 三、环境搭建 首先最新版本 2.97 只支持 java1.8，我们需要将 jdk 版本设置为 1.8 tomcat 的版本最好也是 8.0.x 版本，如果使用 8.5 可能会有问题 系统我们使用 Centos7 3.1 配置 jdk 环境$ wget http://download.oracle.com/otn-pub/java/jdk/8u144-b01/090f390dda5b47b9b721c7dfaa008135/jdk-8u144-linux-x64.tar.gz $ tar zxf jdk-8u91-linux-x64.tar.gz -C /usr/local/ $ ln –s /usr/local/jdk1.8.0_91 /usr/local/jdk $ vim /etc/profile export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$JAVA_HOME/bin:$PATH 检查 $ java -version java version &quot;1.8.0_151&quot; Java(TM) SE Runtime Environment (build 1.8.0_151-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode) 3.2 安装 Jenkins提示：首先 Jenkins 安装方式有 2 中，一种是 yum 安装，另一种是使用 war 的方式进行安装（war 就需要安装 tomcat） 官方文档：https://pkg.jenkins.io/redhat/ 如果我们想使用 war 包的方式可以直接下载 war 包 这里我们可以参考本站以前文章 持续集成之 Jenkins+Gitlab 简介 [一] 下载 tomcat （tomcat 和 jdk 版本最好相同） $ wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.0.48/bin/apache-tomcat-8.0.48.tar.gz $ tar xf apache-tomcat-8.0.48.tar.gz –C /application/ $ mv /application/apache-tomcat-8.0.48 /application/jenkins $ rm –rf /application/jenkins/webapps/* &amp;&amp; mkdir –p /application/jenkins/webapps/ROOT 下载 war 包 $ wget http://mirrors.jenkins.io/war/latest/jenkins.war $ cp jenkins.war /application/jenkins/webapps/ROOT/ $unzip /application/jenkins/webapps/ROOT/jenkins.war 我们直接执行 bin/startup.sh 启动就可以 启动我们可以查看 tomcat 日志 Jenkins 访问地址：localhost:8080 关于 tomcat 安装参数及配置修改可以参考本站 企业必会技能 tomcat 新版本的 jenkins 为了保证安全，在安装之后有一个锁，需要设置密码之后才可以解锁 我们选择推荐安装即可 安装插件中 设置管理员账号密码 登陆 jenkins 3.2 安装 maven 环境$ wget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz $ tar xf apache-maven-3.5.2-src.tar.gz $ mv apache-maven-3.5.2 /usr/local/ $ ln -s /usr/local/apache-maven-3.5.2/ /usr/local/maven $ vim /etc/profile export M2_HOME=/usr/local/maven export PATH=${M2_HOME}/bin:$PATH $source /etc/profile 验证 $ mvn -v Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T03:58:13-04:00) Maven home: /usr/local/maven Java version: 1.8.0_151, vendor: Oracle Corporation Java home: /usr/local/jdk1.8.0_151/jre Default locale: en_US, platform encoding: UTF-8 OS name: &quot;linux&quot;, version: &quot;3.10.0-327.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; 这里我们需要修改 maven 的 settings.xml 设置一些相关配置。这里我们直接访问 https://www.abcdocker.com/abcdocker/2893 3.3 安装私服(Nexus) 下载地址：http://www.sonatype.org/nexus/go/ $ wget https://sonatype-download.global.ssl.fastly.net/nexus/3/nexus-3.7.0-04-unix.tar.gz $ tar xf nexus-3.7.0-04-unix.tar.gz -C /usr/local/ $ ln -s /usr/local/nexus-3.7.0-04/ /usr/local/nexus 设置环境变量 $ vim /etc/profile export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$JAVA_HOME/bin:$PATH export JENKINS_HOME=/jenkins export M2_HOME=/usr/local/maven export PATH=${M2_HOME}/bin:$PATH:/usr/local/nexus/bin $ source /etc/profile 启动脚本 $ nexus WARNING: ************************************************************ WARNING: Detected execution as &quot;root&quot; user. This is NOT recommended! WARNING: ************************************************************ Usage: /usr/local/nexus/bin/nexus {start|stop|run|run-redirect|status|restart|force-reload} $ nexus start WARNING: ************************************************************ WARNING: Detected execution as &quot;root&quot; user. This is NOT recommended! WARNING: ************************************************************ Starting nexus 如果我们想把警告去除，需要在修改用户和环境变量。 访问地址：localhost:8081 端口可以在 /etc/nexus-default.properties 中修改） nexus 登陆界面 3.4 Jenkins 配置 因为我们需要构建 Java 项目，所以需要安装一个 Maven 插件 插件名称 Maven Integration plugin系统管理–&gt; 管理插件 此时我们可以在已安装的插件中找到 配置 Jenkins 全局工具配置 系统管理 --&gt; 全局工具配置 配置我们的 JDK、Maven 地址保存就可以 四、Jenkins 构建项目 4.1 创建 maven 项目 创建 maven 项目，起名称 4.2 设置构建参数 这里是说我们构建的记录保留的天数与个数 SVN 地址以及账户的配置 没有问题就不会报错 这是 maven 的编译参数，如果有问题需要与研发的童鞋商议 添加 Shell 脚本，添加的 shell 脚本可以是命令，也可以是执行一个脚本。 构建演示： 这里是正在下载依赖包，因为我们项目一般在测试环境使用，是很多研发一起使用，所以这里的地址就是我们私服(Nexus 地址) 执行完毕 当我们执行完成之后上面的 shell 脚本可以是将 war 包复制到 tomcat 项目目录里 /jenkins/workspace/maven/bxg-ask-center-web/target–jenkins 主目录—项目目录—- 代码分支—– 以下是我们以前 Jenkins shell 中的配置，比较 low 仅供参考 提示：很多相关的参数不是运维能决定的，需要研发参与 更改 Jenkins 的主目录 https://www.cnblogs.com/zz0412/p/jenkins_jj_07.html 如何用 Maven 创建 web 项目（具体步骤） https://www.cnblogs.com/apache-x/p/5673663.html Maven 私服 Nexus 详解 http://blog.csdn.net/u013516966/article/details/43753143 maven 核心，pom.xml 详解(转) https://www.cnblogs.com/qq78292959/p/3711501.html 转自：Jenkins+Maven+SVN+Nexus 搭建持续集成环境]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成 + 自动化部署 [代码流水线管理及 Jenkins 和 gitlab 集成]【转】]]></title>
    <url>%2F2017%2F03%2F22%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%2B%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%5B%E4%BB%A3%E7%A0%81%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%AE%A1%E7%90%86%E5%8F%8AJenkins%E5%92%8Cgitlab%E9%9B%86%E6%88%90%5D%2F</url>
    <content type="text"><![CDATA[一、代码流水线管理 Pipeline 名词顾名思义就是流水线的意思，因为公司可能会有很多项目。如果使用 jenkins 构建完成后，开发构建项目需要一项一项点击，比较麻烦。所以出现 pipeline 名词。 代码质量检查完毕之后，我们需要将代码部署到测试环境上去，进行自动化测试 新建部署代码项目 点击新建 这里只需要写一下描述 执行 Shell 脚本 温馨提示：执行命令主要涉及的是权限问题，我们要搞明白，jenkins 是以什么权限来执行命令的。那么问题来了，我们现在 192.168.56.11 上，如果在想 192.168.56.12 上执行命令。需要怎么做呢？ 我们做无秘钥有 2 种分案： 1、使用 jenkins 用户将秘钥分发给 192.168.56.12 上 2、使用 root 用户将秘钥分发给 192.168.56.12 上，如果使用 root 用户还要进行 visudo 授权。因为 Web 上默认执行命令的用户是 jenkins 1. 我们使用 root 做密码验证 这里我们的 key 已经做好，如果没做可以直接 ssh-keygen -t ras 来生成秘钥 我们将 192.168.56.11 上的公钥复制到 192.168.56.12 上 [root@linux-node1 ~]# cat .ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQChVQufrGwqP5dkzIU4ZwXCjRuSvMVGN5lJdvL/QFckmlVphWMsQw06VsPhgcI1NDjGbKOh5pbjrylyJUCig5YIJ1xuMOZ2YAK32SceMxnVhEb/G4wNb9VMsGQ/Vs4CxrU1HdATktH9zDAV4Qz81x2POYJW5B5LAvwZ4owqnIpZ7o3ya6xBxEvCIMSVtD17oKrNqAphsg+e68KvRexiNCEbCbRGGq3bKevgiDsWpSGnCYsJC0+cSrUxuzEO3G6AqGI/qR3nOeg91rOsoAP3FpFjBKgb/sXggkwwjmGIqFXJrUG+XmczeF4kG/rUrNbdy84e5RyHoIS3XKnJuRjTxHyD root@linux-node1 [root@linux-node2 ~]# vim .ssh/authorized_keys ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQChVQufrGwqP5dkzIU4ZwXCjRuSvMVGN5lJdvL/QFckmlVphWMsQw06VsPhgcI1NDjGbKOh5pbjrylyJUCig5YIJ1xuMOZ2YAK32SceMxnVhEb/G4wNb9VMsGQ/Vs4CxrU1HdATktH9zDAV4Qz81x2POYJW5B5LAvwZ4owqnIpZ7o3ya6xBxEvCIMSVtD17oKrNqAphsg+e68KvRexiNCEbCbRGGq3bKevgiDsWpSGnCYsJC0+cSrUxuzEO3G6AqGI/qR3nOeg91rOsoAP3FpFjBKgb/sXggkwwjmGIqFXJrUG+XmczeF4kG/rUrNbdy84e5RyHoIS3XKnJuRjTxHyD root@linux-node1 [root@linux-node1 ~]# ssh 192.168.56.12 The authenticity of host &apos;192.168.56.12 (192.168.56.12)&apos; can&apos;t be established. ECDSA key fingerprint is b5:74:8f:f1:03:2d:cb:7d:01:28:30:12:34:9c:35:8c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;192.168.56.12&apos; (ECDSA) to the list of known hosts. Last login: Sat Dec 17 02:14:31 2016 from 192.168.56.1 [root@linux-node2 ~]# ll total 4 -rw-------. 1 root root 1021 Dec 13 05:56 anaconda-ks.cfg #现在 SSH 连接就不需要密码了 授权 jenkins 用户，使用 visudo 或者编辑配置文件 /etc/sudoers [root@linux-node1 ~]# vim /etc/sudoers 92 jenkins ALL=(ALL) NOPASSWD:/usr/bin/ssh #jenkins 授权所有主机，不需要密码执行 ssh。切记不要授权 ALL 我们在 192.168.56.12 上写一个简单 shell 脚本，检测是否可以执行成功。正式环境可以写一个自动化部署的脚本 [root@linux-node2 ~]# echo &quot;echo &quot;hello word&quot;&quot; &gt;demo.sh [root@linux-node2 ~]# chmod +x demo.sh [root@linux-node2 ~]# ll demo.sh -rwxr-xr-x 1 root root 16 Dec 17 02:24 demo.sh jenkins 编写执行脚本 然后我们点击立即构建 成功！ 现在我们要将代码质量管理和测试部署连接起来。 这时候就用到了 git 钩子 我们需要安装 jenkins 插件parameterized 我们选择demo-deploy 再次点击项目设置的时候就会出现Trigger parameterized build on other projects 提示 ：Projects to build 是为构建设置一个项目。例如我们想构建完代码项目后执行测试的，这里就填写测试的就可以。 最后点击保存，点击构建。我们查看效果 这样我们每次点击 demo-deploy 它就会在构建完成之后在对auto-deploy 进行构建 下载 pipeline。这样只需要构建一个项目，就会帮我们完成所有相关项目 搜索插件 pipeline 等待安装完成 我们点击首页 + 号，新建一个试图 点击 OK pipeline 配置 然后我们点击保存 pipeline 视图如下： 点击 Run 这样就先代码质量进行管理，然后就开始部署了 构建成功后： 这样我们下次想看 pipeline 视图的时候，点击上面的 demo-pipeline 即可 二、Jenkins + gitlab 集成 Jenkins + gitlab 集成后，实现的功能是 开发写好代码提交至 gitlab 上，当时开始 push 到 gitlab 上之后，jenkins 自动帮我们立即构建 这个项目我们需要安装一个 gitlab 钩子 的脚本 提示： jenkins 不论想实现什么功能，都需要安装插件！！ 安装完插件之后我们就开始配置钩子脚本 这里需要我们在服务器里面写一个令牌，在 jenkins 上也写一个令牌。这两个可以连接到一起就可以。 # 因为用到了令牌我们还需要在安装一个插件，否则将无法使用。因为令牌是需要登录之后才会有，所以需要有一个管理的插件 插件搜索：Build Aut 为了令牌的安全性，我们使用 openssl 生成一个 [root@linux-node1 ~]# openssl rand -hex 10 0a37c6d7ba1fe3472e26 然后我们点击保存即可 因为 jenkins 上也提示我们需要在 gitlab 上添加钩子脚本 点击我们创建的项目 选中 Webhooks Build Authorization Token Root Plugin 插件使用说明https://wiki.jenkins-ci.org/display/JENKINS/Build+Token+Root+Plugin 使用 Build 插件后，url 如下： http://192.168.56.11:8080/buildByToken/build?job=auto-deploy&amp;token=0a37c6d7ba1fe3472e26 auto-deploy= 项目名称(构建时的项目名称) 0a37c6d7ba1fe3472e26=jenkins 填写的令牌 然后点击Add Webhook 下方就会出现我们这个选项，我们点击 Test 进行测试 测试结果 向 git 服务器提交代码，验证是否可以自动部署： [root@linux-node1 ~]# echo &quot;Build Token Root Plugin&quot; &gt; index.html [root@linux-node1 ~]# git add index.html [root@saltmaster ~/weather]# git commit -m &quot;text&quot; [root@linux-node1 ~]# git push origin master jenkins 服务器的日志记录： [root@linux-node1 ~]# tail -f /var/log/jenkins/jenkins.log jenkins 项目构建： 访问 web 界面验证代码是否最新的：jenkins 控制台输出信息： 转自：持续集成 + 自动化部署[代码流水线管理及 Jenkins 和 gitlab 集成]]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成之代码质量管理 -Sonar [三]【转】]]></title>
    <url>%2F2017%2F03%2F21%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B9%8B%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F%E7%AE%A1%E7%90%86-Sonar%20%5B%E4%B8%89%5D%2F</url>
    <content type="text"><![CDATA[摘要 Sonar 是一个用于代码质量管理的开放平台。通过插件机制，Sonar 可以集成不同的测试工具，代码分析工具，以及持续集成工具。与持续集成工具（例如 Hudson/Jenkins 等）不同，Sonar 并不是简单地把不同的代码检查工具结果（例如 FindBugs，PMD 等）直接显示在 Web 页面上，而是通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。 Sonar 介绍 Sonar 是一个用于代码质量管理的开放平台。通过插件机制，Sonar 可以集成不同的测试工具，代码分析工具，以及持续集成工具。与持续集成工具（例如 Hudson/Jenkins 等）不同，Sonar 并不是简单地把不同的代码检查工具结果（例如 FindBugs，PMD 等）直接显示在 Web 页面上，而是通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。 在对其他工具的支持方面，Sonar 不仅提供了对 IDE 的支持，可以在 Eclipse 和 IntelliJ IDEA 这些工具里联机查看结果；同时 Sonar 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 Sonar。 此外，Sonar 的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。 Sonar 部署 Sonar 的相关下载和文档可以在下面的链接中找到：http://www.sonarqube.org/downloads/。需要注意最新版的 Sonar 需要至少 JDK 1.8 及以上版本。 上篇文章我们已经可以成功的使用 git 进行拉去，Sonar 的功能就是来检查代码是否有 BUG。除了检查代码是否有 bug 还有其他的功能，比如说：你的代码注释率是多少，代码有一些建议，编写语法的建议。所以我们叫质量管理 Sonar 还可以给代码打分，并且引用了技术宅的功能（告诉你有很多地方没改） Sonar 部署[root@linux-node1 ~]# yum install -y java-1.8.0 [root@linux-node1 ~]# cd /usr/local/src 软件包我们通过 wget 或者下载，rz 上传到服务器 #软件包下载：https://sonarsource.bintray.com/Distribution/sonarqube/sonarqube-5.6.zip [root@linux-node1 src]# unzip sonarqube-5.6.zip [root@linux-node1 src]# mv sonarqube-5.6 /usr/local/ [root@linux-node1 src]# ln -s /usr/local/sonarqube-5.6/ /usr/local/sonarqube 准备 Sonar 数据库 如果没有数据库请执行yum install -y mariadb mariadb-server [root@linux-node1 ~]# systemctl start mariadb [root@linux-node1 ~]# systemctl enable mariadb Created symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service. [root@linux-node1 ~]# mysql_secure_installation [root@linux-node1 ~]# mysql -uroot -p123456 特别提示： sonar 好像不支持mysql 5.5，所以如果看日志出现以上 error 请安装mysql 5.6 或者更高版本http://blog.csdn.net/onothing12345/article/details/49910087 执行 sql 语句 mysql&gt; CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci; mysql&gt; GRANT ALL ON sonar.* TO &apos;sonar&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sonar@pw&apos;; mysql&gt; GRANT ALL ON sonar.* TO &apos;sonar&apos;@&apos;%&apos; IDENTIFIED BY &apos;sonar@pw&apos;; mysql&gt; FLUSH PRIVILEGES; 配置 Sonar[root@linux-node1 ~]# cd /usr/local/sonarqube/conf/ [root@linux-node1 conf]# ls sonar.properties wrapper.conf 编写配置文件，修改数据库配置 [root@linux-node1 conf]# vim sonar.properties #我们只需要去配置文件里面修改数据库的认证即可 14 sonar.jdbc.username=sonar# 数据库用户 15 sonar.jdbc.password=sonar@pw #数据库密码 23 sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance 配置 Java 访问数据库驱动 (可选) 默认情况 Sonar 有自带的嵌入的数据库，那么你如果使用类是 Oracle 数据库，必须手动复制驱动类到${SONAR_HOME}/extensions/jdbc-driver/oracle/ 目录下，其它支持的数据库默认提供了驱动。其它数据库的配置可以参考官方文档：http://docs.sonarqube.org/display/HOME/SonarQube+Platform 启动 Sonar 你可以在 Sonar 的配置文件来配置 Sonar Web 监听的 IP 地址和端口，默认是 9000 端口。 [root@linux-node1 conf]# vim sonar.properties 99 #sonar.web.host=0.0.0.0 106 #sonar.web.port=9000 启动命令如下： [root@linux-node1 ~]# /usr/local/sonarqube/bin/linux-x86-64/sonar.sh start Starting SonarQube... Started SonarQube. 如果有什么问题可以看一下日志[/usr/local/sonarqube/logs/sonar.log] 检查是否有相应的端口 [root@linux-node1 ~]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 2239/unicorn master tcp0 0 0.0.0.0:80 0.0.0.0:* LISTEN 505/nginx: master p tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 569/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 971/master tcp0 0 127.0.0.1:43163 0.0.0.0:* LISTEN 5205/java tcp0 0 0.0.0.0:80600.0.0.0:* LISTEN 505/nginx: master p tcp0 0 127.0.0.1:32000 0.0.0.0:* LISTEN 4925/java tcp0 0 0.0.0.0:43044 0.0.0.0:* LISTEN 4952/java tcp0 0 0.0.0.0:33350 0.0.0.0:* LISTEN 5205/java tcp0 0 0.0.0.0:90000.0.0.0:* LISTEN 5011/java tcp0 0 0.0.0.0:33385 0.0.0.0:* LISTEN 5011/java tcp0 0 127.0.0.1:9001 0.0.0.0:* LISTEN 4952/java tcp6 0 0 :::3306 :::*LISTEN 4658/mysqld tcp6 0 0 :::34993:::*LISTEN 2348/java tcp6 0 0 :::8081 :::*LISTEN 2348/java tcp6 0 0 :::22 :::*LISTEN 569/sshd tcp6 0 0 ::1:25 :::*LISTEN 971/master udp6 0 0 :::33848:::*2348/java udp6 0 0 :::5353 :::*2348/java #端口是 9000 哦！ Web 登陆：IP:9000 提示： sonar 跟 jenkins 类似，也是以插件为主 sonar 安装插件有 2 种方式：第一种将插件下载完存放在 sonar 的插件目录，第二种使用 web 界面来使用安装 存放插件路径[/usr/local/sonarqube/extensions/plugins/] 安装中文插件 登陆：用户名：admin 密码：admin 需要重启才会生效 生效后如下图： 我们在安装一个 php 语言 温馨提示：如果下载不下来我们直接去 github 进行下载，因为我们这个插件都是使用 wget 进行下载的 我们现在只能使用 java 的 jar 包和 php，因为我们只安装了 java 和 php 的语言插件。如果想使用 Python 的程序，就需要安装 Python 的语言插件 Sonar 插件 ---&gt; 语言插件 （分析什么语言，你就需要安装什么语言的插件） Sonar 通过 SonarQube Scanner（扫描器）来对代码进行分析 官方文档：http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner 下载扫描器插件 [root@linux-node1 ~]# wget https://sonarsource.bintray.com/Distribution/sonar-scanner-cli/sonar-scanner-2.8.zip [root@linux-node1 ~]# unzip sonar-scanner-2.8.zip [root@linux-node1 ~]# mv sonar-scanner-2.8 /usr/local/ [root@linux-node1 ~]# ln -s /usr/local/sonar-scanner-2.8/ /usr/local/sonar-scanner 我们要将扫描器和 sonar 关联起来 [root@linux-node1 ~]# cd /usr/local/sonar-scanner [root@linux-node1 sonar-scanner]# ls bin conf lib [root@linux-node1 sonar-scanner]# cd conf/ [root@linux-node1 conf]# ls sonar-scanner.properties [root@linux-node1 conf]# vim sonar-scanner.properties sonar.host.url=http://localhost:9000#sonar 地址 sonar.sourceEncoding=UTF-8 #字符集 sonar.jdbc.username=sonar# 数据库账号 sonar.jdbc.password=sonar@pw #数据库密码 sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;amp;characterEncoding=utf8# 数据库连接地址 #打开注释即可 我们现在需要找一个代码进行分析。 sonar 插件提供了一个代码的库 github:https://github.com/SonarSource/sonar-examples 我们下载软件包：https://codeload.github.com/SonarSource/sonar-scanning-examples/zip/master 解压 [root@linux-node1 src]# unzip sonar-examples-master.zip [root@linux-node1 php]# cd sonar-examples-master/projects/languages/php [root@linux-node1 php]# cd php-sonar-runner-unit-tests/ [root@linux-node1 php-sonar-runner-unit-tests]# ll total 8 -rw-r--r-- 1 root root 647 Dec 14 09:57 README.md drwxr-xr-x 2 root root 51 Dec 14 09:57 reports -rw-r--r-- 1 root root 346 Dec 14 09:57 sonar-project.properties drwxr-xr-x 3 root root 31 Dec 14 09:57 src drwxr-xr-x 2 root root 25 Dec 14 09:57 tests #这里就是 PHP 的目录 配置文件解释： 如果你想让我扫描，就需要在代码路径下放一个配置文件 [root@linux-node1 php-sonar-runner-unit-tests]# cat sonar-project.properties sonar.projectKey=org.sonarqube:php-ut-sq-scanner #Key sonar.projectName=PHP :: PHPUnit :: SonarQube Scanner #这里的名称会显示在一会的 web 界面上 sonar.projectVersion=1.0# 版本，这里的版本一会也会显示在 web 界面上 sonar.sources=src #软件包存放路径 sonar.tests=tests sonar.language=php #语言 sonar.sourceEncoding=UTF-8 #字体 # Reusing PHPUnit reports sonar.php.coverage.reportPath=reports/phpunit.coverage.xml sonar.php.tests.reportPath=reports/phpunit.xml 也就是说在项目里面必须有这个配置文件才可以进行扫描 扫描 提示：需要在项目文件里面进行执行 [root@linux-node1 php-sonar-runner-unit-tests]# /usr/local/sonar-scanner/bin/sonar-scanner INFO: Scanner configuration file: /usr/local/sonar-scanner/conf/sonar-scanner.properties INFO: Project root configuration file: /usr/local/src/sonar-examples-master/projects/languages/php/php-sonar-runner-unit-tests/sonar-project.properties INFO: SonarQube Scanner 2.8 INFO: Java 1.8.0_111 Oracle Corporation (64-bit) INFO: Linux 3.10.0-514.2.2.el7.x86_64 amd64 INFO: User cache: /root/.sonar/cache INFO: Load global repositories INFO: Load global repositories (done) | time=211ms WARN: Property &apos;sonar.jdbc.url&apos; is not supported any more. It will be ignored. There is no longer any DB connection to the SQ database. WARN: Property &apos;sonar.jdbc.username&apos; is not supported any more. It will be ignored. There is no longer any DB connection to the SQ database. WARN: Property &apos;sonar.jdbc.password&apos; is not supported any more. It will be ignored. There is no longer any DB connection to the SQ database. INFO: User cache: /root/.sonar/cache INFO: Load plugins index INFO: Load plugins index (done) | time=3ms INFO: Download sonar-csharp-plugin-5.0.jar INFO: Download sonar-java-plugin-3.13.1.jar INFO: Download sonar-l10n-zh-plugin-1.11.jar INFO: Plugin [l10nzh] defines &apos;l10nen&apos; as base plugin. This metadata can be removed from manifest of l10n plugins since version 5.2. INFO: Download sonar-scm-git-plugin-1.2.jar INFO: Download sonar-php-plugin-2.9.1.1705.jar INFO: Download sonar-scm-svn-plugin-1.3.jar INFO: Download sonar-javascript-plugin-2.11.jar INFO: SonarQube server 5.6 INFO: Default locale: &quot;en_US&quot;, source code encoding: &quot;UTF-8&quot; INFO: Process project properties INFO: Load project repositories ................................................. ................................................. 提示：我们什么都不指定就会在当面目录下扫描 sonar-project.properties 文件，根据配置文件进行扫描工作。扫描之后我们在 web 界面上就可以看到代码的扫描结果 这里的名字，版本 都是在 sonar-project.properties 文件中定义的 质量阈帮我们设定好一个阈值，超过相应的阈值就算有bug 为了让 jenkins 可以在构建项目的时候执行 sonar，所以我们需要在 jenkins 上安装插件 现在就可以进行配置，让 jenkins 和sonar结合在一起。这样我们构建项目的时候就会进行代码检测 点击保存 配置 编辑我们的项目，选择最下放。找到构建 对 PHP 文件进行复制 [root@linux-node1 php-sonar-runner-unit-tests]# cat /usr/local/src/sonar-examples-master/projects/languages/php/php-sonar-runner-unit-tests/sonar-project.properties sonar.projectKey=org.sonarqube:php-ut-sq-scanner sonar.projectName=PHP :: PHPUnit :: SonarQube Scanner sonar.projectVersion=1.0 sonar.sources=src sonar.tests=tests sonar.language=php sonar.sourceEncoding=UTF-8 # Reusing PHPUnit reports sonar.php.coverage.reportPath=reports/phpunit.coverage.xml sonar.php.tests.reportPath=reports/phpunit.xml Analysis properties 分析的参数 填写完毕后，我们点击保存 我们选择立即构建 提示：此时的 SonarQube 是无法点击的 点击 Console Output 可以查看构建输出的内容 # 提示：只要没有 error 就可以 构建完成后，我们发现这里的 SonarQube 可以点击，我们点击 SonarQube 就会链接到 192.168.56.11:9000 就是代码查看器的地址 现在我们已经做到了可以在 git 上进行拉取代码。并进行检测 我们还可以配置一个构建失败发送邮箱： 在我们项目里面设置构建后操作，选择E-mail Notification 温馨提示：使用 163 邮箱发送的通知被 163 服务器退回了，因此我将设置在 jenkins 的邮箱改成了 QQ 邮箱 QQ：邮箱需要设置如下： 1、需要开启 POPE3/SMTP 服务 2、在 jenkins 上配置的密码我们需要点击生成授权码进行使用 QQ 邮件默认会收到如下提示： 当再次构件成功时，邮件内容如下： 转自：持续集成之代码质量管理 -Sonar [三]]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成之 Jenkins+Gitlab 简介 [一]【转】]]></title>
    <url>%2F2017%2F03%2F20%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B9%8BJenkins%2BGitlab%E7%AE%80%E4%BB%8B%20%5B%E4%B8%80%5D%2F</url>
    <content type="text"><![CDATA[摘要 DevOps（英文 Development（开发）和 Operations（技术运营）的组合）是一组过程、方法与系统的统称，用于促进开发（应用程序 / 软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作 持续集成之 Jenkins+Gitlab 简介 [一]持续集成概念 持续集成 Continuous Integration—-CI 持续交付 Continuous Delivery—-CD 持续部署 Continuous Deployment—–CD 1.1 什么是持续集成：持续集成是指开发者在代码的开发过程中，可以频繁的将代码部署集成到主干，并进程自动化测试 1.2 什么是持续交付：持续交付指的是在持续集成的环境基础之上，将代码部署到预生产环境 1.3 持续部署：在持续交付的基础上，把部署到生产环境的过程自动化，持续部署和持续交付的区别就是最终部署到生产环境是自动化的。 1.4 部署代码上线流程 1. 代码获取（直接了拉取） 2. 编译 （可选） 3. 配置文件放进去 4. 打包 5.scp 到目标服务器 6. 将目标服务器移除集群 7. 解压并放置到 Webroot 8.Scp 差异文件 9. 重启 （可选） 10. 测试 11. 加入集群 运维必知 OWASPJenkins 上 OWASP 插件介绍 ： 它是开放式 Web 应用程序安全项目[OWASP,Open Web Application Secunity Project] 它每年会出一个 top10 的安全漏洞，我们需要知道当前 top10 的漏洞有哪些 https://www.owasp.org/images/5/57/OWASP_Proactive_Controls_2.pdf https://www.owasp.org/index.php/Top_10_2013-Top_10 Gitlab 介绍 GitLab 是一个利用 Ruby on Rails 开发的开源应用程序，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。 GitLab 拥有与 Github 类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。它还提供一个代码片段收集功能可以轻松实现代码复用，便于日后有需要的时候进行查找。 环境准备[root@linux-node1 ~]# cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) [root@linux-node1 ~]# uname -r 3.10.0-514.2.2.el7.x86_64 下载 epel 源 [root@linux-node1 ~]# wget http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm [root@linux-node1 ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 关闭 NetworkManager 和防火墙 [root@linux-node1 ~]#systemctl stop firewalld.service systemctl disable firewalld systemctl disable NetworkManager 关闭 SELinux 并确认处于关闭状态 sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config grep SELINUX=disabled /etc/selinux/config setenforce 0 更新系统并重启 [root@linux-node1 ~]# yum update -y &amp;&amp; reboot 我们一共有 2 台：192.168.56.11和 192.168.56.12 我们安装在 192.168.56.11 上 [root@linux-node1 /]# yum install curl policycoreutils openssh-server openssh-clients postfix -y [root@linux-node1 /]# systemctl start postfix [root@linux-node1 /]# curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash [root@linux-node1 /]# yum install -y gitlab-ce 由于网络问题，国内用户，建议使用清华大学的镜像源进行安装 [root@linux-node1 ~]# cat /etc/yum.repos.d/gitlab-ce.repo [gitlab-ce] name=gitlab-ce baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7 repo_gpgcheck=0 gpgcheck=0 enabled=1 gpgkey=https://packages.gitlab.com/gpg.key [root@linux-node1 ~]# yum makecache [root@linux-node1 /]# yum install -y gitlab-ce 在安装一个 git 客户端 [root@linux-node1 /]# yum install -y git 配置并启动gitlab-ce [root@linux-node1 ~]# gitlab-ctl reconfigure #时间可能比较长，耐心你等待即可！---- gitlab 常用命令： 关闭 gitlab：[root@linux-node2 ~]# gitlab-ctl stop 启动 gitlab：[root@linux-node2 ~]# gitlab-ctl start 重启 gitlab：[root@linux-node2 ~]# gitlab-ctl restart 重载配置文件: gitlab-ctl reconfigure 可以使用 gitlab-ctl 管理gitlab，例如查看gitlab 状态： [root@linux-node1 /]# gitlab-ctl status run: gitlab-workhorse: (pid 7437) 324s; run: log: (pid 7436) 324s run: logrotate: (pid 7452) 316s; run: log: (pid 7451) 316s run: nginx: (pid 8168) 2s; run: log: (pid 7442) 318s run: postgresql: (pid 7293) 363s; run: log: (pid 7292) 363s run: redis: (pid 7210) 369s; run: log: (pid 7209) 369s run: sidekiq: (pid 7479) 265s; run: log: (pid 7426) 326s run: unicorn: (pid 7396) 327s; run: log: (pid 7395) 327s 提示： 我们要保证 80 端口不被占用 我们可以查看一下端口 [root@linux-node1 /]# gitlab-ctl restart ok: run: gitlab-workhorse: (pid 8353) 0s ok: run: logrotate: (pid 8360) 1s ok: run: nginx: (pid 8367) 0s timeout: down: postgresql: 0s, normally up, want up ok: run: redis: (pid 8437) 0s ok: run: sidekiq: (pid 8445) 0s ok: run: unicorn: (pid 8450) 0s [root@linux-node1 /]# lsof -i:80 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 8367 root7u IPv4 54972 0t0 TCP *:http (LISTEN) nginx 8368 gitlab-www7u IPv4 54972 0t0 TCP *:http (LISTEN) Web：访问：192.168.56.11 提示：启动 gitlab 需要时间！ Web页面提示我们需要设置一个账号密码（我们要设置最少 8 位数 的一个账号密码）我们设置密码为：12345678 我们在后面的页面设置用户名 我们现在是以管理员的身份登陆 我们点击右上角管理区域 第一步：我们关闭自动注册，因为我们内部使用不需要用户自己注册，由运维分配用户即可 提示：Save在页面最下放！！！！！！ 记得点保存！！！！！！！！！！！！ 现在在查看首页就没有注册页面了 第二步：我们创建一个用户，在创建一个项目 先创建一个组 提示：gitlab 上面有一个项目跟组的概念，我们要创建一个组，才可以在创建一个项目。因为 gitlab 的路径上首先是 ip 地址，其次是组 点击下方Create group 然后我们在组里面创建项目 下一步： 创建完成之后它提示我们可以创建一个 key 对它进行管理 我们点击上面的 README 然后我们随便在里面写点东西 填写完成我们点击前面进行查看 我们要做免密验证，现在去 192.168.56.11 复制下面的.ssh/id_rsa.pub [www@linux-node1 ~]$ cat .ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC8wfTSQcSyhlsGYDSUtuxZNb1Gl3VU56nAPuxAEF2wP2ZWZ2yva354ZdKOOb6rZx2yZxqy5XIj7opBJPbhraXap+NtCH5qWyktR7dH19RBmCS7vUGgvk/5RQC0mVFrC8cztBp0M/5HxMuhVir6mD1rhbDvvaLL6S5y4gljzC1Gr2VRHIb4Et9go/38c2tqMjYCike7WWbFRyL9wTal6/146+9uREZ/r69TBTKrGuRqF44fROQP8/ly02XFjlXyl6J5NnGTk6AU855pwasX0W9aNPce3Ynrpe1TBTubmfQhrH1BwteEmg+ZXNRupxjumA+tPWfBUX+u51r/w7W/d4PD www@linux-node1 #提示：需要提前做秘钥认证 设置Keys 添加完之后我们就可以使用 www 用户，就可以拉了 点击Projects 选择SSH，我们要将代码拉去下来 [www@linux-node1 ~]$ cd /deploy/code/ [www@linux-node1 code]$ ls web-demo [www@linux-node1 code]$ rm -rf web-demo/ [www@linux-node1 ~]$ git clone git@linux-node1:web/web-demo.git Cloning into &apos;web-demo&apos;... The authenticity of host &apos;linux-node1 (192.168.56.11)&apos; can&apos;t be established. ECDSA key fingerprint is b5:74:8f:f1:03:2d:cb:7d:01:28:30:12:34:9c:35:8c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;linux-node1&apos; (ECDSA) to the list of known hosts. remote: Counting objects: 3, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0) Receiving objects: 100% (3/3), done. [www@linux-node1 ~]$ ls web-demo/ README.md #git clone 是克隆的意思 我们来模拟开发继续写代码提交 [www@linux-node1 ~]$ mkdir -p /web-demo [www@linux-node1 ~]$ vim web-demo/index.html [www@linux-node1 ~]$ cd web-demo/ [www@linux-node1 web-demo]$ [www@linux-node1 web-demo]$ ls index.html README.md [www@linux-node1 web-demo]$ git add * [www@linux-node1 web-demo]$ git commit -m &quot;add index.html&quot; *** Please tell me who you are. Run git config --global user.email &quot;you@example.com&quot; git config --global user.name &quot;Your Name&quot; to set your account&apos;s default identity. Omit --global to set the identity only in this repository. fatal: empty ident name (for &lt;www@linux-node1.(none)&gt;) not allowed 需要身份验证： [www@linux-node1 web-demo]$ git config --global user.email &quot;you@example.com&quot; [www@linux-node1 web-demo]$ git config --global user.name &quot;Your Name&quot; [www@linux-node1 web-demo]$ git commit -m &quot;add index.html&quot; [master be8a547] add index.html 1 file changed, 169 insertions(+) create mode 100644 index.html git push命令用于将本地分支的更新，推送到远程主机。它的格式与 git pull 命令相仿。 [www@linux-node1 web-demo]$ git push warning: push.default is unset; its implicit value is changing in Git 2.0 from &apos;matching&apos; to &apos;simple&apos;. To squelch this message and maintain the current behavior after the default changes, use: git config --global push.default matching To squelch this message and adopt the new behavior now, use: git config --global push.default simple See &apos;git help config&apos; and search for &apos;push.default&apos; for further information. (the &apos;simple&apos; mode was introduced in Git 1.7.11. Use the similar mode &apos;current&apos; instead of &apos;simple&apos; if you sometimes use older versions of Git) Counting objects: 4, done. Delta compression using up to 4 threads. Compressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 7.66 KiB | 0 bytes/s, done. Total 3 (delta 0), reused 0 (delta 0) To git@linux-node1:web/web-demo.git 0c1d357..be8a547 master -&gt; master 我们的 gitlab 安装在 opt/gitlabgitlab 配置文件 存放在etc/gitlab/gitlab.rb # 现在 git 需要加上主机名，我们可以修改配置文件，让它使用 IP 进行访问 编辑配置文件 [root@linux-node1 ~]# vim /etc/gitlab/gitlab.rb external_url &apos;http://192.168.56.11&apos; [root@linux-node1 ~]# gitlab-ctl reconfigure #提示：修改完需要使用 reconfigure 重载配置才会生效 我们从新登陆进行查看 咦！ 为啥还没改呢！ 我们从新创建一个项目在试一下 友情提示： 关于 Git 可以查看 徐布斯博客 or 廖雪峰 Git 自动化运维之 DevOps DevOps（英文 Development（开发 ）和 Operations（ 技术运营）的组合）是一组过程、方法与系统的统称，用于促进开发（应用程序 / 软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。 它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作 简单的来说 DevOps 是一种文化，是让开发开发、运维、测试能够之间沟通和交流 自动化运维工具：saltstack、jenkins、等。因为他们的目标一样，为了我们的软件、构建、测试、发布更加的敏捷、频繁、可靠 如果运维对 git 不熟，是无法做自动化部署。因为所有的项目都受制于开发 Jenkins 介绍 Jenkins 只是一个平台，真正运作的都是插件。这就是 jenkins 流行的原因，因为 jenkins 什么插件都有 Hudson 是Jenkins的前身，是基于 Java 开发的一种持续集成工具，用于监控程序重复的工作，Hudson后来被收购，成为商业版。后来创始人又写了一个 jenkins，jenkins 在功能上远远超过hudson Jenkins 官网：https://jenkins.io/ 安装 安装 JDK Jenkins 是 Java 编写的，所以需要先安装 JDK，这里采用 yum 安装，如果对版本有需求，可以直接在 Oracle 官网下载 JDK。 [root@linux-node1 ~]# yum install -y java-1.8.0 安装 jenkins [root@linux-node1 ~]# cd /etc/yum.repos.d/ [root@linux-node1 yum.repos.d]# wget http://pkg.jenkins.io/redhat/jenkins.repo [root@linux-node1 ~]# rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key [root@linux-node1 ~]# yum install -y jenkins [root@linux-node1 ~]# systemctl start jenkins #本文使用 yum 进行安装，大家也可以使用编译安装。 新版本的 jenkins 为了保证安全，在安装之后有一个锁，需要设置密码之后才可以解锁 Jenkins Web访问地址：192.168.56.11:8080 友情提示：jenkins 如果跟 gitlab 在一台服务器需要将 jenkins 的端口进行修改，需要将 jenkins 的 8080 修改为 8081 [root@linux-node1 ~]# cat /var/lib/jenkins/secrets/initialAdminPassword 490a2f35a2df49b6b8787ecb27122a3a 复制这个文件下面的 ID，否则不可以进行安装。 我们选择推荐安装即可 它会给我们安装一些基础的插件 设置用户名密码： 点击保存并退出 早期 jenkins 默认是不需要登陆的 我们先来介绍一下 jenkins 基础功能 我们点击 新建 这里就是构建一个项目 用户界面：主要是一些用户的管理 可以看到当前登陆用户及用户权限等 任务历史：可以查看到所有构建过的项目的历史 # 之所以叫构建，是因为都是 java，因为如果不是 java 程序就没有构建这个词。但是我们也可以把一些工作称之为构建 系统管理：存放 jenkins 所有的配置 My Views：视图功能，我们可以自己创建一个自己的视图 构建队列：如果当前有视图任务都会显示在这里 构建执行状态：显示在正构建的任务 系统管理：- 系统设置 设置 Jenkins 全局设置 &amp; 路径 Jenkins 系统管理比较重要的就是插件管理了 # 因为 jenkins 所有的东西都需要靠插件来完成， 点击已安装可以查看我们的安装 我们想安装什么插件，我们可以选择可选插件 我们为了和 gitlab 和在一起，我们需要安装一个插件 查看还可以去 jenkins 官网下载，然后上传插件 因为很多插件需要翻墙才可以继续下载，jenkins 还提供了代理的设置 还是在服务器目录下进行上传插件 目录路径 = /var/lib/jenkins/plugins/ 这个目录下是我们安装所有的插件 转自：持续集成之 Jenkins+Gitlab 简介 [一]]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成之 Jenkins+Gitlab 简介 [二]【转】]]></title>
    <url>%2F2017%2F03%2F20%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B9%8BJenkins%2BGitlab%E5%AE%9E%E7%8E%B0%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%20%5B%E4%BA%8C%5D%2F</url>
    <content type="text"><![CDATA[持续集成之 Jenkins+Gitlab 实现持续集成 [二]项目：使用 git+jenkins 实现持续集成 开始构建 General 源码管理 我们安装的是 git 插件，还可以安装 svn 插件 我们将 git 路径存在这里还需要权限认证，否则会出现error 我们添加一个认证 选择一下认证方式（我们可以在 系统管理 --&gt;Configure Credentials）里面进行设置 提示：gitlab 有一个 key，是我们用来做仓库的 key。拥有的权限是read-only 公钥我们需要在服务器上查看。 [root@linux-node1 ~]# ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Created directory &apos;/root/.ssh&apos;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: 5c:55:51:4e:a0:ad:1f:87:e0:96:9b:24:a3:09:68:62 root@linux-node2 The key&apos;s randomart image is: +--[RSA 2048]----+ |..++o| | . o o | | . o . .| | . . . . + . | | E o . S o * o .| | . o . o = + o | |o o . | | | | | +-----------------+ 在 192.168.56.11 部署的节点上，生成 key [root@linux-node1 ~]# cat .ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDWEDIIatngRx5NaqU6t+f6FvY2RqYp3V3u5CNJS6xAamGokQ3MnbsTv/V8yKy2TpvNcXsaXmqwQtOVSAO4BzltidMPxBJUQCqKdMRbPqpzo7ZqGCuLcCfHC8M6tSbr1AaHkLbow29YbCMyzCCkjDfRcOez8yHuLj5BSFpKYCjx2wpJxoZ/Z6J8Fslsyu7MaRMvUhBMAF6mqQaC1qZ6K4BMt0IpAuJvoL4dNu9P6KcnG3Wy2zrzoKzkFUi0xpKCmpYo2bq4zRXgAFAndp44j5iMKEavWPeRH0RHTGsfE5vU5/0CI9LCRjtp/3vTaYlBryq5vNXb2abCrJXWws0jwp6L root@linux-node2 我们设置完成后测试 git 是否可以拉去 [root@linux-node2 ~]# yum install git -y #如果没有 git 命令就安装一个 git 客户端 [root@linux-node1 ~]# git clone git@www.abcdocker.com:web/web-demo.git Cloning into &apos;web-demo&apos;... The authenticity of host &apos;www.abcdocker.com (192.168.56.11)&apos; can&apos;t be established. ECDSA key fingerprint is b5:74:8f:f1:03:2d:cb:7d:01:28:30:12:34:9c:35:8c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added &apos;www.abcdocker.com,192.168.56.11&apos; (ECDSA) to the list of known hosts. remote: Counting objects: 10, done. remote: Compressing objects: 100% (8/8), done. remote: Total 10 (delta 0), reused 0 (delta 0) Receiving objects: 100% (10/10), 70.00 KiB | 0 bytes/s, done. 私钥： [root@linux-node1 ~]# cat .ssh/ id_rsa id_rsa.pub known_hosts [root@linux-node1 ~]# cat .ssh/id_rsa -----BEGIN RSA PRIVATE KEY----- MIIEpQIBAAKCAQEAoVULn6xsKj+XZMyFOGcFwo0bkrzFRjeZSXby/0BXJJpVaYVj LEMNOlbD4YHCNTQ4xmyjoeaW468pciVAooOWCCdcbjDmdmACt9knHjMZ1YRG/xuM DW/VTLBkP1bOAsa1NR3QE5LR/cwwFeEM/NcdjzmCVuQeSwL8GeKMKpyKWe6N8mus QcRLwiDElbQ9e6CqzagKYbIPnuvCr0XsYjQhGwm0Rhqt2ynr4Ig7FqUhpwmLCQtP nEq1MbsxDtxugKhiP6kd5znoPdazrKAD9xaRYwSoG/7F4IJMMI5hiKhVya1Bvl5n M3heJBv61KzW3cvOHuUch6CEt1ypybkY08R8gwIDAQABAoIBAQCXVnTZ6t9oXlDB EI1jlFi14LJd2tBfhuY3IOrfgFZ+knvOyX53VcrB0ARdtOAeEoezstNomysuF/EU D1frWu5RZcLx5tM5deT22zAzxxHT1grXYdrl++Ml1k2jkOUde5MeaYH36oErx+/P hlYtlAk5gmP+6Gx2Ry1/hqGfk0rBAmY/eazqpT5hc1ANuW5dCmdQ5pqHog8CwH+K YnhKNUaW0VMqzWg9y3cQc8tlQItWUAsjl4+l/rSdOxsC9lTtuJZfMPIlrtLPi6tg tfjpX+N4zRbSwVblrD6mXOcKmAPbnuvLhyIBnBmDXeAHKCEnOYJ8eEJ6rT+GRjc8 aDvzsLmhAoGBAM0qj6lqdY4ZpHjCd7hJzGIitLBqsqRmHWgs9ymLIFQ+Z8LYI2HQ 1xja/oUfMkAnArcjz+q+gpDinC+oOVAnr4FQWB+lUdlMzzuE6OtYyWYYzjHpdTbO j4tHgqkOraiuRy1TanjgAJJSwR6oTwnBIC8PjEHa3o8xslVuexOobh1TAoGBAMlO JUHMMVmgxDaZq0c50Bn/r/k57QGj87E9mEbJeqBs+8fcxZoOFLEEd+Sb8Q1riqV9 12L2BAc6EoypoPUydbt0Q5/1G2VvCN1a6G43Ip7QM1cUTPrp17fvHWVSAMdq7lIr ntabqmtZVGqcxedmG1N7BVNXBd4Jy5HjOZ8Qfg4RAoGBAMyX5s9hNH1SIOuzscN7 BG/QgDN1E1RR6H1cadVpwgGAgeSRuSbwJa/JowqJg4jp3hFXix1igb2N3YbA0PaX vLLNtjNInwh9SiLmdYdL8Pr5PZYUYykWb5rK4wdHdfHCaYRPrNuBNdC06ZRy7u6h QkDr1khNxKczPc1n8SA3VCe1AoGAYdWb39WIaoHquoqGppAfZnNQp/SSDkkLR6mi 10xWT5+H4oOWeZ+8SKfeSPnM9nO8p194jXz5SjXcDAbo1iIW++qubxAlp2+GRGZJ Lj+XkM2pFfoky5FYqOkKRVLMVB7RAph2kuCGu7NnhoT43dRPFYxlczKJBHeIOzfO qlLOoLECgYEAkexlwKGeXyJj481SfqCYhjiTjCiibx/s6yS2cmamgEKOZCB2osmq 3m9PvOAp26Sm1ISiuINNbpLY3Gi5fEvNUSyRx8HzRXP2fydvdgpltDxJUPaUVxvn X46F8ewsMJ7/FDLSyjdzwvoDRvKCk99OBmGmofqh5zW0GrjcQjthmbk= -----END RSA PRIVATE KEY----- [root@linux-node1 ~]# 刚刚返回刚刚的区域，继续配置 现在我们复制 git 的url就不会出现验证提示 我们选择 gitlab，url 如下图 查看 gitlab 版本 [root@linux-node1 ~]# rpm -qa|grep gitlab gitlab-ce-8.14.5-ce.0.el7.x86_64 我们现在就添加了一个 git 仓库，现在保存就可以了！ 保存完毕后，我们选择立即构建 点击 Console Output 可以显示控制台的输出 现在基本就算是构建成功了 转自：持续集成之 Jenkins+Gitlab 实现持续集成 [二]]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-3.2.3 实现微信（WeChat）告警【转】]]></title>
    <url>%2F2016%2F12%2F10%2FZabbix-3.2.3%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%EF%BC%88WeChat%EF%BC%89%E5%91%8A%E8%AD%A6%E3%80%90%E8%BD%AC%E3%80%91%2F</url>
    <content type="text"><![CDATA[摘要 Zabbix 可以通过多种方式把告警信息发送到指定人，常用的有邮件，短信报警方式，但是越来越多的企业开始使用 zabbix 结合微信作为主要的告警方式，这样可以及时有效的把告警信息推送到接收人，方便告警的及时处理。 Zabbix-3.2.3 实现微信（WeChat）告警 Zabbix 可以通过多种方式把告警信息发送到指定人，常用的有邮件，短信报警方式，但是越来越多的企业开始使用 zabbix 结合微信作为主要的告警方式，这样可以及时有效的把告警信息推送到接收人，方便告警的及时处理。 关于邮件报警可以参考：Zabbix Web 邮件报警 一、微信企业号申请 地址： https://qy.weixin.qq.com/ 第一步注册 提示：这里简单的说一下，微信企业号和微信公众号是不一样的！ 到邮件查看邮件，继续下一步 提示一下：注册以后就不可以修改微信号类型 我们选择注册团队 由于我已经注册了，下一步就不继续操作了 二、配置微信企业号 当我们设置完微信号的信息之后，请继续跟我操作 我们点击通讯录–&gt; 创建子部门–&gt; 运维组 提示： 我们需要记录运维组的 ID，用于脚本接收报警 我们点击运维–&gt; 添加成员 关于认证可以参考官方说明： 我们可以使用扫描二维码认证或者邀请认证 我们点击创建应用 选择消息型 设置组合用户，将运维整个组添加进去 设置完成之后如下图所示！提示：我们需要记录应用 ID，在接收邮件时会使用 设置权限，让运维组有查看的选项。管理员可以不进行设置 需要确定管理员有权限使用应用发送消息，需要管理员的 CorpID 和 Sercrt。（重要） 准备事项：微信企业号 企业号已经被部门成员关注 企业号有一个可以发送消息的应用，一个授权管理员，可以使用应用给成员发送消息 需要得到的信息 成员账号 组织部门 ID 应用 ID CorpID 和 Secret 三、修改 Zabbix.conf[root@abcdocker ~]# grep alertscripts /etc/zabbix/zabbix_server.conf AlertScriptsPath=/usr/lib/zabbix/alertscripts 我们设置 zabbix 默认脚本路径，这样在 web 端就可以获取到脚本 四、设置 python 脚本# 安装 simplejson wget https://pypi.python.org/packages/f0/07/26b519e6ebb03c2a74989f7571e6ae6b82e9d7d81b8de6fcdbfc643c7b58/simplejson-3.8.2.tar.gz tar zxvf simplejson-3.8.2.tar.gz &amp;&amp; cd simplejson-3.8.2 python setup.py build python setup.py install 下载 wechat.py 脚本 git clone https://github.com/X-Mars/Zabbix-Alert-WeChat.git cp Zabbix-Alert-WeChat/wechat.py /usr/lib/zabbix/alertscripts/ cd /usr/lib/zabbix/alertscripts/ chmod +x wechat.py &amp;&amp; chown zabbix:zabbix wechat.py 提示：这里需要修改 py 脚本 看注释，这就不解释了 [root@abcdocker ~]# cat /usr/lib/zabbix/alertscripts/wechat.py #!/usr/bin/python #_*_coding:utf-8 _*_ import urllib,urllib2 import json import sys import simplejson reload(sys) sys.setdefaultencoding(&apos;utf-8&apos;) def gettoken(corpid,corpsecret): gettoken_url = &apos;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=&apos; + corpid + &apos;&amp;corpsecret=&apos; + corpsecret print gettoken_url try: token_file = urllib2.urlopen(gettoken_url) except urllib2.HTTPError as e: print e.code print e.read().decode(&quot;utf8&quot;) sys.exit() token_data = token_file.read().decode(&apos;utf-8&apos;) token_json = json.loads(token_data) token_json.keys() token = token_json[&apos;access_token&apos;] return token def senddata(access_token,user,subject,content): send_url = &apos;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=&apos; + access_token send_values = { &quot;touser&quot;:user,# 企业号中的用户帐号，在 zabbix 用户 Media 中配置，如果配置不正常，将按部门发送。 &quot;toparty&quot;:&quot;2&quot;,# 企业号中的部门 id。 &quot;msgtype&quot;:&quot;text&quot;, #消息类型。 &quot;agentid&quot;:&quot;2&quot;,# 企业号中的应用 id。 &quot;text&quot;:{&quot;content&quot;:subject + &apos;\n&apos; + content}, &quot;safe&quot;:&quot;0&quot; } #send_data = json.dumps(send_values, ensure_ascii=False) send_data = simplejson.dumps(send_values, ensure_ascii=False).encode(&apos;utf-8&apos;) send_request = urllib2.Request(send_url, send_data) response = json.loads(urllib2.urlopen(send_request).read()) print str(response) if __name__ == &apos;__main__&apos;: user = str(sys.argv[1]) #zabbix 传过来的第一个参数 subject = str(sys.argv[2]) #zabbix 传过来的第二个参数 content = str(sys.argv[3]) #zabbix 传过来的第三个参数 corpid = &apos;11111111111111&apos; #CorpID 是企业号的标识 corpsecret = &apos;222222222222222222&apos; #corpsecretSecret 是管理组凭证密钥 accesstoken = gettoken(corpid,corpsecret) senddata(accesstoken,user,subject,content) 执行 py 脚本，进行测试 [root@abcdocker alertscripts]# ./wechat.py www www 123 https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=wx6dadb9cc293b793e&amp;corpsecret=JjesoeixbFt6dDur7_eXtamVBx2SjPBuXMQ0Jte3YLkz8l-VBnr0JvU12P0kvpGJ {u&apos;invaliduser&apos;: u&apos;all user invalid&apos;, u&apos;errcode&apos;: 0, u&apos;errmsg&apos;: u&apos;ok&apos;} 五、zabbix web 界面配置 创建报警媒介 创建报警用户 这里填写运维组 ID 设置报警动作 报警消息设置如下： hostname: ({HOST.NAME} Time:{EVENT.DATE} {EVENT.TIME} level:{TRIGGER.SEVERITY} message:{TRIGGER.NAME} event:{ITEM.NAME}:{ITEM.VALUE} url:www.abcdocker.com 恢复报警如下： hostname: ({HOST.NAME} Time:{EVENT.DATE} {EVENT.TIME} level:{TRIGGER.SEVERITY} message:{TRIGGER.NAME} event:{ITEM.NAME}:{ITEM.VALUE} url:www.abcdocker.com 报警配置如下 恢复配置如下 提示： 不要忘记先点小的add--&gt; 小的 update--&gt;Update 六、测试 为了验证效果我们停掉 zabbix-agent, 进行查看报警 [root@abcdocker ~]# systemctl stop zabbix-agent 报警如下 本文参考： Zabbix-3.0.3 实现微信（WeChat）告警 转自：Zabbix-3.2.3 实现微信（WeChat）告警]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-3.0.X 安装 Graphtree【转】]]></title>
    <url>%2F2016%2F12%2F05%2FZabbix-3.0.X%20%E5%AE%89%E8%A3%85Graphtree%2F</url>
    <content type="text"><![CDATA[Zabbix-3.0.X 安装 Graphtreezabbix本文转载http://blog.csdn.net/wh211212/article/details/52735180 Zabbix 中，想要集中展示图像，唯一的选择是 screen，后来zatree 解决了 screen 的问题，但性能不够好。Graphtree 由 OneOaaS 开发并开源出来，用来解决 Zabbix 的图形展示问题，性能较好。 提示：zatree 不支持 3.x 和 3.2 暂时只支持 2.4 一、Graphtree 功能概述 ▲ 集中展示所有分组设备 ▲ 集中展示一个分组图像 ▲ 集中展示一个设备图像 ▲ 展示设备下的 Application ▲ 展示每个应用下的图像 ▲ 展示每个应用下的日志 ▲ 对原声无图的监控项进行绘图 注意事项： 主机和组级别下，默认只显示系统初始的图形 二、Zabbix 版本要求：3.0.x提示：暂时只支持 3.0 版本，根据测试不支持 3.2 版本 1、插件安装 Zabbix-web 目录 提示：如果是 yum 安装并且是 centos7 目录会在 /usr/share/zabbix 可以使用 find 进行查找 cd /usr/local/nginx/html/zabbix 下载 Graphtree 补丁包 wget https://raw.githubusercontent.com/OneOaaS/graphtrees/master/graphtree3-0-1.patch 安装 Linux 下打补丁命令 patch yum -y install patch 打补丁 patch -Np0 &lt; graphtree3-0-1.patch 三、Graphtree 效果图1、删除提示信息vim /usr/local/nginx/html/zabbix/graphtree.right.php 根据自己的路径进行修改 d7d #删除 344-350 行 2、重启载入 Zabbix-web，可以看到 Graphtree 已出效果 转自：Zabbix-3.0.X 安装 Graphtree]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix_sender 介绍及配置【转】]]></title>
    <url>%2F2016%2F11%2F28%2FZabbix_sender%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zabbix_sender 是什么? 有什么作用？ zabbix 获取 key 值 有超时时间，如果自定义的 key 脚本一般需要执行很长时间，这根本没法去做监控，那怎么办呢？这时候就需要使用 zabbix 监控类型 zabbix trapper，配合zabbix_sender 给它传递数据。所以说 zabbix_sender 是更新 items 值 最快的方式 安装 在 centos5 上安装rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/5/x86_64/zabbix-sender-3.0.5-1.el5.x86_64.rpm 在 centos6 上安装 zabbix_senderrpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/6/x86_64/zabbix-sender-3.0.5-1.el6.x86_64.rpm 在 centos7 上安装 zabbix_senderrpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-sender-3.0.5-1.el7.x86_64.rpm 命令解释 zabbix_sender 命令详解 最简易使用方法一: zabbix_sender -z server -s host -k key -o value 最简易使用方法二： zabbix_sender -c config-file -k key -o value 最简易使用方法三： zabbix_sender -z server -i file 更多的使用方法可以man zabbix_sender 主要的使用参数 -c --config &lt;file&gt; zabbix_agent 配置文件绝对路径 -z --zabbix-server &lt;server&gt; zabbix server 的 IP 地址 -p --port &lt;server port&gt; zabbix server 端口. 默认 10051 -s --host &lt;hostname&gt; 主机名，与 zabbix_server web 上主机的 hostname 一致 例如 -I --source-address &lt;IP address&gt; 源 IP -k --key &lt;key&gt; 监控项的 key -o --value &lt;key value&gt;key 值 -i --input-file &lt;input file&gt; 从文件里面读取 hostname、key、value 一行为一条数据，使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来 -r --real-time 将数据实时提交给服务器 -v --verbose 详细模式, -vv 更详细 案例 下面：我们创建一个监控项item zabbix_sender -z 192.168.56.11 -s 192.168.56.100 -k login.users -o 111 如下图所示 检验 -o的值也可以引用命令： [root@muban ~]# zabbix_sender -z 192.168.56.11 -s 192.168.56.100 -k login.users -o $(w|sed &apos;1,2d&apos;|wc -l) 使用 zabbix_sender 批量发送 首先多准备几个 zabbix_trapper 类型的监控项 编写批量列表，每行以 hostname、key、value 的方式 [root@muban ~]# cat f.txt 192.168.56.100 login.users 12 192.168.56.100 login.users1 13 192.168.56.100 login.users2 14 192.168.56.100 login.users3 15 测试 zabbix_sender -z 192.168.56.11 -i f.txt 转自：Zabbix_sender 介绍及配置]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix Web 邮件报警【转】]]></title>
    <url>%2F2016%2F11%2F27%2FZabbix%20Web%20%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[zabbix 3.0 版本系列会造成无法使用 smtp 进行报警我们可以使用邮件报警，可以参考文章Zabbix 使用脚本发送邮件 完整配置邮件步骤如下： 首先点击配置，选择报警媒介，点击邮件[Email] 提示：这里的密码不是 QQ 登陆密码，而是 QQ 邮箱的授权密码 设置收件人邮箱 设置发送邮件动作 此处注意如果没有开启需要开启，要确保状态是 Enabled 这里可以设置脚本内容，我们默认就行 测试 我自己服务器安装 zabbix 3.2(3.2 安装文档)，zabbix 3.2 有默认的网卡监控，我设置一个超过 10M 报警的动作。我们可以看邮件如下 报警邮件 恢复邮件 谁要在说发送不了邮件，我打死他！ 转自：Zabbix Web 邮件报警]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 自动化监控 [十]【转】]]></title>
    <url>%2F2016%2F11%2F25%2FZabbix%203.0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E7%9B%91%E6%8E%A7%20%5B%E5%8D%81%5D%2F</url>
    <content type="text"><![CDATA[自动化分类 所有的自动化都可以分为 2 种 1. 自动注册 Zabbix agnet 自动添加 2. 主动发现 1. 自动发现 Discover 2.zabbix api 因为我们只有 2 台web，为了方便演示。我们将原来添加的 proxy 删掉. 提示： 主动模式下设置自动注册 一、自动注册设置agent 配置文件修改 [root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf LogFileSize=0 StartAgents=0 Server=192.168.56.11 ServerActive=192.168.56.11 Hostname=192.168.56.11 HostMetadata=system.uname #Server IP 地址 HostMetadataItem=system.uname #特征 1. 可以我们自己写一个特征 2. 我们执行一个 key #手写级别大于执行 key 过滤出我们的配置[如下] [root@CentOS6 zabbix]# egrep -v &quot;#|^$&quot; zabbix_agentd.conf PidFile=/var/run/zabbix/zabbix_agentd.pid LogFile=/var/log/zabbix/zabbix_agentd.log LogFileSize=0 StartAgents=0 Server=192.168.56.11 ServerActive=192.168.56.11 Hostname=192.168.56.12 HostMetadata=system.uname Include=/etc/zabbix/zabbix_agentd.d/ 我们先不重启，因为重启就生效了。我们需要设置一个规则. 注意自动发现必须要设置 ServerActive 让客户端启动主动去寻找服务端 提示，zabbix-agent 起来的时候去找 server，这时候就会产生一个事件，然后我们可以基于这个事件来完成一个动作 提示： zabbix-agent 起来的时候回去找 Server，这时候就会产生一个事件，然后我们可以基于这个事件来完成一个动作。 我们需要选中，然后在进行创建 如果选项匹配到 Linux，为什么匹配 Linux 呢？ 因为 Linux 可以在输入任何命令都可以生成 [root@linux-node2 ~]# uname Linux [root@linux-node2 ~]# uname -a Linux linux-node2.example.com 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux 提示： 需要点击小的 Add 才可以继续操作 设置操作 我们先点击Add，在选择Host 我们在添加一个主机组，随便选一个就可以。 我们在添加一个模板 解释： 这样设置后我发现你这台主机我会给你设置一个主机组和一个模板。并且是 Linux 最后我们选择 Add 修改完之后我们在 重启 一下 [root@linux-node2 ~]# systemctl restart zabbix-agent.service 如果还没有出来，我们可以稍等一会 自动注册完! ————————分割线———————- 二、自动发现设置 因为我们的服务器只用了 2 台，所以昨晚 自动注册 我们在把它停掉。要不总会影响我们 我们在删除刚刚添加的主机 自动发现可以去扫描 IP 地址范围（需要手动设置）进行发现的动作 官方说明： https://www.zabbix.com/documentation/3.0/manual/discovery/network_discovery 创建 Zabbix 自动发现（生产一般不用） 唯一的标识我们可以设置 IP 地址，或者 key 值 然后我们创建一个Action(动作) 现在它自己就添加上去了 三、API 介绍 Zabbix 提供了一个丰富的 API，Zabbix 提供的 API 有2种功能。 一个是管理 一个是查询 请求方法 POST我们可以进行访问查看 无法打开，我们需要进行 POST 请求才可以。官方说明文档：https://www.zabbix.com/documentation/3.0/manual/api curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;user.login&quot;, &quot;params&quot;: { &quot;user&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;123456&quot; }, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool -d 请求的内容 -H 类型 id 名字，类似一个标识 user 我们登陆用的是 zhangsan 默认是 Admin password 默认是 zabbix，我们修改为 123456 了 [root@linux-node1 ~]# curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; &gt; { &gt; &quot;jsonrpc&quot;: &quot;2.0&quot;, &gt; &quot;method&quot;: &quot;user.login&quot;, &gt; &quot;params&quot;: { &gt; &quot;user&quot;: &quot;zhangsan&quot;, &gt; &quot;password&quot;: &quot;123456&quot; &gt; }, &gt; &quot;id&quot;: 1 &gt; }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool -------------------------- 分割线 ------------------------ 下面是返回的结果！！！！！！！！！！！！！！！！！！！！！！ { &quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot; } 例如：我们获取所有主机的列表 官方文档：https://www.zabbix.com/documentation/3.0/manual/api/reference/host/get curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;host.get&quot;, &quot;params&quot;: {&quot;output&quot;: [&quot;host&quot;] }, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 提示： auth 里面填写的是我们刚刚返回的 result 里面的值, 如果我们在 [&quot;hostid&quot;] 加上 id 就会显示id。想全显示主机名就直接写host [root@linux-node1 ~]# curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;host.get&quot;, &quot;params&quot;: {&quot;output&quot;: [&quot;host&quot;] }, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool { &quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: [ { &quot;host&quot;: &quot;Zabbix server&quot;, &quot;hostid&quot;: &quot;10084&quot; }, { &quot;host&quot;: &quot;linux-node1.example.com&quot;, &quot;hostid&quot;: &quot;10105&quot; }, { &quot;host&quot;: &quot;linux-node1.example.com1&quot;, &quot;hostid&quot;: &quot;10107&quot; }, { &quot;host&quot;: &quot;linux-node2.example.com&quot;, &quot;hostid&quot;: &quot;10117&quot; } ] } 对比图 例如：如何获取模板 官方文档：https://www.zabbix.com/documentation/3.0/manual/api/reference/template/get curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;template.get&quot;, &quot;params&quot;: {&quot;output&quot;: &quot;extend&quot;}, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 默认太多不发了，看图！ 过滤 过滤主机有 OS LINUX 的模板 curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;template.get&quot;, &quot;params&quot;: { &quot;output&quot;: &quot;extend&quot;, &quot;filter&quot;: { &quot;host&quot;: [&quot;Template OS Linux&quot;] } }, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 效果图如下！ 我们提供一个快速认证的 Python 脚本 链接：http://pan.baidu.com/s/1gf0pQwF 密码：m7dq 脚本内容如下 [root@linux-node1 ~]# cat zabbix_auth.py #!/usr/bin/env python # -*- coding:utf-8 -*- import requests import json url = &apos;http://192.168.56.11/zabbix/api_jsonrpc.php&apos; post_data = { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;user.login&quot;, &quot;params&quot;: { &quot;user&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;123123&quot; }, &quot;id&quot;: 1 } post_header = {&apos;Content-Type&apos;: &apos;application/json&apos;} ret = requests.post(url, data=json.dumps(post_data), headers=post_header) zabbix_ret = json.loads(ret.text) if not zabbix_ret.has_key(&apos;result&apos;): print &apos;login error&apos; else: print zabbix_ret.get(&apos;result&apos;) 我们可以执行一下进行查看 提示： 需要修改里面的 用户名 和密码！ # 安装 python 环境 [root@linux-node1 ~]# yum install python-pip -y [root@linux-node1 ~]# pip install requests You are using pip version 7.1.0, however version 8.1.2 is available. You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. Collecting requests Downloading requests-2.11.1-py2.py3-none-any.whl (514kB) 100% |████████████████████████████████| 516kB 204kB/s Installing collected packages: requests Successfully installed requests-2.11.1 ################################################ ################################################ ################################################ 执行结果 [root@linux-node1 ~]# python zabbix_auth.py 5b21317186f2a47404214556c5c1d846 四、案例：使用 API 进行自动添加主机 首先我们需要删除主机和自动发现 我们使用 API 来实现自动添加监控主机 使用 API 添加主机：https://www.zabbix.com/documentation/3.0/manual/api/reference/host/create curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;host.create&quot;, &quot;params&quot;: { &quot;host&quot;: &quot;Zabbix agent 192&quot;, &quot;interfaces&quot;: [ { &quot;type&quot;: 1, &quot;main&quot;: 1, &quot;useip&quot;: 1, &quot;ip&quot;: &quot;192.168.56.12&quot;, &quot;dns&quot;: &quot;&quot;, &quot;port&quot;: &quot;10050&quot; } ], &quot;groups&quot;: [ {&quot;groupid&quot;: &quot;8&quot;} ], &quot;templates&quot;: [ {&quot;templateid&quot;: &quot;10001&quot;} ] }, &quot;auth&quot;: &quot;5b21317186f2a47404214556c5c1d846&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 用户组 ID 获取方法 模板 IP 查看方法 执行结果如下： [root@linux-node1 ~]# curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; &gt; { &gt; &quot;jsonrpc&quot;: &quot;2.0&quot;, &gt; &quot;method&quot;: &quot;host.create&quot;, &gt; &quot;params&quot;: { &gt; &quot;host&quot;: &quot;Zabbix agent 192&quot;, &gt; &quot;interfaces&quot;: [ &gt; { &gt; &quot;type&quot;: 1, &gt; &quot;main&quot;: 1, &gt; &quot;useip&quot;: 1, &gt; &quot;ip&quot;: &quot;192.168.56.12&quot;, &gt; &quot;dns&quot;: &quot;&quot;, &gt; &quot;port&quot;: &quot;10050&quot; &gt; } &gt; ], &gt; &quot;groups&quot;: [ &gt; { &gt; &quot;groupid&quot;: &quot;8&quot; &gt; } &gt; ], &gt; &quot;templates&quot;: [ &gt; { &gt; &quot;templateid&quot;: &quot;10001&quot; &gt; } &gt; ] &gt; }, &gt; &quot;auth&quot;: &quot;5b21317186f2a47404214556c5c1d846&quot;, &gt; &quot;id&quot;: 1 &gt; }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool { &quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: { &quot;hostids&quot;: [&quot;10118&quot;] } } 查看 Zabbix 页面 提示： 里面的主机名 / 模板 都是我们设置好的 Zabbix 完！ 转自：Zabbix 3.0 自动化监控 [十]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 分布式监控 [九]【转】]]></title>
    <url>%2F2016%2F11%2F21%2FZabbix%203.0%20%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7%20%5B%E4%B9%9D%5D%2F</url>
    <content type="text"><![CDATA[Zabbix Proxy是一个类似于代理的服务，可以代替 Zabbix-server 获取 zabbix-agent信息。其中 数据 存到本地（Proxy 有自己的数据库）然后在发送给 Server，这样可以保证数据不丢失 Zabbix-server -----&gt;Zabbix-Proxy -----&gt;Zabbix-Server 地址：https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies Zabbix Proxy 使用场景 常用于多机房情况或者监控主机特别多，几千台左右。这时候使用Zabbix Proxy 可以减轻服务器server 的压力，还可以减轻 Zabbix 的维护。 最常用的特点是适用于 多机房 、 网络不稳定 的时候，因为如果直接由 Zabbix-server 发送信息可能 agent 没有收到，但是直接使用 Zabbix-Proxy 就不会遇到这个问题。 Zabbix 官方说明（分布式监控）Proxy 有如下功能 地址： Distributed monitoring NO - 中文解释 1. 没有 Web 界面 2. 本身不做任何告警通知（告警通知都是 Server 做） 小结： Zabbix Proxy 可以有多个，用来代理 Zabbix server 来运行。Proxy会将所有数据暂存于本地, 然后同一转发到 Zabbix Server 上 Proxy 只需要一条 TCP 链接，可以连接到 Zabbix-server 上即可。所以防火墙只需要添加一条 Zabbix Proxy 即可 我们可以参考上面的Zabbix Proxy 图 Proxy 是需要使用单独的 数据库 ，所以不能将Server 和Agent放在一起 Proxy 说明：https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies 安装文档：https://www.zabbix.com/documentation/3.0/manual/installation/install 官方文档使用的是源码安装，因为方便我们使用 yum 安装，因为我们只有 2 台，所以就用 agent 当做 Proxy [root@linux-node2 ~]# yum install -y zabbix-proxy zabbix-proxy-mysql mariadb-server 我们需要启动 MySQL [root@linux-node2 ~]# systemctl start mariadb.service 我们还需要创建一个库 mysql create database zabbix_proxy character set utf8; grant all on zabbix_proxy.* to zabbix_proxy@localhost identified by &apos;zabbix_proxy&apos;; 我们需要导入数据 [root@linux-node2 ~]# cd /usr/share/doc/zabbix-proxy-mysql-3.0.5/ [root@linux-node2 zabbix-proxy-mysql-3.0.5]# zcat schema.sql.gz | mysql -uzabbix_proxy -p zabbix_proxy Enter password: #密码是：zabbix_proxy 是我们数据库授权的密码 检查数据库 mysql show databases; use zabbix_proxy; show tables; #查看是否含有数据 我们需要修改 proxy 的配置文件 [root@linux-node2 zabbix-proxy-mysql-3.0.5]# vim /etc/zabbix/zabbix_proxy.conf Server=192.168.56.11 Hostname=Zabbix proxy DBName=zabbix_proxy #数据库名称 DBUser=zabbix_proxy #用户名 DBPassword=zabbix_proxy #用户密码 配置文件中没有配置的内容如下：（有需要可以配置） # ProxyLocalBuffer=0 #数据保留的时间（小时为单位） # ProxyOfflineBuffer=1 #连不上 Server，数据要保留多久（小时为单位，默认 1 小时） # DataSenderFrequency=1 #数据的发送时间间隔（默认是 1 秒） # StartPollers=5 #启动的线程数 # StartIPMIPollers=0 #启动 IPMI 的线程数 从这往下都是性能的监控，就不一次说明了。 上面都有中文注释 过滤修改过的配置如下： [root@linux-node2 zabbix-proxy-mysql-3.0.5]# grep &apos;^[a-Z]&apos; /etc/zabbix/zabbix_proxy.conf Server=192.168.56.11 Hostname=Zabbix proxy LogFile=/var/log/zabbix/zabbix_proxy.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_proxy.pid DBName=zabbix_proxy DBUser=zabbix_proxy DBPassword=zabbix_proxy SNMPTrapperFile=/var/log/snmptrap/snmptrap.log Timeout=4 ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 启动 [root@linux-node2 ~]# systemctl start zabbix-proxy 查看 proxy 进程 [root@linux-node2 ~]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:33060.0.0.0:* LISTEN 15685/mysqld tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 15924/zabbix_proxy tcp6 0 0 :::44589:::*LISTEN 9052/java tcp6 0 0 :::8080 :::*LISTEN 9052/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 :::8888 :::*LISTEN 9052/java tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::39743:::*LISTEN 9052/java tcp6 0 0 :::10051:::*LISTEN 15924/zabbix_proxy tcp6 0 0 127.0.0.1:8005 :::*LISTEN 9052/java tcp6 0 0 :::8009 :::*LISTEN 9052/java Zabbix-proxy 监控 10051 端口，因为是代理就必须跟 Server 的端口相同，对于 Agent Proxy 就是 Server Zabbix Web 添加 点击 Add 即可 我们需要将这台主机的 Server 设置为 Proxy编辑 192.168.56.12 这台主机，需要将 Server 的IP 地址修改成自己的 因为现在是主动模式，我们只需要修改主动模式的 Server 即可 [root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf ServerActive=192.168.56.12 #配置文件修改完需要重启 [root@linux-node2 ~]# systemctl restart zabbix-agent 这时候我们就可以看到那个 proxy 都管理了那些机器, 做到方便管理的机制 proxy 简单的理解就是一个 Server 完！ 转自：Zabbix 3.0 分布式监控 [九]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 主备模式 [八]【转】]]></title>
    <url>%2F2016%2F11%2F20%2FZabbix%203.0%20%E4%B8%BB%E5%A4%87%E6%A8%A1%E5%BC%8F%20%5B%E5%85%AB%5D%2F</url>
    <content type="text"><![CDATA[监控常遇到的问题？ 1. 监控主机多，性能跟不上，延迟大 2. 多机房，防火墙因素 Zabbix 轻松解决以上问题，Nagios 不太好解决的问题。 Zabbix 模式介绍： 1、被动模式 2、主动模式 默认是被动模式，我们可以通过以下方式查看监控项是什么模式 因为我们使用的是模板，无法进行修改。我们可以修改配置文件或者新建 item 的时候设置。 注意： 1、当监控主机超过 300+，建议使用主动模式（此处是一个经验值，要根据服务器的硬件来进行考虑） 2、还需要保证 Queue 对列里面没有延迟的主机 Queue 对列介绍 如果此处的延迟主机有点多的话，我们就需要将被动模式修改为主动模式. 主动模式设置 将 192.168.56.12 监控设置为主动模式 1、修改配置文件 为了方便模拟，我们将 node2(192.168.56.12)从 Zabbix 删除从新添加 [root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf #Server=192.168.56.11 #我们需要注释 Server，因为这个是被动模式用的 StartAgents=0 #设置为 0 之后就不会 TCP 端口，之前监听 TCP 端口是因为 Server 要去问 agent 信息所以需要开启 ServerActive=192.168.56.11 #此处可以是 IP 或者是域名，他会连接 10051 端口 Hostname=linux-node2.example.com #唯一识别符，我们需要修改成我们本机的主机名。如果我们不设置，它默认会通过 item 来获取 [root@linux-node2 ~]# systemctl restart zabbix-agent.service 保存重启 保存重启之后我们可以查看我们监听的一些端口，因为我们关闭的被动模式所以不会在监听 zabbix 端口了 [root@linux-node2 ~]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp6 0 0 :::44589:::*LISTEN 9052/java tcp6 0 0 :::8080 :::*LISTEN 9052/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 :::8888 :::*LISTEN 9052/java tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::39743:::*LISTEN 9052/java tcp6 0 0 127.0.0.1:8005 :::*LISTEN 9052/java tcp6 0 0 :::8009 :::*LISTEN 9052/java 我们可以查看日志，进行检查 [root@linux-node2 ~]# tailf /var/log/zabbix/zabbix_agentd.log 14932:20161011:084303.210 **** Enabled features **** 14932:20161011:084303.210 IPv6 support: YES 14932:20161011:084303.210 TLS support: YES 14932:20161011:084303.210 ************************** 14932:20161011:084303.210 using configuration file: /etc/zabbix/zabbix_agentd.conf 14932:20161011:084303.210 agent #0 started [main process] 14933:20161011:084303.227 agent #1 started [collector] 14934:20161011:084303.227 agent #2 started [active checks #1] 14934:20161011:084303.271 no active checks on server [192.168.56.11:10051]: host [linux-node2.example.com] not found 14934:20161011:084503.415 no active checks on server [192.168.56.11:10051]: host [linux-node2.example.com] not found 日志解释： zabbix—agent设置完主动模式后，会去主动问 server 需求。相当于入职刚入职运维需要老大进行分配任务。并且以后就会根据这个任务清单进行执行 因为我们还没有配置server，所以现在会出现错误 Zabbix-web 设置 我们需要添加 zabbix-agent 添加模板 ，zabbix 没有提供主动模式的模板。所以我们需要克隆一下 OS Linux 找到 OS Linux 模板，移动到最下面 点击复制 我们从新进行设置名称 修改我们刚刚添加的模板名为OS Linux Active 我们点击刚刚创建模板的 item 然后选择最下方 Update 结果如下： 在次查看模板，发现 zabbix 还依赖一个模板。我们需要把它也改了或者是删掉。 我们添加主机 添加模板 # 提示：我们已经可以获取到数据了，但是发现 zabbix 这个模块发红。可能是由于我们没有修改他的依赖造成的 如下图： 可能是通过 agent.ping 来获取信息, 没有看过源码 所以不太清楚，我研究它 zabbix 主备模式完成 转自：Zabbix 3.0 主备模式 [八]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 监控 MySQL [六]【转】]]></title>
    <url>%2F2016%2F11%2F15%2FZabbix%203.0%20%E7%9B%91%E6%8E%A7MySQL%20%5B%E5%85%AD%5D%2F</url>
    <content type="text"><![CDATA[Mysql 监控 zabbix 自带了一个监控 mysql 的模板，但是真正监控 mysql 的并不是 zabbix 自带的模板。而是 percona 公司的一个监控 mysql 模板 percona 官网： www.percona.com Percona 组成介绍 1、php 脚本 用来数据采集2、shell 脚本 用来调用采集信息3、zabbix 配置文件4、zabbix 模板文件 安装文档：https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html percona 利用的是 php 来获取 mysql 的相关信息，所以如果我们想使用 percona 插件监控 mysql 就需要在 agent 端安装php。在安装文档上有写哦~ 安装步骤： 查看上面的链接也可以进行安装 我们安装在 zabbix-server 上，因为上面有一个 MySQL [root@linux-node1 web]# yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm [root@linux-node1 web]# yum install percona-zabbix-templates php php-mysql -y #percona 插件是通过 php 去获取 mysql 的参数，所以我们要安装 php 和 php-mysql 我们可以查看它都安装了那些软件 [root@linux-node1 web]# rpm -ql percona-zabbix-templates /var/lib/zabbix/percona /var/lib/zabbix/percona/scripts /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh #shell 脚本 /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php #php 获取 mysql 信息 /var/lib/zabbix/percona/templates /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf #zabbix 配置文件 /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml #zabbix 模板文件 在 percona 组成我们已经说过了，此处只是略微介绍。 我们将 zabbix 模板下载下来 [root@linux-node1 web]# sz /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml 然后我们需要将模板通过 web 界面导入到 zabbix 中 提示：如果出现错误，可能是 zabbix 3.0 版本的问题。我们这里提供了一个生产的模板 下载链接： https://pan.baidu.com/s/1TgsPR3qjWyxjwKYQrz6fWQ密码:u09h 然后从新上传即可 复制配置文件 [root@linux-node1 web]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/ [root@linux-node1 web]# ls /etc/zabbix/zabbix_agentd.d/ #安装完软件包后会在 /var/lib/zabbix/percona/templates/ 目录下产生一个配置文件，我们将它拷贝，因为在前面的博文中，我们已经修改过 zabbix 的配置文件[Include=/etc/abbix/zabbix_agentd.d/] 所以将配置文件放在这个目录下，zabbix 就会自己在这个目录下查找相关信息 [root@linux-node1 web]# systemctl restart zabbix-agent.service 重启一下！ 下面就应该配置与 MySQL 的连接 在/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf创建一个文件 [root@linux-node1 ~]# cat /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf &lt;?php $mysql_user = &apos;root&apos;; $mysql_pass = &apos;&apos;; #用户名密码可以自己创建，有密码写密码，没密码为空就好了 提示： 正常这里的用户我们应该创建一个专门用来监控的，由于我这里是测试环境。就不浪费时间了 测试 查看是否可以获取到值，随便找一个测试 [root@linux-node1 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf 选择一个肯定有值的 key [root@linux-node1 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf|grep gm UserParameter=MySQL.read-views,/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gm 测试结果如下： [root@linux-node1 ~]# cd /var/lib/zabbix/percona/scripts/ [root@linux-node1 scripts]# ./get_mysql_stats_wrapper.sh gm 1 [root@linux-node1 scripts]# ./get_mysql_stats_wrapper.sh gw 9736342 可以获取到值，说明没有问题 温馨提示： shell 脚本中数据库的路径是 localhost，如果我们没有授权 localhost 会获取不到值 [root@linux-node1 scripts]# cat get_mysql_stats_wrapper.sh HOST=localhost RES=`HOME=~zabbix mysql -e &apos;SHOW SLAVE STATUS\G&apos; | egrep &apos;(Slave_IO_Running|Slave_SQL_Running):&apos; | awk -F: &apos;{print $2}&apos; | tr &apos;\n&apos; &apos;,&apos;` #mysql 是通过命令来获取的，如果环境变量不一样 也可能造成影响 Zabbix_Web 界面配置 模板已经上传到 zabbix 中，这时候我们就需要进行设置了 提示： 我们还需要授权 /tmp 下的一个文件，因为默认情况下 zabbix 在文件中获取的值 修改完就可以获取值了，所以我们还需要测试 结果如下图 思想： 如果出现错误我们需要先查看 shell 的脚本，因为 shell 是去调用 php。 错误的因素有很多，最简单的方法就是用 shell 后面加上 key 看看是否可以有值。 其中报错最多的地方就是 php 和 mysql 连接的问题，还有我们 mysql 授权的一些问题。 MYSQL 监控 完！ 转载自：Zabbix 3.0 监控 MySQL [六]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 监控 Web [七]【转】]]></title>
    <url>%2F2016%2F11%2F15%2FZabbix%203.0%20%E7%9B%91%E6%8E%A7Web%20%5B%E4%B8%83%5D%2F</url>
    <content type="text"><![CDATA[Zabbix 默认自带一个 web 监控 我们可以从 Monitoring---&gt;Web 进行查看 按照前面的文章，我们在 192.168.56.12 上面已经开启了一个 Tomcat 端口为 8080. 如果没有的小伙伴可以阅读 [Zabbix 3.0 生产案例 [四] 一、检查 首先我们需要检查 192.168.56.12 是否有 tomcat，是否可以运行。能否访问 1. 查看进程 [root@linux-node2 ~]# ps -ef|grep java root 8048 25468 0 10:31 pts/000:00:00 grep --color=auto java root 42757 1 0 Sep26 pts/000:38:59 /usr/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8888 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=192.168.56.12 -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start 2. 查看端口 [root@linux-node2 ~]# lsof -i:8080 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java42757 root 48u IPv6 379379 0t0 TCP *:webcache (LISTEN) 3. 测试是否可以访问 8080 端口 [root@linux-node2 ~]# curl -I 192.168.56.11:8080 HTTP/1.1 200 OK Server: nginx/1.10.1 Date: Mon, 10 Oct 2016 05:08:18 GMT Content-Type: text/html Content-Length: 612 Last-Modified: Mon, 19 Sep 2016 01:59:49 GMT Connection: keep-alive ETag: &quot;57df4695-264&quot; Accept-Ranges: bytes 二、Zabbix Web 界面配置 提示： 监控 Web 不依赖于 agent，是server 直接发送请求的 提示： 这里名字叫做 Web 场景，因为我们可以设置触发上面 3 个选项后，才进行报警 提示： 字符串里面可以添加一些字符串，当请求下来有这个字符串就是正常，没有就是不正常。但是最常用的还是状态 然后我们选择Add 比较坑的一点是，我们新添加了一个 Web 监控。zabbix 默认没有给我们安装触发器 三、触发器添加 Web 监控中默认不含有触发器，所以需要手动添加 点右上角，进行创建触发器 四、触发器报警测试1、停掉 tomcat，要想返回值不是 200 停掉 tomcat 是最简单的 [root@linux-node2 ~]# /usr/local/tomcat/bin/shutdown.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 检查 [root@linux-node2 ~]# ps aux|grep tomcat root 8723 0.0 0.0 112648 976 pts/1R+ 12:21 0:00 grep --color=auto tomcat 报警如下： 回复如上 邮件报警设置可以访问 Zabbix 3.0 生产案例 [五]我们还可以优化动作[Actions] Zabbix 就是一个万能的什么都可以监控，只要我们有 key。什么都可以监控key 我们可以使用脚本，程序等等等 转自：Zabbix 3.0 监控 Web [七]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 生产案例 [五]【转】]]></title>
    <url>%2F2016%2F11%2F12%2FZabbix%203.0%20%E7%94%9F%E4%BA%A7%E6%A1%88%E4%BE%8B%20%5B%E4%BA%94%5D%2F</url>
    <content type="text"><![CDATA[上面我们说到了监控 TCP 和 Nginx 状态，但是光是监控是没有任何作用的。监控完我们不知道跟没监控没啥区别，下面我们进行 监控项 的讲解 1. 触发器 首先我们给 Nginx 添加触发器1. 选择Configuration---&gt;Hosts 2. 找到我们相对应的主机进入 3. 选择主机中的 Triggers—&gt; 添加(Create trigger) 我们设置一个事件 我们选择 Insert，然后选择Add 即可 4. 查看报警状态 因为我们设置的级别大于 1 就报警，默认 Nginx 是 0，随便访问以下就是 1. 所以肯定就会报警。报警邮件可以根据我们前面 [Zabbix 3.0 部署监控 [三]]文章进行设置 报警邮件如下： 我们可以查看这个事件的相关过程 以上就是我们添加的一个触发器报警步骤 Zabbix 默认触发器的预值比较低，我们需要调大。这个在面试过程中会被问到 我们进行修改默认模板 路径下图： 我们可以看到默认是大于 300 进行报警, 我们点进去修改即可 根据实际情况进行修改，我们设置 600 即可。同时触发器支持多个条件进行报警，如 or all 等，只需要在上面的值后面继续添加即可。 我们修改完之后 还有一个有警告显示磁盘不够，因为是虚拟机我们不予理会，我们可以查看到恢复之后的邮件 2. 脚本发送邮件 提示： Zabbix 邮件报警是 3.0 才有的，以前不支持用户名密码。所以早期都是使用脚本进行发送邮件报警。 由于时间关系我们就不进行写了请下载发送邮件的 python 脚本：链接：http://pan.baidu.com/s/1gfkGrgZ 密码：6bsh 脚本注释： Python 脚本中三个相关的参数 receiver = sys.argv[1] #收件人地址 subject = sys.argv[2] #发送邮件的主题 mailbody = sys.argv[3] #发送邮件的内容 smtpserver = &apos;smtp.exmail.qq.com&apos; #邮件服务器地址，本脚本使用的是企业邮箱 username = &apos;username&apos; #用户名 password = &apos;password&apos; #密码 sender = username #发送人名称 我们如果要写一个发送邮件的脚本，需要支持三个参数 1、收件人 2、标题 3、内容 自定义告警脚本 我们也可以使用shell 写一个最简单的 脚本存放路径：我们可以在配置文件中查看 [root@linux-node1 web]# vim /etc/zabbix/zabbix_server.conf AlertScriptsPath=/usr/lib/zabbix/alertscripts 提示： 这行配置文件定义了邮件脚本的存放路径，因为它默认会从 usr/lib/zabbix/alertscripts 查找邮件脚本 [root@linux-node1 web]# vim /usr/lib/zabbix/alertscripts/sms.sh #!/bin/bash ALTER_TO=$1 ALTER_TITLE=$2 ALTER_BODY=$3 echo $ALTER_TO &gt;&gt; /tmp/sls.log echo $ALTER_TITLE &gt;&gt; /tmp/sms.log echo $ALTER_BODY &gt;&gt; /tmp/sms.log 我们可以写完之后进行检测，如果这里有信息说明已经调用这个脚本。 如果我们有短信通道将里面的内容换一下即可，短信通道都是有售后的 修改权限 [root@linux-node1 web]# chmod +x /usr/lib/zabbix/alertscripts/sms.sh [root@linux-node1 web]# ll /usr/lib/zabbix/alertscripts/sms.sh -rwxr-xr-x 1 root root 152 Oct 8 20:26 /usr/lib/zabbix/alertscripts/sms.sh 我们写的脚本是短信报警，首先你需要有一个短信通道，我们可以使用阿里云大鱼，本次我们使用文件追加的形式来模拟. Zabbix 页面设置 点击右上角创建报警介质 点击最下面的 Add 提示：先点击小的 Update 在点最下面的Update 我们还需要修改报警媒介 找到相对应的用户，点击。 接下来就需要我们触发报警了 上面我们设置的连接数是大于 1，所以我们多刷新几次就可以了 这里显示发送完成，我们去日志进行查看 13122323232 为发送的手机号 PROBLEM： 为主题信息 Nginx Active 监控项 Original……..：为故障信息，2 代表连接数是 2 提示： 因为中国的短信收费是 70 个字符 2 毛，字母也算是。所以我们发送邮件的报警信息就需要简介明了一点 优化图如下： 修改后如下： 设置完成之后最好数一下，不要超过 70 个字符 http://www.alidayu.com/ 有兴趣的同学可以自己了解一下阿里大鱼，可以提供短信通道、语音、验证码等业务。 短信通道比较出名的几款产品： 亿美软通 阿里大鱼 腾讯云也有 微信报警 短信报警和邮件报警已经说过了，我们简单的说一下微信报警 因为在很早之前就说过，个人服务号和订阅号不支持直接跟订阅用户进行沟通。如果是企业号可以直接获取到一个类似 key，拿着这个 key 直接 curl 就可以了发了。 具体内容可以进行百度或者谷哥搜索。 扩展： 除了以上三种报警，还有 钉钉报警 以前还有 QQ 报警、 飞信报警，但是现在已经不开源了 提示： 上面那三行最好不要删除，在生产环境中追加到一个文件中。记录发送邮件的信息 转载自：Zabbix 3.0 生产案例 [五]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 生产案例 [四]（转）]]></title>
    <url>%2F2016%2F11%2F10%2FZabbix%203.0%20%E7%94%9F%E4%BA%A7%E6%A1%88%E4%BE%8B%20%5B%E5%9B%9B%5D%2F</url>
    <content type="text"><![CDATA[Zabbix 生产案例实战 一、项目规划 1、主机分组： 交换机 Nginx Tomcat MySQL 2、监控对象识别： 1、使用 SNMP 监控交换机 2、使用 IPMI 监控服务器硬件 3、使用 Agent 监控服务器 4、使用 JMX 监控 Java 应用 5、监控 MySQL 6、监控 Web 状态 7、监控 Nginx 状态 3、操作步骤：SNMP 监控 1.1 在交换机上开启Snmpconfig t snmp-server community public ro end 提示：如果不知道我们可以百度 ####1.2 在 Zabbix 上添加SNMP 监控 步骤：Configuration---&gt;Hosts---&gt; 设置 1.3 Host 页面设置 1.4 Templates 模板设置 设置 SNMP 团体名称 Macros 宏 这里的设置要跟我们创建的 SNMP 的设置相同 因为 Zabbix 监控的时候依赖团体名称 1.5 生产图片 Zabbix 会自动给我们进行检测端口，每个端口都会添加一个网卡的流量图，每个端口都会加上一个触发器。（端口的状态 ） 还会帮我们添加VLAN 的一个监控 1.6 案例图 含有有进口和出口流量 提示：此图是 Zabbix SNMP 模板自动生成的 IPMI 监控 2.1 添加 IPMIConfiguration---&gt;Hosts---&gt; 选择主机 ---&gt; 设置 IPMI 端口及主机 ---&gt; 用户名密码 因为 IMP 容易超时，建议使用自定义 item，本地执行ipmitool 命令来获取数据 JMX 监控 Zabbix 默认提供了一个监控 JMX, 通过 java gateway 来监控 java 地址：https://www.zabbix.com/documentation/3.2/manual/appendix/config/zabbix_java JAVA GATEWAY需要独立安装，相当于一个网关，因为 zabbix_server 和 zabbix-agent 不可以直接获取 java 信息。所以需要一个代理来获取 zabbix java Gateway不存任何数据, 只是一个简单的代理 1、安装[root@linux-node1 ~]# yum install -y zabbix-java-gateway java-1.8.0 提示：java-gateway 需要 java 环境 2、配置 修改 java-gateway [root@linux-node1 ~]# vim /etc/zabbix/zabbix_java_gateway.conf # LISTEN_IP=&quot;0.0.0.0&quot; 监听的 IP 地址 # LISTEN_PORT=10052 监听的端口 PID_FILE=&quot;/var/run/zabbix/zabbix_java.pid&quot; 存放 pid 路径 # START_POLLERS=5 开通几个进程, 默认是 5。你有多少 java 进行可以设置多少个，也可以设置 java 进程的一半。 TIMEOUT=3 超时时间 1-30，如果网络环境差，超时时间就修改长一点 我们默认就可以了，不进行修改 3、启动[root@linux-node1 ~]# systemctl start zabbix-java-gateway.service 4、端口、进程查看 我们可以进行进程的查看 [root@linux-node1 ~]# netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:33060.0.0.0:* LISTEN 10439/mysqld tcp0 0 0.0.0.0:80800.0.0.0:* LISTEN 33484/nginx: master tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1054/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2484/master tcp0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 76482/zabbix_agentd tcp0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 34572/zabbix_server tcp0 0 127.0.0.1:199 0.0.0.0:* LISTEN 11143/snmpd tcp6 0 0 :::80 :::*LISTEN 10546/httpd tcp6 0 0 :::22 :::*LISTEN 1054/sshd tcp6 0 0 ::1:25 :::*LISTEN 2484/master tcp6 0 0 :::10050:::*LISTEN 76482/zabbix_agentd tcp6 0 0 :::10051:::*LISTEN 34572/zabbix_server tcp6 0 0 :::10052:::*LISTEN 13465/java 10052 zabbix-java-gateway默认端口已经起来了！ 它是一个 java 应用，需要安装 jdk [root@linux-node1 ~]# ps -aux|grep java root 13465 0.4 3.4 2248944 34060 ? Sl 19:17 0:01 java -server -Dlogback.configurationFile=/etc/zabbix/zabbix_java_gateway_logback.xml -classpath lib:lib/android-json-4.3_r3.1.jar:lib/logback-classic-0.9.27.jar:lib/logback-core-0.9.27.jar:lib/slf4j-api-1.6.1.jar:bin/zabbix-java-gateway-3.0.4.jar -Dzabbix.pidFile=/var/run/zabbix/zabbix_java.pid -Dzabbix.timeout=3 -Dsun.rmi.transport.tcp.responseTimeout=3000 com.zabbix.gateway.JavaGateway root 13584 0.0 0.0 112648 972 pts/0S+ 19:21 0:00 grep --color=auto java 5、通知 zabbix-server 我们需要通知 zabbix-server，java-gateway 在哪里 修改配置文件 [root@linux-node1 ~]# vim /etc/zabbix/zabbix_server.conf 编辑 zabbix-server 来指定 zabbix-java-gateway JavaGateway=192.168.56.11 #IP 地址是安装 java-gateway 的服务器 # JavaGatewayPort=10052 端口，默认就可以 StartVMwareCollectors=5 预启动多少个进程[zabbix---&gt;java-gateway 的数量] 6、重启 zabbix-server[root@linux-node1 ~]# systemctl restart zabbix-server.service 7、准备 apache我们安装 tomcat-8 版本 官网：http://tomcat.apache.org下载软件包 [root@linux-node2 src]# wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.5/bin/apache-tomcat-8.5.5.tar.gz 我们将 tomcat 安装在 apache 服务器上，来模拟监控 jvm [root@linux-node2 src]# tar xf apache-tomcat-8.5.5.tar.gz [root@linux-node2 src]# mv apache-tomcat-8.5.5 /usr/local/ [root@linux-node2 src]# ln -s /usr/local/apache-tomcat-8.5.5/ /usr/local/tomcat [root@linux-node2 src]# yum install -y java-1.8.0#tomcat 需要在 java 环境运行 [root@linux-node2 src]# /usr/local/tomcat/bin/startup.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar Tomcat started. 在 web2 上面查看运行状态 [root@linux-node2 src]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 10088/zabbix_agentd tcp6 0 0 :::8080 :::*LISTEN 25750/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::10050:::*LISTEN 10088/zabbix_agentd tcp6 0 0 127.0.0.1:8005 :::*LISTEN 25750/java tcp6 0 0 :::8009 :::*LISTEN 25750/java JMX 三种类型： 1. 无密码认证 2. 用户面密码认证 3.ssl 开启 JMX 远程监控 官方文档：http://tomcat.apache.org/tomcat-8.0-doc/monitoring.html我们创建一个无密码认证 [root@linux-node2 src]# vim /usr/local/tomcat/bin/catalina.sh CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8888 #端口号 -Dcom.sun.management.jmxremote.ssl=false #SSL 关闭 -Dcom.sun.management.jmxremote.authenticate=false #用户密码验证关闭 -Djava.rmi.server.hostname=192.168.56.12&quot; #监控的主机 修改完成后重启 tomcat 可以使用 ./shutdown.sh 或者使用kill 的方式 [root@linux-node2 src]# /usr/local/tomcat/bin/shutdown.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 中间可以使用 px -aux|grep java 查看是否被杀死 [root@linux-node2 src]# /usr/local/tomcat/bin/startup.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar Tomcat started. 我们 JMX 端口设置为 8888 [root@linux-node2 src]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 10088/zabbix_agentd tcp6 0 0 :::8080 :::*LISTEN 26226/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 :::8888 :::*LISTEN 26226/java tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::10050:::*LISTEN 10088/zabbix_agentd tcp6 0 0 :::38532:::*LISTEN 26226/java tcp6 0 0 127.0.0.1:8005 :::*LISTEN 26226/java tcp6 0 0 :::8009 :::*LISTEN 26226/java tcp6 0 0 :::38377:::*LISTEN 26226/java 我们可以在 windows 上面安装 jdk ，使用命令行来监控 java 我们下载安装，具体步骤不说了，然后我们找到 jconsole.exe 文件运行 填写安装 JMX 的服务器 因为在配置文件中我们设置的是无密码认证，所以这里不需要输入密码直接连接。端口号我们设置的是 8888 连接即可 这样我们就可以在图形化监控 tomcat 提示：按照现在观察，java-gateway 已经安装成功，我们可以加入到 zabbix 中 找我们要添加的主机 填写安装 java-gateway 的主机 我们还需要设置一个模板 这个模板就是我们自带的一个监控 JMX 的模板，然后我们点击Update. 更新 我们需要等待一会才可以出图 提示：可以在 Zabbix-server 上使用 zabbix-get 获取某一台机器的某一个 key , 效果图如下：需要等待一会 手动检测监控状态 Zabbix-Server 操作： [root@linux-node1 ~]# yum install -y zabbix-get Key： 我们随便找一个 key，然后我们复制后面的 key [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k jmx[&quot;java.lang:type=Runtime&quot;,Uptime] ZBX_NOTSUPPORTED: Unsupported item key. 提示：未支持的 key，现在并不能获取到这个 key 因为没有获取到这个值，所以不会显示。我们可以获取别的试一下 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.079323 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.075377 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.075377 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.073547 小结： Zabbix 其实就是通过 zabbix_get 获取到的这个值进行比较的 日志 开启 zabbix debug 模式 [root@linux-node2 tomcat]# systemctl restart zabbix-agent ### Option: DebugLevel # Specifies debug level: # 0 - basic information about starting and stopping of Zabbix processes # 1 - critical information # 2 - error information # 3 - warnings # 4 - for debugging (produces lots of information) # 5 - extended debugging (produces even more information) DebugLevel=4 如果及别是 4 就是 debug 模式，修改完配置文件之后需要重启生效 Zabbix 生产案例1. 开启 Nginx 监控 2. 编写脚本来进行数据采集 3. 设置用户自定义参数 4. 重启 zabbix-agent 5. 添加 item 6. 创建图形 7. 创建触发器 8. 创建模板 实践步骤 脚本编写： 我们这里提供已经写好的脚本, 链接：https://pan.baidu.com/s/19JrCetaRZYGY_mvq4CyoJQ 密码：94us 需要修改一下 zabbix-agent 的配置文件 vim /etc/zabbix/zabbix_agentd.conf 修改 Include 设置, 这样我们可以把脚本放在这个目录下。配置就是.conf 结尾 Include=/etc/zabbix/zabbix_agentd.d/*.conf 3. 添加权限及测试脚本 [root@linux-node1 zabbix_agentd.d]# chmod +x zabbix_linux_plugin.sh [root@linux-node1 zabbix_agentd.d]# sh zabbix_linux_plugin.sh Usage: zabbix_linux_plugin.sh {tcp_status key|memcached_status key|redis_status key|nginx_status key} 提示： 这个脚本要用 zabbix 用户执行的权限，因为都是 zabbix 用户在执行，监控 TCP 会在 /tmp/ 目录生成一个文件用于监控使用 4. 修改 nginx 配置文件 提示：nginx 默认路径是 /usr/local/nginx 编译安装需要查看安装路径 [root@linux-node1 zabbix_agentd.d]# vim /usr/local/nginx/conf/nginx.conf location /nginx_status { stub_status on; allow 127.0.0.1; access_log off; } 因为脚本的 url 是 nginx_status 所以我们配置文件也要这样修改 测试脚本 [root@linux-node1 zabbix_agentd.d]# curl 192.168.56.11:8080/nginx_status Active connections: 1 server accepts handled requests 2823682 2823682 2821835 Reading: 0 Writing: 1 Waiting: 0 [root@linux-node1 zabbix_agentd.d]# ./zabbix_linux_plugin.sh nginx_status 8080 active 1 [root@linux-node1 zabbix_agentd.d]# ./zabbix_linux_plugin.sh nginx_status 8080 reading 0 [root@linux-node1 zabbix_agentd.d]# ./zabbix_linux_plugin.sh nginx_status 8080 handled 2823688 设置 Key，首先是Key 的名称 [root@linux-node1 zabbix_agentd.d]# cat linux.conf UserParameter=linux_status[*],/etc/zabbix/zabbix_agentd.d/zabbix_linux_plugin.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot; [*]代表一个传参，可以将后面的 $1,$2,$3 引入进行 ，后面是脚步本的路径 需要重启 agent [root@linux-node1 zabbix_agentd.d]# systemctl restart zabbix-agent 我们使用 zabbix_get 进行测试 [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -k linux_status[nginx_status,8080,active] 1 [-k] 就是指定 key 不细说了 [*] * 的作用在 web 界面配置 item 会显示出来 5.Zabbix web 界面设置 我们需要添加 item，因为要加好多。我们就使用模板的方式进行添加 提示：我们写一下注释然后选择 Add 即可 找到我们的模板 我们创建 item 创建 各参数前文都有讲解不细说！ 修改完成吼点击 Add 添加完成后我们要复制很多个用来监控 Nginx status 的所有状态，所以我们使用克隆。来克隆多个进行设置 点进我们的 item，然后拖到最下面选择克隆 填一些基本的修改即可，例如下： 添加完成如下图： item 添加完成我们还需要添加一个图形，用于展示，找到图形路径。点击创建 因为我们主机还没有加入我们的模板，所以我们这里是没有数据的 下面将模板加入到主机中 修改模板 查看结果如下： 6. 导出模板 因为设置模板比较麻烦，我们可以将模板导出 导出之后我们需要修改名称就可以了 7. 导入模板 我们需要导出自然需要导入，操作如下： 点击添加即可 提示： 模板之间的名称不可以相同 以上就是 Nginx 完整的监控使用8. 导入 TCP 模板 加入模板的步骤跟刚刚加入 Nginx 的一样，这里我们就使用模板了。下载链接：http://pan.baidu.com/s/1i54ULjJ 密码：25lh我们导入模板即可 导入完成之后我们可以查看模板 在里面我们可以见到 TCP 的 11 种状态，这个 item 是我们需要根据我们脚本进行同步的。 我们可以随便点击一个进行查看，其中这里的 key 要和脚本的相同 我们在两台服务器都加载这个模板 步骤和上面的一样 添加完成 查看脚本需要等待 1 分钟，这主要看我们设置的获取值的时间而定。我们可以查看图形 更多内容请看下集！~ 转载自：Zabbix 3.0 生产案例 [四]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 字符集乱码及 Centos7 补全设置 [转]]]></title>
    <url>%2F2016%2F11%2F10%2FZabbix%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B9%B1%E7%A0%81%E5%8F%8ACentos7%E8%A1%A5%E5%85%A8%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Centos 补全安装软件包 [root@linux-node1 ~]# yum install -y bash-completion 从新打开窗口即可 操作： 1. 找到本地 C:\Windows\Fonts\simkai.ttf（楷体）上传到服务器 zabbix 网站目录 fonts 目录下。 [root@localhost /]# whereis zabbix zabbix: /usr/lib/zabbix /etc/zabbix /usr/share/zabbix [root@localhost /]# cd /usr/share/zabbix [root@localhost zabbix]# ll |grep fonts drwxr-xr-x. 3 root root75 Jun 12 14:04 fonts [root@localhost zabbix]# cd fonts/ [root@localhost fonts]# ll total 30176 drwxr-xr-x. 2 root root 26 Jun 12 14:01 fonts_bak -rw-r--r--. 1 root root 720012 Jun 12 14:03 graphfont.ttf -rw-r--r--. 1 root root 11785184 Jun 11 2009 simkai.ttf -rw-r--r--. 1 root root 18387092 Jun 12 14:04 uming.ttf [root@localhost fonts]# 2. 修改 zabbix php 配置文件 [root@localhost /]# find -name defines.inc.php ./usr/share/zabbix/include/defines.inc.php [root@localhost fonts]# cd /usr/share//zabbix/ [root@localhost zabbix]# ll |grep include drwxr-xr-x. 4 root root 4096 Jun 12 14:37 include #从网上抄的，不适合本机 sed -i &apos;s/DejaVuSans/simkai/g&apos; ./include/defines.inc.php #自己修改的，做了两次，后发现界面上文字没有了。 sed -i &apos;s/graphfont/simkai/g&apos; ./include/defines.inc.php sed -i &apos;s/fonts/simkai/g&apos; ./include/defines.inc.php #检查 defines.inc.php 文件 [root@localhost zabbix]# vim defines.inc.php #查找到“simkai”关键字，修改 ZBX_FONTPATH&apos;（红色标记部分） // the maximum period to display history data for the latest data and item overview pages in seconds // by default set to 86400 seconds (24 hours) define(&apos;ZBX_HISTORY_PERIOD&apos;, 86400); define(&apos;ZBX_WIDGET_ROWS&apos;, 20); define(&apos;ZBX_FONTPATH&apos;, realpath(&apos;/usr/share/zabbix/fonts/&apos;)); // where to search for font (GD &gt; 2.0.18) define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;simkai&apos;); // font file name /simkai define(&apos;ZBX_FLAG_DISCOVERY_NORMAL&apos;, 0x0); define(&apos;ZBX_FLAG_DISCOVERY_RULE&apos;, 0x1); define(&apos;ZBX_FLAG_DISCOVERY_PROTOTYPE&apos;, 0x2); define(&apos;ZBX_FLAG_DISCOVERY_CREATED&apos;,0x4); define(&apos;EXTACK_OPTION_ALL&apos;, 0); define(&apos;EXTACK_OPTION_UNACK&apos;, 1); define(&apos;EXTACK_OPTION_BOTH&apos;,2); define(&apos;TRIGGERS_OPTION_RECENT_PROBLEM&apos;,1); define(&apos;TRIGGERS_OPTION_ALL&apos;, 2); define(&apos;TRIGGERS_OPTION_IN_PROBLEM&apos;,3); define(&apos;ZBX_ACK_STS_ANY&apos;, 1); define(&apos;ZBX_ACK_STS_WITH_UNACK&apos;,2); define(&apos;ZBX_ACK_STS_WITH_LAST_UNACK&apos;, 3); define(&apos;EVENTS_OPTION_NOEVENT&apos;, 1); define(&apos;EVENTS_OPTION_ALL&apos;, 2); define(&apos;EVENTS_OPTION_NOT_ACK&apos;, 3); define(&apos;ZBX_FONT_NAME&apos;, &apos;simkai&apos;); define(&apos;ZBX_AUTH_INTERNAL&apos;, 0); define(&apos;ZBX_AUTH_LDAP&apos;, 1); define(&apos;ZBX_AUTH_HTTP&apos;, 2); #重启 zabbix 服务 service zabbix-server restart 提示：如果我们找不到配置文件可以使用以下方法 [root@linux-node1 ~]# find / -type f -name &quot;defines.inc.php&quot; /usr/share/zabbix/include/defines.inc.php 将字体导入到 /usr/share/zabbix/fonts 效果图如下 图一，修改前 图一，修改后 转载自：Zabbix 字符集乱码及 Centos7 补全设置]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 部署监控 [三]（转）]]></title>
    <url>%2F2016%2F10%2F11%2FZabbix%203.0%20%E9%83%A8%E7%BD%B2%E7%9B%91%E6%8E%A7%20%5B%E4%B8%89%5D%20%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Dashboard 首页信息介绍 Status of Zabbix（Zabbix 状态）介绍 Zabbix server is running #Zabbix 服务器是否运行 Number of hosts (enabled/disabled/templates) #主机数量（已启用 / 已禁用 / 模板） Number of items (enabled/disabled/not supported) #监控项数量（已启用 / 已禁用 / 不支持） Number of triggers (enabled/disabled [problem/ok]) #触发器数量（已启用 / 已禁用 / 问题 / 正常） Number of users (online) #用户数（线上） Required server performance, new values per second #要求的主机性能，每秒新值 此处需要注意的事项如下：1、需要时刻关注那些主机数量中已禁用的（例如：那一天有一台监控有问题，顺手关闭了。没有打开 结果后期导致监控出现问题） 2、监控项数量里面最好不要放置已禁用，要么删除这个监控项或者不让他报警。尽量不要给他禁用 3、触发器只禁用几个没什么大问题，但是如果一下禁用几十个不方便进行管理 4、正式环境最好划分主机组，可以按照业务划分，类型划分。那个出现问题都方便查看处理 Latest data 最新数据介绍 加入监控 刚刚之前我们一直使用的是一台服务器，因为不方便解释。我们新添加一台服务器 加入监控的几个步骤： 1、安装软件 2、修改配置 1、设置 yum 源[root@linux-node2 ~]# rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm 2、安装软件包[root@linux-node2 ~]# yum install -y zabbix-agent 3、修改配置文件[root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf Server=192.168.56.11 ServerActive=192.168.56.11 #提示：这里的 IP 地址改成 Server 端的 IP 地址 4、启动[root@linux-node2 ~]# systemctl start zabbix-agent[root@linux-node2 ~]# netstat -lntup|grep zabbixtcp0 0 0.0.0.0:10050 0.0.0.0: LISTEN 10088/zabbix_agentdtcp6 0 0 :::10050:::LISTEN 10088/zabbix_agentd 5、web 界面设置 克隆~ 步骤：我们随便点击一个进去。拉到最下面有一个全部克隆 剩下的我们就改一下就可以了 模板修改 其他的就没有什么可以配置的，模板主要是添加 Template OS Linux。然后我们选择Add 即可 创建完成如下： 新添加的 IP 如上述所示 Maps 优化设置 上次只是简单的连接线的设置，这次我们进行深入设置 路径：Monitoring---&gt;Maps---&gt;Edit map进行修改 我们点击 Zabbix server 没有设置主机的，选择Host 修改linux-node2。 提示：此处我们修改了 2 台主机，这个可以根据业务需求进行设置 我们新添加一台，然后进行连接。Ctrl + 主机 然后点击 Link：Add 例如我们想查看他们的 流量带宽 首先，他们必须要连接在一起，然后点击 Links 选项后面的 Edit 进行编辑 我们可以在 Label 表里面写监控项的值 我们可以在 Configuration---&gt;Hosts---&gt;items 中查看到 括号内写入发下： {linux-node2.example.com:net.if.out[eth0].last(0)} linux-node2.example.com= 主机名 net.if.out=key 值 last（0）= 获取最新的一个数据 现在我们就可以实时的监控流量 切记需要update 保存如下图显示 如何让 Zabbix 报警 我们可以先打开Events 查看事件 zabbix 事件有很多类型 Trigger= 触发器的事件 Disovery= 自动发现事件 还有内部的事件以及自动注册的事件 我们可以选择 主机，查看相对应的事件 Zabbix的报警可以当做事件通知，当这个事件发生时。zabbix进行通知（报警） 事件报警分为 2 种方式： 1、怎么通知 2、通知给谁 Zabbix 通知方式：Zabbix 通知方式通过 Actions 进行通知 Zabbix默认有一个，我们可以点开进行查看 条件设置 操作设置 温馨提示：保存的时候需要先点击下方小的 Update 否则就木有啦, 这里的步骤可以让报警邮件发送的级别、例如：先发送给 运维、项目经理、项目总监 等 例如如下： 刚刚的填写完成，现在提示的是 1-2 发送的人 我们可以点击下面的 New 在添加几个 模拟设置，当报警 1-2 次时候发送给 XX，2-4次发送给XX。 依次叠加 我们需要配置报警媒介类型，用于发送邮件 温馨提示：3.0之前发送邮件需要启动邮件相关服务来进行安全认证，3.0之后默认自带安全认证 我们以 qq 邮箱为例 我们还需要配置 用户 的邮箱，因为上面已经选择发送给那个 用户。接下来就改配置用户的邮箱 我们点开之后选择Media（报警媒介进行设置）如果看不懂英文我们可以设置中文 然后我们选择下方的Add 设置收件人地址 小结：步骤就不截图了，可以调成中文，按照步骤来。 1、报警媒介 2、动作（active）配置（操作–编辑） 注意点小的 update 3、创建用户群组（注意权限） 4、创建用户（权限和报警媒介设置）权限只能按照用户组分配（我们可以选择用户 / 管理员 / 超级管理员） 提示：添加新主机后，要注意确认权限分配 我们的使用 QQ 邮箱需要开启 SNMP 和一个授权码。 填写发件人密码时需要设置授权码为密码 邮件结果如下：异常 因为我们开启了正常之后继续发送邮件，所以正常之后邮件如下 提示：当异常时它会一直发邮件，直到服务正常或者匹配规则到时 转载自：Zabbix 3.0 部署监控 [三]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 部署监控 [二]（转）]]></title>
    <url>%2F2016%2F10%2F11%2FZabbix%203.0%20%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%20%5B%E4%BA%8C%5D%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、添加监控主机及设置1. 创建主机 Agent 可以干一些 SNMP 无法干的事情，例如自定义监控项snmp 相关文章：http://www.abcdocker.com/abcdocker/1376 这里我们先不着急点add，还需要设置其他选项 点击监控模板 zabbix 监控是由 监控项 组成（cpu使用率监控就是一个 监控项 / 内存使用率 就是一个监控项），如果是 100 台服务器就需要监控 模板 了。只需要将监控项和模板 关联 起来即可 举个例子：我们上面主机使用的是 SNMP，就可以直接搜索SNMP。提示：有的模板需要自己定义 温馨提示：请点击下面的小add 然后在点大的。否则会出现问题哦 IPMI如果有的话，需要在这里写上 用户名 和密码 宏定义，这个宏其实就是一个变量。我们给可以给变量附一个值 因为我们设置的是 SNMP，SNMP 有一个团体名。并且可以设置定义 团体名是中间的abcdocker，具体的可以看http://www.abcdocker.com/abcdocker/1376 [root@localhost ~]# cat /etc/snmp/snmpd.conf rocommunity abcdocker 192.168.56.11 值：{$SNMP_COMMUNITY} 主机资产设置分为 3 中 1、关闭 Disabled2、手动 Manual3、自动 Automatic （自动代表的是你在定义监控项的时候，他有一个小箭头，勾上之后监控项的值就会填写在这里） 我们这设置好模板就可以选择add 了 等 SNMP 变绿就好了 现在的状态是用 SNMP 进行监控了，我们只是添加了一个 SNMP OS LINUX 的模板，但是出现了 4 个。这 4 个链接。可以和多个 模板 连起来用 进入监控项，下面这个菜单是过滤搜索用的 下面全都是模板 我们可以随便点击一个，这里我们新建一个监控项 点击创建 类型选择 Zabbix agent 被动 Zabbix agent (active 主动模式) Simple check 简单检测 SNMPv1 agent …… 在 Key 这行点击 Select 可以进行选择 我们随便选择一个，例如 agent.version。查看 agent 的版本Numeric 是无符号整数型 2. 图形说明Configuration----hosts----Graphs 绘图靠的是 监控项，我们可以随便打开一个看看 颜色等都是可以随意设置 3、聚合图形 screens 设置 提示 ：因为咱们用的版本是 3.0 当 2.4 的时候需要在Configuration---- 下面来创建screens 创建 Screens 我们创建一个 2*2 命名为test screens 的screens 然后我们点进去 点击 编辑 点击 Change 进行设置 多添加几个之后就是以下结果 二、监控案例 [自定义监控项] 例如 ：我们自己添加一个监控项来进行监控当前的活动连接数nginx 安装地址：http://www.abcdocker.com/abcdocker/1376Nginx 状态模块配置如下，过于简单不说了 [root@localhost ~]# cat /usr/local/nginx/conf/nginx.conf listen 8080; location /status { stub_status on; access_log off; allow 192.168.56.0/24; deny all; } 修改 nginx 端口并重启 测试：http://192.168.56.11:8080/status 解释说明：使用 zabbix 来监控活动连接数，通过 status 状态模块为前提 , 我们现在命令取出我们想要的值，例如： [root@localhost ~]# curl -s http://192.168.56.11:8080/status|grep Active|awk -F &quot;[]&quot; &apos;{print $3}&apos; 1 因为我们是监控他的活动连接数，他的活动连接数为1 [root@linux-node1 ~]# vim /etc/zabbix/zabbix_agentd.conf Include=/etc/zabbix/zabbix_agentd.d/ 提示： 如果想要加自定义监控项，不要在配置文件中写入，可以在 Include 里面定义的目录写上 , 只要我们写在 Include 目录下，都可以识别到 [root@linux-node1 ~]# cd /etc/zabbix/zabbix_agentd.d/ [root@linux-node1 zabbix_agentd.d]# ls userparameter_mysql.conf #默认有一个 MySQL 的，我们可以参考 MySQL 的进行操作 UserParameter=mysql.ping,HOME=/var/lib/zabbix mysqladmin ping | grep -c alive #提示，前面是 key 的名称 后面的 key 的命令 UserParameter=mysql.version,mysql -V 我们自己编辑一个文件 [root@linux-node1 zabbix_agentd.d]# cat nginx.conf UserParameter=nginx.active,/usr/bin/curl -s http://192.168.56.11:8080/status|grep Active|awk -F &quot;[]&quot; &apos;{print $3}&apos; 提示，此处配置文件的名字可以随便起 如果是多个命令可以写一个 脚本 ，命令最好写 绝对路径 ！这个过程其实就是我们定义监控的过程，前面是key 的名字，后面是命令 修改完配置文件之后需要重启zabbix-agent [root@linux-node1 zabbix_agentd.d]# systemctl restart zabbix-agent 配置完成之后先在 server 端测试，是否可以获取到 agent 上的值。不要着急添加 , 我们现在只用了 1 台服务器，本机是 server 也是 agent。然后使用 zabbix-get 进行 测试 [root@linux-node1 zabbix_agentd.d]# yum list|grep zabbix zabbix-agent.x86_64 3.0.4-1.el7@zabbix zabbix-release.noarch 3.0-1.el7 installed zabbix-server-mysql.x86_64 3.0.4-1.el7@zabbix zabbix-web.noarch 3.0.4-1.el7@zabbix zabbix-web-mysql.noarch 3.0.4-1.el7@zabbix python-pyzabbix.noarch 0.7.3-2.el7epel uwsgi-stats-pusher-zabbix.x86_642.0.13.1-2.el7 epel zabbix-get.x86_64 3.0.4-1.el7zabbix 查看 zabbix_get [root@linux-node1 zabbix_agentd.d]# yum install -y zabbix-get zabbix-get使用参数如下： [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -p 10050 -k &quot;nginx.active&quot; -s 指定我们要查看的服务器 -p 端口，可以不加。默认是 10050 -k 监控项的名称（根据上面的配置来定义的） 更多参数：zabbix_get --help 错误案例： 如果出现如下错误，大致意思是拒绝连接 [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -p 10050 -k &quot;nginx.active&quot; zabbix_get [24234]: Check access restrictions in Zabbix agent configuration 解决方法： [root@linux-node1 ~]# vim /etc/zabbix/zabbix_agentd.conf Server= 192.168.56.11 因为我们当时只允许本机 127.0.0.1 进行连接。所以会出现这样问题 [root@linux-node1 ~]# systemctl restart zabbix-agent 修改完配置文件都要 重启 提示： zabbix-agent 的配置文件中指定允许那个 server 连接，那个才可以进行连接。 [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -p 10050 -k &quot;nginx.active&quot; 1 正确结果如上！提示：如果在 zabbix-agent 上面修改了，还需要在网页上进行修改 在 /etc/zabbix/zabbix-agent.conf 上面指定的 Server 是谁，就只会允许谁通过。如果有多个 ip 可以使用逗号进行分割 添加 item 找到一个安装zabbix-agent，点击 点击items 然后添加Create item（创建 item） Data type：数据类型，这里我们选择 Decimal。其他的基本上用不上 Units：单位 超过 1 千就写成 1k 了。 可以在这里做一个单位的设置。默认就可以 Use custom multiplier：如果这里面设置了一个数，得出来的结果都需要乘以文本框设定的值 Update interval（in sec）:监控项刷新时间间隔（一般不要低于 60 秒） Custom intervals:创建时间间隔（例如：1 点 -7 点每隔多少秒进行监控）格式大致为：周，时，分 History storage period: 历史数据存储时间（根据业务来设置，默认就可以） Trend storage period: 趋势图要保存多久 New application: 监控项的组 application: 选择一个监控项组 Populates host inventory field: 资产，可以设定一个监控项。把获取的值设置在资产上面 描述！必须要写。 要不你就是不负责任 添加自定义监控项小结： 1、添加用户自定义参数（在 /etc/zabbix/zabbix.agent.d/ 定义了一个 nginx.conf 步骤如上） 2、重启zabbix-agent 3、在 Server 端使用 zabbix_get 测试 获取（命令如上） 4、在 web 界面创建item（监控项） 自定义图形 Name：名字 Width：宽度 Height：高度 Graph type：图形类型 其他 默认 即可 然后我们点击 Add 添加 Items 监控项，找到我们刚刚设置的服务器 然后找到我们刚刚添加的 监控项 还可以选择颜色，添加其他的很多设置。不细说 点击 Prewview 可以进行预览，如果出现字符乱码可以阅读我们另一篇文章（zabbix 默认不支持中文）, 确定没有问题，选择下方 Add 即可 出现我们添加的 需要在 Monitoring---&gt;Graphs---&gt; 选择我们添加的主机即可 接下来我们需要进行 测试 ： 测试前： 使用 ab 测试工具进行测试，设置 100 万 并发进行访问 [root@linux-node1 ~]# ab -c 1000 -n 1000000 http://192.168.56.11:8080/ This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 192.168.56.11 (be patient) 测试后： 我们可以查看 zabbix 监控图标 我们中间设置了间隔 60 秒，说明每隔 60 秒 我们进行获取一次, 我们可以设置它的方式显示 找到 Graph 选择类型，Stacked是堆叠显示，其他的大家可以自行百度。不细说 堆叠显示如下： 如果我们想加多个图形都显示在一张图上，可以进行如下操作 找到Graphs 找到我们设置的图形 点击添加即可 我们可以让多个图标显示在一个图片上 点击我们创建一个聚合图形（screens） 点击进去 点击编辑 选择 item 添加的地方，因为上面创建聚合图形的时候我们选择了 2X2 所以这里会显示 2 个 找到相对应的添加即可 我们可以多添加几个 结果如上图显示 除了显示图片还可以显示其他内容 Action log：日志 Clock：时间 Data overview：数据概述 Graph：图形 History of events：历史事件 Host group issues：主机组问题 Host issues：主机问题 Hosts info：主机信息 Plain text：文本 Map：架构图 Screen：屏幕 Server info：服务器信息 Simple graph：简单的图 Simple graph prototype：简单的原型图 System status：系统状态 Triggers info：触发器信息 Tiggers overview：概述 URL：URL 地址 例如我们输入一个 URL： 我们还可以自定义一个Maps，一张架构图。操作如下： 第二步：选择编辑Edit map 因为他默认图片比较小，我们可以点击下方，进行调整图片大小。 点击右上角 编辑，然后我们点中图中的服务器即可 我们模拟有 2 台服务器 然后我们选中新添加的服务器进行修改 点击 Apply 就可以了。按住 Ctrl 点中 zabbix server 和另一台服务器 然后我们点击左上方的Link：他们就连接起来了 温馨提示：修改完成后需要点击保存 [update] 如果不点后果就是从新在做一遍~ 未完！ 转载自：Zabbix 3.0 部署监控 [二] | abcdocker 运维博客]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 基础介绍 [一]（转）]]></title>
    <url>%2F2016%2F10%2F10%2FZabbix%203.0%20%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%20%5B%E4%B8%80%5D%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摘要 本文主要讲述 Zabbix 的简介以及 Zabbix 安装及页面设置 Zabbix 3.0 基础介绍 [一]一、Zabbix 介绍zabbix 简介 Zabbix 是一个高度集成的网络监控解决方案，可以提供企业级的开源分布式监控解决方案，由一个国外的团队持续维护更新，软件可以自由下载使用，运作团队靠提供收费的技术支持赢利 zabbix 是一个基于 Web 界面的，提供分布式系统监控以及网络监视功能的企业级的开源解决方案。 zabbix 能监视各种网络参数，保证服务器系统的安全运营，并提供灵活的通知机制以让系统管理员快速定位 / 解决存在的各种问题 zabbix 主要由 2 部分构成 zabbix server 和 zabbix agent，可选组建 zabbix proxy zabbix server 可以通过 SNMP，zabbix agent，fping 端口监视等方法对远程服务器或网络状态完成监视，数据收集等功能。同时支持 Linux 以及 Unix 平台，Windows 平台只能安装客户端 Zabbix 功能 ①具备常见的商业监控软件所具备的功能（主机的性能监控、网络设备性能监控、数据库、性能监控、FTP 等通用协议监控、多种告警方式、详细的报表图表绘制） ②支持自动发现网络设备和服务器（可以通过配置自动发现服务器规则来实现） ③支持自动发现（low discovery）key 实现动态监控项的批量监控（需写脚本） ④支持分布式，能集中展示、管理分布式的监控点 ⑤扩展性强，server 提供通用接口（api 功能），可以自己开发完善各类监控（根据相关接口编写程序实现）编写插件容易，可以自定义监控项，报警级别的设置。 ⑥数据收集 可用和性能检测 支持 snmp(包括 trapping and polling)，IPMI，JMX，SSH，TELNET 自定义的检测 自定义收集数据的频率 服务器 / 代理和客户端模式 灵活的触发器 可以定义非常灵活的问题阈值，称为触发器，从后端数据库的参考值 高可定制的报警 发送通知，可定制的报警升级，收件人，媒体类型 通知可以使用宏变量有用的变量 自动操作包括远程命令 实时的绘图功能 监控项实时的将数据绘制在图形上面 WEB 监控能力 ZABBIX 可以模拟鼠标点击了一个网站，并检查返回值和响应时间 Api 功能 应用 api 功能，可以方便的和其他系统结合，包括手机客户端的使用。 更多功能请查看http://www.zabbix.com/documentation.php Zabbix 版本 Zabbix 3.0 Manual Zabbix 2.4 Manual Zabbix 2.2 Manual Zabbix 2.0 Manual 下载地址：http://www.zabbix.com/documentation.php 本次采用 yum 安装，安装 zabbix3.0. 使用 Centos7 Zabbix 优缺点 优点 1、开源，无软件成本投入 2、Server 对设备性能要求低 3、支持设备多，自带多种监控模板 4、支持分布式集中管理，有自动发现功能，可以实现自动化监控 5、开放式接口，扩展性强，插件编写容易 6、当监控的 item 比较多服务器队列比较大时可以采用被动状态，被监控客户端主动从 7、server 端去下载需要监控的 item 然后取数据上传到 server 端。这种方式对服务器的负载比较小。 8、Api 的支持，方便与其他系统结合 缺点 需在被监控主机上安装 agent，所有数据都存在数据库里，产生的数据据很大, 瓶颈主要在数据库。 Zabbix 监控原理 Zabbix 通过 C/S 模式采集数据，通过 B/S 模式在 web 端展示和配置。 被监控端：主机通过安装 agent 方式采集数据，网络设备通过 SNMP 方式采集数据 Server 端：通过收集 SNMP 和 agent 发送的数据，写入数据库（MySQL，ORACLE 等），再通过 php+apache 在 web 前端展示。 Zabbix 运行条件 Server：Zabbix Server 需运行在 LAMP（Linux+Apache+Mysql+PHP）环境下（或者 LNMP），对硬件要求低 Agent：目前已有的 agent 基本支持市面常见的 OS，包含 Linux、HPUX、Solaris、Sun、windows SNMP：支持各类常见的网络设备SNMP(Simple Network Management Protocol, 简单网络管理协议 Zabbix 监控过程逻辑图 Zabbix 监控类型 硬件监控：适用于物理机、远程管理卡（iDRAC），IPMI（只能平台管理接口） ipmitools:MegaCli（查看 Raid 磁盘） 系统监控: 监控 cpt：lscpu、uptime、top、vmstat 1 、mpstat 1、htop 监控内存： free -m 监控硬盘：df -h、iotop 监控网络：iftop、netstat、ss 应用服务监控：nfs、MySQL、nginx、apache、php、rsync 更详细的监控类型可以参考：http://www.abcdocker.com/abcdocker/1376 引入 Zabbix所有监控范畴，都可以整合到 Zabbix 中 硬件监控：Zabbix、IPMI、lnterface 系统监控：Zabbix、Agent、Interface Java 监控：Zabbix、JMX、lnterface 网络设备监控：Zabbix、SNMP、lnterface 应用服务监控：Zabbix、Agent、UserParameter MySQL 数据库监控：percona-monitoring-plulgins URL 监控：Zabbix Web 监控 ## 二、Zabbix 环境配置 1、环境信息 [root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@localhost ~]# uname -r 3.10.0-327.28.3.el7.x86_64 2、yum 安装 阿里云 yum 源已经提供了 zabbix3.0，因此我们需要使用官方 yum 源。官方 yum 源下载会比较慢 [root@localhost ~]# rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm 问题：为什么要下载 release 版本的 zabbix？ [root@localhost ~]# ls /etc/yum.repos.d/ CentOS-Base.repo CentOS-Media.repo epel.repo.rpmnew CentOS-CR.repo CentOS-Sources.repo epel-testing.repo CentOS-Debuginfo.repo CentOS-Vault.repo zabbix.repo CentOS-fasttrack.repo epel.repo 因为下载这个版本会在 yum.repos.d 下面生成一个 zabbix.repo 的文件 3、安装相关软件包 [root@localhost ~]# yum install zabbix-server zabbix-web zabbix-server-mysql zabbix-web-mysql mariadb-server mariadb -y 注：如果 Server 端也需要监控则需要安装 zabbix-agent 提示：在 Centos7 中，mysql 改名为 mariadb 4、修改 PHP 时区设置 [root@localhost ~]# sed -i &apos;s@# php_value date.timezone Europe/Riga@php_value date.timezone Asia/Shanghai@g&apos; /etc/httpd/conf.d/zabbix.conf #要注意需要改的配置文件是 /etc/httpd/conf.d/zabbix.conf 而不是 /etc/php.ini， 三、数据库设置1. 启动数据库 [root@localhost ~]# systemctl start mariadb 2. 创建 zabbix 数据库及用户 mysql create database zabbix character set utf8 collate utf8_bin; grant all on zabbix.* to zabbix@&apos;localhost&apos; identified by &apos;123456&apos;; exit 3. 导入数据 [root@localhost ~]# cd /usr/share/doc/zabbix-server-mysql-3.0.4/ [root@localhost zabbix-server-mysql-3.0.4]# ll total 1836 -rw-r--r-- 1 root root 98 Jul 22 11:05 AUTHORS -rw-r--r-- 1 root root 687803 Jul 22 11:05 ChangeLog -rw-r--r-- 1 root root 17990 Jul 22 11:06 COPYING -rw-r--r-- 1 root root 1158948 Jul 24 02:59 create.sql.gz -rw-r--r-- 1 root root 52 Jul 22 11:06 NEWS -rw-r--r-- 1 root root 188 Jul 22 11:05 README [root@localhost zabbix-server-mysql-3.0.4]# zcat create.sql.gz |mysql -uzabbix -p123456 zabbix 我们使用 zcat，专门查看 sql.gz 包。和 cat 基本相似 4. 修改 zabbix 配置文件 [root@localhost zabbix-server-mysql-3.0.4]# vim /etc/zabbix/zabbix_server.conf DBHost=localhost #数据库所在主机 DBName=zabbix #数据库名 DBUser=zabbix #数据库用户 DBPassword=123456 #数据库密码 5. 启动 zabbix 及 apache [root@localhost ~]# systemctl start zabbix-server [root@localhost ~]# systemctl start httpd 注意：如果没有启动成功，要看一下是不是 80 端口被占用 6.Web 界面安装 master访问地址：http://192.168.56.11/zabbix/setup.php 点击 Next step 进行安装 首先要确保没有no，如果时区没有改好会提示我们进行修改 账号密码都是我们刚刚在配置文件中设置的，端口默认就是 3306 为我们的 zabbix 起个名字，一会在右上角会显示 最后是展示我们的配置信息，可以查看到哪里有错误 点击 Finish 提示：登录上去之后请立即修改密码 7. 配置 zabbix-agent 端 [root@localhost ~]# vim /etc/zabbix/zabbix_agentd.conf Server=127.0.0.1 修改 Server 端的 IP 地址（被动模式 IP 地址） ServerActive=127.0.0.1 主动模式，主动向 server 端报告 [root@localhost ~]# systemctl start zabbix-agent 查看端口号 [root@localhost ~]# netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 7806/mysqld tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1062/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2208/master tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 11511/zabbix_agentd tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 11335/zabbix_server tcp 0 0 127.0.0.1:199 0.0.0.0:* LISTEN 2692/snmpd tcp6 0 0 :::80 :::* LISTEN 11408/httpd tcp6 0 0 :::22 :::* LISTEN 1062/sshd tcp6 0 0 ::1:25 :::* LISTEN 2208/master tcp6 0 0 :::443 :::* LISTEN 11408/httpd tcp6 0 0 :::10050 :::* LISTEN 11511/zabbix_agentd tcp6 0 0 :::10051 :::* LISTEN 11335/zabbix_server 10051 为 server 端口，10050 为 agent 端口 四、Web 界面配置 找到 Configuration—-&gt;Hosts 添加一台监控主机 开启后，如果出现错误我们可以看一下 zabbix 的日志 [root@localhost ~]# ls /var/log/zabbix/zabbix_ zabbix_agentd.log zabbix_server.log 当 ZBX 变成绿色的时候，说明监控成功。因为我们没有配置 SNMP、JMX、IPMI 等。所以我发监控 因为我们现在只安装了一台服务器，所以只有一个主机。我们可以查看现在这台主机的 CPU 等及基本的信息 点击 Monitoring—–Graphs，选择我们要监控的内容 我们选择可以随便选择一个进行查看信息 例如：我们查看 CPU 的负载 某一段时间内，CPU 正在处理以及等待 CPU 处理的进程数的之和。Load Average 是从另一个角度来体现 CPU 的使用状态的。 这些监控其实就是 zabbix 在数据库查找数据，然后使用 jd 进行画图Zabbix 性能依赖于 mysql 数据库 五、Zabbix 页面安全设置1、设置默认账号密码 设置完中文 六、Zabbix 菜单说明Zabbix 上方的菜单简单介绍说明 Doshboard 下面可以设置你想设置的图形，添加方法如下： 这时，就可以找到你喜爱的了，直接打开 screens 其实就是一个聚合图形，可以把多个图片合在一起。然后放在大屏幕上，供别人查看 maps 就是一个架构图 Status of Zabbix 就是一个状态栏 第一行是 Server 是否运行 [yes] 和后面的运行地址 第二行监控的机器 （启用的 / 关闭的 / 模板） 第三行监控项 （启用的 / 关闭的 / 不支持的） 第四行触发器的状态 （启用的 / 关闭的 /【故障 / 正常】） 第五行 当前用户数量 （在线数量） 第六行 zabbix 每秒可以收到的一个新值 告警的级别 我们可以设置报警响铃，让他在前端响 我们首页的监控列表是可以随意拖动的 我们还可以将它关闭，并且设置刷新时间 Zabbix 基础完! 转载自：Zabbix 3.0 基础介绍 [一] | abcdocker 运维博客]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 主题内接入网页在线联系功能]]></title>
    <url>%2F2015%2F02%2F26%2FHexo%20NexT%E4%B8%BB%E9%A2%98%E5%86%85%E6%8E%A5%E5%85%A5%E7%BD%91%E9%A1%B5%E5%9C%A8%E7%BA%BF%E8%81%94%E7%B3%BB%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[之前有访问过一些大佬的个人博客，里面有个在线联系功能，看着不错，所以也试着在自己的站点上接入了此功能。 注册 首先在 DaoVoice 注册个账号，点击 -&gt;邀请码 是2e5d695d。 完成后，会得到一个app_id，后面会用到： 修改 head.swig修改 /themes/next/layout/_partials/head.swig 文件，添加内容如下： {% if theme.daovoice %} (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice") daovoice('init', {app_id: "{{theme.daovoice_app_id}}" }); daovoice('update'); {% endif %} 位置贴图： 主题配置文件 在_config.yml文件中添加内容： # Online contact daovoice: true daovoice_app_id: # 这里填你刚才获得的 app_id 聊天窗口配置 附上我的聊天窗口的颜色、位置等设置信息： 至此，网页的在线联系功能已经完成，重新 hexo g，hexo d 上传 GitHub 后，页面上就能看到效果了。 就比如说你现在往右下角看看(～￣▽￣)～ ，欢迎撩我（滑稽）。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 主题内加入动态背景]]></title>
    <url>%2F2015%2F02%2F25%2FHexo%20NexT%E4%B8%BB%E9%A2%98%E5%86%85%E5%8A%A0%E5%85%A5%E5%8A%A8%E6%80%81%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[主题内新添加内容 _layout.swig 找到 themes\next\layout\_layout.swig 文件，添加内容：在 &lt;body&gt; 里添加： &lt;div class=&quot;bg_content&quot;&gt; &lt;canvas id=&quot;canvas&quot;&gt;&lt;/canvas&gt; &lt;/div&gt; 仍是该文件，在末尾添加： &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/dynamic_bg.js&quot;&gt;&lt;/script&gt; dynamic_bg.js 在 themes\next\source\js\src 中新建文件dynamic_bg.js，代码链接中可见：dynamic_bg.js custom.styl在 themes\next\source\css\_custom\custom.styl 文件末尾添加内容： .bg_content { position: fixed; top: 0; z-index: -1; width: 100%; height: 100%; } 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考： Hexo NexT 主题内加入动态背景]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSSFS 实现阿里云 OSS 文件系统数据共享]]></title>
    <url>%2F2015%2F01%2F24%2FOSSFS%E5%AE%9E%E7%8E%B0%E9%98%BF%E9%87%8C%E4%BA%91OSS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[阿里云 ESC 服务器挂载 OSS 文件系统 ossfs 能让您在 Linux/Mac OS X 系统中把 Aliyun OSS bucket 挂载到本地文件 系统中，您能够便捷的通过本地文件系统操作 OSS 上的对象，实现数据的共享。 阿里云 oss 官方：ossfs 挂载，您可以理解为把挂载的 bucket 当做一个 ecs 目录来操作的，存储文件到挂载的 bucket 中是占用的这个 bucket 的内存，不会占用您 ecs 的内存。 安装 下载文件 ossfs_1.80.3_centos7.0_x86_64.rpm 到阿里云 安装sudo yum localinstall ossfs_1.80.3_centos7.0_x86_64.rpm 写入 oss 配置echo my-bucket:my-access-key-id:my-access-key-secret &gt; /etc/passwd-ossfs, 例： echo ossfs-xuan:LTAIw5M5SHnIoNcm:ci1Oj7*******ZqDziBj &gt; /etc/passwd-ossfs 更改配置文件权限chmod 640 /etc/passwd-ossfs 创建挂载目录mkdir /ossfs 挂载ossfs ossfs-xuan /ossfs -ourl=oss-cn-shenzhen-internal.aliyuncs.com 额外的命令# 允许 linux 其他用户对改 oss 文件系统进行操作 ossfs ossfs-xuan /ossfs -ourl=oss-cn-shenzhen-internal.aliyuncs.com -o allow_other #卸载挂载 oss 目录 umount /ossfs 可能出现的错误 InvalidBucketName 错误可以看出 BucketName 重复了 ossfs: bad request &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;Error&gt; &lt;Code&gt;InvalidBucketName&lt;/Code&gt; &lt;Message&gt;The specified bucket is not valid.&lt;/Message&gt; &lt;RequestId&gt;5A93BFD701A3E286AC09FDDD&lt;/RequestId&gt; &lt;HostId&gt;ossfs-xuan.ossfs-xuan.oss-cn-shenzhen-internal.aliyuncs.com&lt;/HostId&gt; &lt;BucketName&gt;ossfs-xuan.ossfs-xuan&lt;/BucketName&gt; &lt;/Error&gt; 解决：-ourl=oss-cn-shenzhen-internal.aliyuncs.com不需要带BucketName]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7.4 安装 GlusterFS]]></title>
    <url>%2F2015%2F01%2F23%2FCentOS7.4%E5%AE%89%E8%A3%85GlusterFS%2F</url>
    <content type="text"><![CDATA[介绍 Gluster 是一个大尺度文件系统。 主要功能 简单卷 distribute volume 分布式卷，两台主机的磁盘融合一个磁盘 stripe volume 条带卷，一个文件分成数据块存储到不同的地方 replica volume 复制卷，一个文件分别保存到两台主机 复合卷 1+2，1+3，2+3，1+2+3 总结常用命令gluster peer status #查看集群各主机连接状态 gluster volume list# 查看挂载卷信息 gluster volume list #查看卷列表 #创建挂在卷，force 忽略在 root 目录创建挂在卷的警告 gluster volume create swarm-volume replica 3 worker:/xuan/docker/gluster-volume home:/xuan/docker/gluster-volume xuanps:/xuan/docker/gluster-volume force gluster volume start swarm-volume #启动 gluster volume stop swarm-volume #停止 gluster volume delete swarm-volume #删除 ，了文件还会保留 #挂载本地目录到 glusterfs 卷（swarm-volume），在本地目录添加的会自动同步到其他挂载卷 #eg 在本机 mnt 添加文件，其他 volume-name 目录也会添加 mount [- 参数] [设备名称] [挂载点] mount -t glusterfs worker:/swarm-volume /mnt/ umount worker:/swarm-volume #卸载了就不会同步了 #重置，删除所有数据 systemctl stop glusterd rm -rf /var/lib/glusterd/ systemctl start glusterd #删除节点 gluster peer detach home 安装 准备工作： 三台局域网主机（centos7 修改主机名 ） hostnameip备注xuanpsleft-aligned10.14.0.1 workercentered10.14.0.4homeright-aligned10.14.0.5 三台都需要安装 GlusterFS # 搜索 glusterfs 可安装的版本 yum search centos-release-gluster #安装最新长期稳定版本 (Long Term Stable) 的 gluster 软件 yum -y install centos-release-gluster #安装 glusterfs-server yum --enablerepo=centos-gluster*-test install glusterfs-server glusterfs -V #测试 systemctl enable glusterd #开机启动 systemctl start glusterd #启动 systemctl status glusterd #查看是否正常运行 #修改 hosts 不然不能通过主机名连接到对方 vim /etc/hosts #---------- 三台都要添加如下设置 -------------------------- 10.14.0.1 xuanps 10.14.0.4 worker 10.14.0.5 home #------------------------------------------------------ #从 xuanps 上执行下面两条，其他主机不用执行 gluster peer probe worker gluster peer probe home #三台都执行该命令是否都是 connected gluster peer status #查看挂载卷信息 gluster volume info #创建挂在卷，force 忽略在 root 目录创建挂在卷的警告 gluster volume create volume-name replica 3 worker:/xuan/docker/gluster-volume/test home:/xuan/docker/gluster-volume/test xuanps:/xuan/docker/gluster-volume/test force #启动 gluster volume start volume-name #启动 nfs 同步，测试需验证，这里要不要开启 gluster volume set volume-name nfs.disable off #挂载本地目录到 glusterfs 卷（volume-name），在本地目录添加的会自动同步到其他挂载卷 #eg 在本机 mnt 添加文件，其他 volume-name 目录也会添加 mount -t glusterfs worker:/volume-name /mnt/ 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考 官方文档 centos 官方安装手册 基于 GlusterFS 实现 Docker 集群的分布式存储]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7.4 安装 OpenVpn]]></title>
    <url>%2F2015%2F01%2F22%2FCentOS7.4%E5%AE%89%E8%A3%85OpenVpn%2F</url>
    <content type="text"><![CDATA[openvpn service 安装与配置1. 下载脚本 wget https://git.io/vpn -O openvpn-install.sh# 添加执行权限 chmod +x openvpn-install.sh #总结 wget https://git.io/vpn -O openvpn-install.sh &amp;&amp; bash openvpn-install.sh 2. 运行脚本./openvpn-install.sh, 设置如下 监听地址设置为空 IP address: Protocol:[2]TCP Port:1194 不选 DNS: client name: client_k2 External IP : 112.74.51.136 3. 配置服务端 vim /etc/openvpn/server.conf# 指定 ip, 所以记录 ip 没效果屏蔽 ;ifconfig-pool-persist ipp.txt ;push &quot;redirect-gateway def1 bypass-dhcp&quot; #推送服务器路由 push &quot;route 10.14.0.0 255.255.255.0&quot; #推送 k2 客户端子网路由到所有客户端除了 ccd 里面申明了该路由的客户端 push &quot;route 192.168.123.0 255.255.255.0&quot; #添加服务器路由，访问客户端 K2 的 192.168.123.0 子网通过网关 10.14.0.2(k2 客户端 ip) route 192.168.123.0 255.255.255.0 10.14.0.2 #添加客户端配置目录，启用之后，每个客户端必须指定 ip，否正有可能访问不了其他客户端的子网 client-config-dir ccd #客户端访问客户端 client-to-client 4. 配置客户端路由 mkdir /etc/openvpn/ccd 和 vim /etc/openvpn/ccd/client_k2# 设置该客户端的 vpn 的 ip 是 10.14.0.2, 子网掩码必须是 255.255.255.0，如果启用 ccd，必须配置 ifconfig-push 10.14.0.2 255.255.255.0 #申明 192.168.123.0 是自己的子网，并且让子网也可以访问 vpn 服务器，申明之后不会推送该路由到该客户端 iroute 192.168.123.0 255.255.255.0 route 192.168.123.0 255.255.255.0 5. 添加客户端./openvpn-install.shSelect an option[1-4]:1 (add a new user) client name: client_worker # 编辑配置文件 vim /etc/openvpn/server.conf #重启生效 systemctl restart openvpn@server.service systemctl enable openvpn@server.service #注释掉客户端的 #setenv opt block-outside-dns 6. 下载 ovpn 文件，并修改配置，注释调 #setenv opt block-outside-dns 7. 常用命令# 重启生效 systemctl restart openvpn@server.service #使能服务 systemctl enable openvpn@server.service #ssh 下载文件 scp root@112.74.51.136:/root/client_xuan_ubuntu.ovpn ./ openvpn client 安装与配置1. 安装yum update #更新 yum install vim #安装 vim yum install epel-release #添加 epel 源 yum clean all # 可选 yum update # 可选 yum makecache # 可选 yum install openvpn iptables-services #安装 openvpn scp root@112.74.51.136:~/client_vm.ovpn /etc/openvpn/client/ #下载客户端配置 #注释掉客户端的 vim /etc/openvpn/client/client_vm.ovpn #setenv opt block-outside-dns #----------------------- 废弃 ------------------------------------------------ openvpn --daemon --cd /etc/openvpn/client --config client_vm.ovpn --log-append /etc/openvpn/openvpn.log #启动 tail -100f /etc/openvpn/openvpn.log #查看日志 ps -ef | grep openvpn #查看 openvpn 进程 kill &lt;pid&gt; #杀死进程 #--------------------- 废弃结束 ------------------------------------------------------ #openvpn-client 启动服务，反斜杠转义字符，实际名称是 openvpn-client@.service vim /lib/systemd/system/openvpn-client\@.service #修改 ExecStart=/usr/sbin/openvpn --suppress-timestamps --nobind --config %i.conf #为 ExecStart=/usr/sbin/openvpn --daemon --config %i.ovpn --log-append /etc/openvpn/openvpn.log #防止已经启动，@符号后面等效与 %i, 所以这里为客户端配置的名字 systemctl restart openvpn-client@client_vm #开机启动 systemctl enable openvpn-client@client_vm 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考 官网 脚本 github 官网 Nyr/openvpn-install openvpn 的一个一键安装脚本“openvpn-install”让 openvpn 重放光彩（需翻墙） How to Configure OpenVPN Server on CentOS 7.3 使用 OpenVPN 互联多地机房及 Dokcer 跨主机 / 机房通讯 扩大 OpenVPN 使用范围，包含服务器或客户端子网中的其他计算机]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 修改网卡为 eth0]]></title>
    <url>%2F2015%2F01%2F22%2FCentOS7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E4%B8%BAeth0%2F</url>
    <content type="text"><![CDATA[使用 CentOS-7 最直观的变化就是服务管理了。这里介绍一下。 services 使用了 systemd 来代替 sysvinit 管理 systemd 是 Linux 下的一种 init 软件，由 Lennart Poettering 带头开发，并在 LGPL 2.1 及其后续版本许可证下开源发布。其开发目标是提供更优秀的框架以表示系统服务间的依赖关系，并依此实现系统初始化时服务的并行启动，同时达到降低 Shell 的系统开销的效果，最终代替现在常用的 System V 与 BSD 风格 init 程序。与多数发行版使用的 System V 风格 init 相比，systemd 采用了以下新技术：采用 Socket 激活式与总线激活式服务，以提高相互依赖的各服务的并行运行性能；用 cgroups 代替 PID 来追踪进程，以此即使是两次 fork 之后生成的守护进程也不会脱离 systemd 的控制。从设计构思上说，由于 systemd 使用了 cgroup 与 fanotify 等组件以实现其特性，所以只适用于 Linux。systemd 的服务管理程序：systemctl 是主要的工具，它融合之前 service 和 chkconfig 的功能于一体。可以使用它永久性或只在当前会话中启用 / 禁用服务。 启动一个服务：systemctl start postfix.service 关闭一个服务：systemctl stop postfix.service 重启一个服务：systemctl restart postfix.service 显示一个服务的状态：systemctl status postfix.service 在开机时启用一个服务：systemctl enable postfix.service 在开机时禁用一个服务：systemctl disable postfix.service 查看服务是否开机启动：systemctl is-enabled postfix.service;echo $? 查看已启动的服务列表：systemctl list-unit-files|grep enabled CentOS7 修改网卡为 eth0编辑网卡信息[root@linux-node2~]# cd /etc/sysconfig/network-scripts/ #进入网卡目录 [root@linux-node2network-scripts]# mv ifcfg-eno16777728 ifcfg-eth0 #重命名网卡名称 [root@linux-node2network-scripts]# cat ifcfg-eth0 #编辑网卡信息 TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no NAME=eth0 #name 修改为 eth0 ONBOOT=yes IPADDR=192.168.56.12 NETMASK=255.255.255.0 GATEWAY=192.168.56.2 DNS1=192.168.56.2 修改 grub[root@linux-node2~]# cat /etc/sysconfig/grub #编辑内核信息, 添加红色字段的 GRUB_TIMEOUT=5 GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=&quot;console&quot; GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rhgb net.ifnames=0 biosdevname=0 quiet&quot; GRUB_DISABLE_RECOVERY=&quot;true&quot; [root@linux-node2~]# grub2-mkconfig -o /boot/grub2/grub.cfg #生成启动菜单 Generatinggrub configuration file ... Foundlinux image: /boot/vmlinuz-3.10.0-229.el7.x86_64 Foundinitrd image: /boot/initramfs-3.10.0-229.el7.x86_64.img Foundlinux image: /boot/vmlinuz-0-rescue-1100f7e6c97d4afaad2e396403ba7f61 Foundinitrd image: /boot/initramfs-0-rescue-1100f7e6c97d4afaad2e396403ba7f61.img Done 也可以在开机启动加载安装系统界面设置。 验证是否修改成功[root@linux-node2~]# reboot #必须重启系统生效 [root@linux-node2~]# yum install net-tools #默认 centos7 不支持 ifconfig 需要看装 net-tools 包 [root@linux-node2~]# ifconfig eth0 #在次查看网卡信息 eth0:flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.56.12 netmask 255.255.255.0 broadcast 192.168.56.255 inet6 fe80::20c:29ff:fe5c:7bb1 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:5c:7b:b1 txqueuelen 1000 (Ethernet) RX packets 152 bytes 14503 (14.1 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 98 bytes 14402 (14.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 设置主机名解析[root@linux-node1 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.56.11 linux-node1 linux-node1.example.com 192.168.56.12 linux-node2 linux-node2.example.com centos 7 修改主机名的方法 hostnamectl 命令 在 7 版本中，hostname 有三种形式 静态 (Static host name) 动态 (Transient/dynamic host name) 别名(Pretty host name) 查询主机名 hostnamectl 或 hostctl status 查询主机名 hostnamectl status [--static|--transient|--pretty] 修改 hostname hostnamectl set-hostname servername [--static|--transient|--pretty] 删除 hostname hostnamectl set-hostname &quot;&quot; hostnamectl set-hostname &quot;&quot; --static hostnamectl set-hostname &quot;&quot; --pretty 修改配置文件 hostname name vim /etc/hostname 通过 nmtui 修改，之后重启 hostnamed systemctl restart systemd-hostnamed 通过 nmcui 修改，之后重启 hostnamed nmcli general hostname servername systemctl restart systemd-hostnamed 安装 EPEL 仓库和常用命令[root@linux-node1 ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm [root@linux-node1 ~]# yum install -y net-tools vim lrzsz tree screen lsof tcpdump 关闭 NetworkManager 和防火墙[root@linux-node1 ~]# systemctl stop firewalld #关闭防火墙 [root@linux-node1 ~]# systemctl disable firewalld #设置开机不启动 [root@linux-node1 ~]# systemctl stop NetworkManager 关闭 SELinux[root@linux-node1 ~]# vim /etc/sysconfig/selinux SELINUX=disabled #修改为 disabled 检查结果如下 [root@linux-node1 ~]# getsebool getsebool: SELinux is disabled 更新系统并重启[root@linux-node1 ~]# yum update -y &amp;&amp; reboot centos7 设置开机脚本 新建开机脚本vim /root/Dropbox/save/bootstartscript.sh # 添加开机启动脚本 #开机启动 dropbox dropbox start -d 添加开机脚本到启动文件vim /etc/rc.d/rc.local # 开机启动脚本 /bin/sh /root/Dropbox/save/bootstartscript.sh 设置启动脚本生效 chmod +x /etc/rc.d/rc.local]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos 7/6 内核版本由 3.10.0 升级至 4.12.4 方法]]></title>
    <url>%2F2015%2F01%2F21%2FCentos7%E5%86%85%E6%A0%B8%E7%94%B13.10%E5%8D%87%E7%BA%A7%E8%87%B34.12%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[【写在前面】公司打算上 Docker 服务，目前需要安装运行环境，Docker 新的功能除了需要 Centos 7 系统之外，内核的版本高低也决定着使用的效果，所以在此记录下系统内核版本升级过程。注：对于线上环境的内核版本还需要根据实际情况谨慎选择，越新的版本未来可能遇到的问题越多，此文只是记录升级方法而已。 【文章内容】关于内核版本的定义： 版本性质：主分支 ml(mainline)，稳定版(stable)，长期维护版 lt(longterm) 版本命名格式为 “A.B.C”： 数字 A 是内核版本号 ：版本号只有在代码和内核的概念有重大改变的时候才会改变，历史上有两次变化： 第一次是 1994 年的 1.0 版，第二次是 1996 年的 2.0 版，第三次是 2011 年的 3.0 版发布，但这次在内核的概念上并没有发生大的变化 数字 B 是内核主版本号：主版本号根据传统的奇 - 偶系统版本编号来分配：奇数为开发版，偶数为稳定版 数字 C 是内核次版本号：次版本号是无论在内核增加安全补丁、修复 bug、实现新的特性或者驱动时都会改变 一、查看那系统内核版本uname -r 3.10.0-514.el7.x86_64 cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) 二、升级内核Centos 6 和 Centos 7 的升级方法类似，只不过就是选择的 YUM 源或者 rpm 包不同罢了，下面主要是 Centos 7 的安装方法，中间也会有对于 Centos 6 升级的方法提示。 方法一： Centos 6 YUM 源：http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpmCentos 7 YUM 源：http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 升级内核需要先导入 elrepo 的 key，然后安装 elrepo 的 yum 源： rpm -import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 仓库启用后，你可以使用下面的命令列出可用的内核相关包，如下图： yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available 上图可以看出，长期维护版本 lt 为 4.4，最新主线稳定版 ml 为 4.12，我们需要安装最新的主线稳定内核，使用如下命令：(以后这台机器升级内核直接运行这句就可升级为最新稳定版) yum -y --enablerepo=elrepo-kernel install kernel-ml.x86_64 kernel-ml-devel.x86_64 方法二： 对于一些无法上网的服务器，或者需要安装指定版本内核的需求，我们可以把 kernel image 的 rpm 包下载下来安装，下载地址如下： 下载指定版本 kernel： http://rpm.pbone.net/index.php3?stat=3&amp;limit=1&amp;srodzaj=3&amp;dl=40&amp;search=kernel 下载指定版本 kernel-devel：http://rpm.pbone.net/index.php3?stat=3&amp;limit=1&amp;srodzaj=3&amp;dl=40&amp;search=kernel-devel 官方 Centos 6: http://elrepo.org/linux/kernel/el6/x86_64/RPMS/ 官方 Centos 7: http://elrepo.org/linux/kernel/el7/x86_64/RPMS/ 将 rpm 包下载上传到服务器上，使用下面的命令安装即可： yum -y install kernel-ml-devel-4.12.4-1.el7.elrepo.x86_64.rpm yum -y install kernel-ml-4.12.4-1.el7.elrepo.x86_64.rpm 方法三： 还可以通过源码包编译安装，这种方式可定制性强，但也比较复杂，有需要的可自行查找资料安装，下面只给出各系统版本内核源码包的下载地址：https://www.kernel.org/pub/linux/kernel/ 三、修改 grub 中默认的内核版本 内核升级完毕后，目前内核还是默认的版本，如果此时直接执行 reboot 命令，重启后使用的内核版本还是默认的 3.10，不会使用新的 4.12.4，首先，我们可以通过命令查看默认启动顺序： awk -F\&apos; &apos;$1==&quot;menuentry &quot; {print $2}&apos; /etc/grub2.cfg CentOS Linux (4.12.4-1.el7.elrepo.x86_64) 7 (Core) CentOS Linux (3.10.0-514.el7.x86_64) 7 (Core) CentOS Linux (0-rescue-a43cc2091b4557f1fd10a52ccffa5db2) 7 (Core) 由上面可以看出新内核 (4.12.4) 目前位置在 0，原来的内核 (3.10.0) 目前位置在 1，所以如果想生效最新的内核，还需要我们修改内核的启动顺序为 0： vim /etc/default/grub 注：Centos 6 更改的文件相同，使用命令确定新内核位置后，然后将参数 default 更改为 0 即可。 接着运行 grub2-mkconfig 命令来重新创建内核配置，如下： grub2-mkconfig -o /boot/grub2/grub.cfg 四、重启系统并查看系统内核reboot 系统启动完毕后，可以通过命令查看系统的内核版本，如下： uname -r 4.12.4-1.el7.elrepo.x86_64 到此，Centos 7 内核升级完毕。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 主题添加点击爱心效果]]></title>
    <url>%2F2015%2F01%2F20%2FHexo%20NexT%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E7%82%B9%E5%87%BB%E7%88%B1%E5%BF%83%E6%95%88%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[给 NexT 主题内添加页面点击出现爱心的效果 创建 js 文件 在/themes/next/source/js/src下新建文件 clicklove.js，接着把该链接下的代码拷贝粘贴到clicklove.js 文件中。代码如下： !function(e,t,a){function n(){c(&quot;.heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: &apos;&apos;;width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}&quot;),o(),r()}function r(){for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText=&quot;left:&quot;+d[e].x+&quot;px;top:&quot;+d[e].y+&quot;px;opacity:&quot;+d[e].alpha+&quot;;transform:scale(&quot;+d[e].scale+&quot;,&quot;+d[e].scale+&quot;) rotate(45deg);background:&quot;+d[e].color+&quot;;z-index:99999&quot;);requestAnimationFrame(r)}function o(){var t=&quot;function&quot;==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e){t&amp;&amp;t(),i(e)}}function i(e){var a=t.createElement(&quot;div&quot;);a.className=&quot;heart&quot;,d.push({el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()}),t.body.appendChild(a)}function c(e){var a=t.createElement(&quot;style&quot;);a.type=&quot;text/css&quot;;try{a.appendChild(t.createTextNode(e))}catch(t){a.styleSheet.cssText=e}t.getElementsByTagName(&quot;head&quot;)[0].appendChild(a)}function s(){return&quot;rgb(&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;)&quot;}var d=[];e.requestAnimationFrame=function(){return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e){setTimeout(e,1e3/60)}}(),n()}(window,document); 修改_layout.swig在 \themes\next\layout\_layout.swig 文件末尾添加： &lt;!-- 页面点击小红心 --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/clicklove.js&quot;&gt;&lt;/script&gt;]]></content>
      <categories>
        <category>Hexo Next</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何整理个人资料]]></title>
    <url>%2F2015%2F01%2F20%2F%E5%A6%82%E4%BD%95%E6%95%B4%E7%90%86%E4%B8%AA%E4%BA%BA%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[序言 在现如今信息爆炸的时代，资料整理的方法显得越来越重要。好的资料整理方法可以让收集的资料发挥出它应有的价值，否则便和没有收集无异。 在平时工作学习中，看到好的技术文档或文章忍不住把它放到收藏夹或使用印象笔记类似的工具裁剪到笔记里，想着日后细细品读。可大多数是没有日后的，这便造成了收集的资料越来越多，越来越混乱，有时候还整理下，但随着数量的增多，发现整理这些东西也是需要很大的时间成本的。这些资料没有发挥其应用的价值，但还舍不得删掉。 之前一直想整理自己的知识体系，想着形成自己的一个知识库，可以随时翻阅。当需要用到哪方便的知识时，可以通过翻阅很快的回忆起来，立即上手。近几年有写博客的习惯，把一些读书笔记和技术的使用过程记录了下来，发挥了些知识库的作用。但总感觉不是那么完美，最近查了下资料，看了些有关资料和个人知识系统整理的文章，有些想法，梳理下加深印象。 整体流程 整个过程应该是这样的： 资料的收集 在现如今网络如此遍历，资料的获取已经不成问题。而如何有效的获取，成为关键。即如何在海一样的信息中，找到我们需要的。现如今我的资料收集方法如下：•搜索引擎 通过搜索引擎关键字，找到自己需要的资料。关键字很重要，必要的时候可以直接使用英文搜索。•微信公众号 通过平时碎片化的阅读，可收集到一些自己认为有价值的文章。•各技术社区 现如今国内各技术社区活跃，文章水平残次不齐。推荐先根据标题略读，发现好的文章后再精度。我们会发现一些高质量文章的产出作者，我们可以订阅他们，之后可重点关注他们的文章。 整理分类 根据我自己的资料，大致分如下几种：•新技术的文档：各种框架文档•技术学习文章：微信公众号文章、各技术社区文章•技术问题：stackoverflow/ 技术问题解决记录•大牛博客•其他工具性网址资料•产出的联系或功能代码 针对以上资料，该如何整理呢？ 工欲善其事必先利其器，整理以上众多资料，整理方法及使用工具如下：•xmind 构建自己的知识体系脑图，作为整个知识库的索引。•evernote 主要存储技术文章和不能公开的自己产出的文档笔记。可按语言和功能所属划分类别，再为文章打好 tag 便于检索。建立临时笔记本暂存未读完的或不知归类的文章，待后续阅读整理。•bookmarks 主要存储技术文档链接、牛人博客地址、工具性网址。同样分好类别，便于检索。•百度云盘 存储开源 pdf 书籍，方便各设备同步。•github 存储自己的周边项目。•博客 产出自己的想法和收获。 消化，产出价值 以上资源分类保存好后，便是消化产出价值了。 第一，在此阶段重要的还是整理，通过阅读我们知道了每篇文章的价值，是否需要留存待日后查询。 原则如下： •可以在网络上轻易找到的，直接删除 •过期的资料直接删除 第二，除了平时碎片化时间的阅读，还需要沉下心来花大块的时间，系统的来学习某项技术。 如何高效的学习消化，日后再整理篇，本篇暂不展开。 通过以上各流程方法，便构建了自己的知识库。完成了以下目标：•梳理自己的知识图谱•通过知识库，可以方便的回忆起某特定技术使用方法。•形成自己的 QA•记录下自己学习的周边项目，作为工作参考 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考 如何有效的进行资料整理？ 信息爆炸的时代，如何静心学习？]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 文件的常用编写语法]]></title>
    <url>%2F2015%2F01%2F19%2Fmarkdown%E5%B8%B8%E7%94%A8%E7%BC%96%E5%86%99%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[序言:很久没有写博客了，感觉只要是不写博客，人就很变得很懒，学的知识点感觉还是记不住，渐渐地让我明白，看的越多，懂的越少（你这话不是有毛病吗？应该是看的越多，懂的越多才对），此话怎讲，当你在茫茫的前端知识库里面东看看，西看看的时候，很快就被海量的知识给淹没了，根本就不知道哪些是对的，哪些是错的，感觉好像这个也懂了，那个也懂了，但是真正写起来，脑子又一片空白，又好像什么都不懂，这种状态时有发生，这就叫不懂装懂，最根本的原因就是看的太多，写的太少，所以为了改掉这样毛病，把被动学习变成主动学习，接下来的日子，多写写，即使是写一些学习工作中遇到的坑也是好的，没事翻出来看看，还可以加深印象，好了，废话到处！ 起因：因为现在的前端基本上都用上了前端构建工具，那就难免要写一些 readme 等等的说明性文件，但是这样的文件一般都是.md 的文件，编写的语法自然跟其他格式的文件有所区别，置于为什么要用这种格式的文件，不要问我，我也不知道，大家都这么用，跟着用就对了，如果有大神知道的，不妨告知小弟，本文也是我学习写 markdown 文件的一个笔记吧，仅供参考！ 正文：1、标题的几种写法：第一种： 前面带 #号，后面带文字，分别表示 h1-h6, 上图可以看出，只到 h6，而且 h1 下面会有一条横线，注意，# 号后面有空格 第二种： 这种方式好像只能表示一级和二级标题，而且 = 和 - 的数量没有限制，只要大于一个就行 第三种： 这里的标题支持 h1-h6，为了减少篇幅，我就偷个懒，只写前面二个，这个比较好理解，相当于标签闭合，注意，标题与 #号要有空格 那既然 3 种都可以使用，可不可以混合使用呢？我试了一下，是可以的，但是为了让页面标签的统一性，不建议混合使用，推荐使用第一种，比较简洁，全面 为了搞清楚原理，我特意在网上搜一下在线编写 markdown 的工具，发现实际上是把这些标签最后转化为 html 标签，如图： 在线地址请看这里： http://tool.oschina.net/markdown/ （只是想看看背后的转换原理，没有广告之嫌） 2、列表 我们都知道，列表分为有序列表和无序列表，下面直接展示 2 种列表的写法： 可以看到，无序列表可以用 ， + ， — 来创建，用在线编辑器看，实际上是转换成了 ul&gt;li ，所以使用哪个都可以，推荐使用 吧 有序列表就相对简单一点，只有这一种方式，注意，数字后面的点只能是英文的点，特别注意，有序列表的序号是根据第一行列表的数字顺序来的，比如说： 第一组本来是 3 2 1 倒序，但是现实 3 4 5 ，后面一组 序号是乱的， 但是还是显示 3 4 5 ，这点必须注意了 3、区块引用 比如说，你想对某个部分做的内容做一些说明或者引用某某的话等，可以用这个语句 无序列表下方的便是引用，可以有多种用途，看你的需求了，用法就是在语句前面加一个 &gt; ，注意是英文的那个右尖括号，注意空格 引用因为是一个区块，理论上是应该什么内容都可以放，比如说：标题，列表，引用等等，看看下图： 将上面的代码稍微改一下，全部加上引用标签，就变成了一个大的引用，还有引用里面还有引用，那引用嵌套引用还没有别的写法呢？ 上图可以看出，想要在上一次引用中嵌套一层引用，只需多加一个 &gt;，理论上可以无限嵌套，我就不整那么多了，注意：多层嵌套的 &gt; 是不需要连续在一起的，只要在一行就可以了，中间允许有空格，但是为了好看，还是把排版搞好吧 4、华丽的分割线 分割线可以由 * - _（星号，减号，底线）这 3 个符号的至少 3 个符号表示，注意至少要 3 个，且不需要连续，有空格也可以 应该看得懂吧，但是为了代码的排版好看，你们自己定规则吧，前面有用到星号，建议用减号 5、链接 支持 2 种链接方式：行内式和参数式，不管是哪一种，链接文字都是用 [方括号] 来标记。 上图可知，行内式的链接格式是：链接的文字放在 [] 中，链接地址放在随后的（）中，举一反三，经常出现的列表链接就应该这样写： 链接还可以带 title 属性，好像也只能带 title，带不了其他属性，注意，是链接地址后面空一格，然后用引号引起来 这是行内式的写法，参数式的怎么写： 这就好理解了，就是把链接当成参数，适合多出使用相同链接的场景，注意参数的对应关系，参数定义时，这 3 种写法都可以： 还支持这种写法，如果你不想混淆的话： 其实还有一种隐式链接的写法，但是我觉得那种写法不直观，所以就不写了，经常用的一般就上面 2 种，如果你想了解隐式链接，可以看我文章最后放出的参考地址 6、图片 图片也有 2 种方式：行内式和参数式， 用法跟链接的基本一样，唯一的不同就是，图片前面要写一个！（这是必须的），没什么好说的 7、代码框 这个就比较重要了，很多时候都需要展示出一些代码 如果代码量比较少，只有单行的话，可以用单反引号包起来，如下： 要是多行这个就不行了，多行可以用这个： 多行用三个反引号，如果要写注释，可以在反引号后面写 8、表格 这个写的有点麻烦，注意看 从这 3 种不同写法看，表格的格式不一定要对的非常起，但是为了好看，对齐肯定是最好的，第一种的分割线后面的冒号表示对齐方式，写在左边表示左对齐，右边为右对齐，两边都写表示居中，还是有点意思的，不过现实出来的结果是，表格外面并没有线框包起来，不知道别人的怎么弄的 9、强调 一个星号或者是一个下划线包起来，会转换为 倾斜，如果是 2 个，会转换为 加粗 10、转义 就不一一列举了，基本上跟 js 转义是一样的 11、删除线 常用的基本上就这些了，如果还有一些常用的，可以跟我留言，我补充上去，我觉得图文并茂才是高效学习的正确姿势，但愿为你的学习带来帮助！ 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考文献： Markdown 语法说明 (简体中文版) 认识与入门 Markdown]]></content>
      <categories>
        <category>技术工具</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
