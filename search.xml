<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ELK+Filebeat+Kafka+ZooKeeper 构建海量日志分析平台【转】]]></title>
    <url>%2F2018%2F09%2F12%2FELK%2BFilebeat%2BKafka%2BZooKeeper%20%E6%9E%84%E5%BB%BA%E6%B5%B7%E9%87%8F%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E3%80%90%E8%BD%AC%E3%80%91%2F</url>
    <content type="text"><![CDATA[ELK+Filebeat+Kafka+ZooKeeper 构建海量日志分析平台 原文链接：http://blog.51cto.com/tchuairen/1861167 什么要做日志分析平台？ 随着业务量的增长，每天业务服务器将会产生上亿条的日志，单个日志文件达几个 GB，这时我们发现用 Linux 自带工具，cat grep awk 分析越来越力不从心了，而且除了服务器日志，还有程序报错日志，分布在不同的服务器，查阅繁琐。 待解决的痛点: 1、大量不同种类的日志成为了运维人员的负担，不方便管理; 2、单个日志文件巨大，无法使用常用的文本工具分析，检索困难; 3、日志分布在多台不同的服务器上，业务一旦出现故障，需要一台台查看日志。 为了解决以上困扰: 接下来我们要一步步构建这个日志分析平台，架构图如下: 架构解读 : （整个架构从左到右，总共分为 5 层） 第一层、数据采集层 最左边的是业务服务器集群，上面安装了 filebeat 做日志采集，同时把采集的日志分别发送给两个 logstash 服务。 第二层、数据处理层，数据缓存层 logstash 服务把接受到的日志经过格式处理，转存到本地的 kafka broker+zookeeper 集群中。 第三层、数据转发层 这个单独的 Logstash 节点会实时去 kafka broker 集群拉数据，转发至 ES DataNode。 第四层、数据持久化存储 ES DataNode 会把收到的数据，写磁盘，建索引库。 第五层、数据检索，数据展示 ES Master + Kibana 主要协调 ES 集群，处理数据检索请求，数据展示。 笔者为了节约宝贵的服务器资源，把一些可拆分的服务合并在同一台主机。大家可以根据自己的实际业务环境自由拆分，延伸架构。 开 工 ! 操作系统环境 : CentOS release 6.5 各服务器角色分配 : jdk-8u101-linux-x64.rpm logstash-2.3.2.tar.gz filebeat-1.2.3-x86_64.rpm kafka_2.11-0.10.0.1.tgz zookeeper-3.4.9.tar.gz elasticsearch-2.3.4.rpm kibana-4.5.3-linux-x64.tar.gz 一、安装部署 Elasticsearch 集群 布置 ES Master 节点 10.10.1.244 1、安装 jdk1.8，elasticsearch-2.3.4oracle 官网 jdk 下载地址: http://www.oracle.com/technetwork/java/javase/downloads/index.html elasticsearch 官网: https://www.elastic.co/ 安装命令 yum install jdk-8u101-linux-x64.rpm elasticsearch-2.3.4.rpm -y ES 会被默认安装在 /usr/share/elasticsearch/ 2、系统调优，JVM 调优# 配置系统最大打开文件描述符数 vim /etc/sysctl.conf fs.file-max=65535 配置进程最大打开文件描述符 vim /etc/security/limits.conf # End of file \* soft nofile 65535 \* hard nofile 65535 # 配置 JVM 内存 vim /etc/sysconfig/elasticsearch ES\_HEAP\_SIZE=4g # 这台机器的可用内存为 8G 3、编写 ES Master 节点配置文件 # /etc/elasticsearch/elasticsearch.yml # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: bigdata # ------------------------------------ Node ------------------------------------ node.name: server1 node.master: true node.data: false # ----------------------------------- Index ------------------------------------ index.number\_of\_shards: 5 index.number\_of\_replicas: 0 index.refresh\_interval: 120s # ----------------------------------- Paths ------------------------------------ path.data: /home/elk/data path.logs: /var/log/elasticsearch/elasticsearch.log # ----------------------------------- Memory ----------------------------------- bootstrap.mlockall: true indices.fielddata.cache.size: 50mb #------------------------------------ Network And HTTP -------------------------- network.host: 0.0.0.0 http.port: 9200 # ------------------------------------ Translog ---------------------------------- index.translog.flush\_threshold\_ops: 50000 # --------------------------------- Discovery ------------------------------------ discovery.zen.minimum\_master\_nodes: 1 discovery.zen.ping.timeout: 200s discovery.zen.fd.ping\_timeout: 200s discovery.zen.fd.ping.interval: 30s discovery.zen.fd.ping.retries: 6 discovery.zen.ping.unicast.hosts: [&amp;quot;10.10.1.60:9300&amp;quot;,&amp;quot;10.10.1.90:9300&amp;quot;,&amp;quot;10.10.1.244:9300&amp;quot;,] discovery.zen.ping.multicast.enabled: false # --------------------------------- merge ------------------------------------------ indices.store.throttle.max\_bytes\_per\_sec: 100mb 注: path.data、path.logs 这两个参数指定的路径，如果没有需要自己创建，还要赋予权限给 elasticsearch 用户。（后面的 ES DataNode 也同样） 4、安装 head、kopf、bigdesk 开源插件 安装方法有两种 : 1、使用 ES 自带的命令 plugin# head /usr/share/elasticsearch/bin/plugin install mobz/elasticsearch-head # kopf /usr/share/elasticsearch/bin/plugin install lmenezes/elasticsearch-kopf # bigdesk /usr/share/elasticsearch/bin/plugin install hlstudio/bigdesk 2、自行下载插件的源码包安装 我们通过 plugin 命令安装的插件，其实是安装到了这个路径:/usr/share/elasticsearch/plugins 而 plugin install 命令后面跟的这一串 mobz/elasticsearch-head 其实是 github 上的一个地址。 前面加上 github 的官网地址就是 https://github.com/mobz/elasticsearch-head 可以复制到浏览器中打开，找到该插件的源码仓库。 现在知道了，想要找插件自己可以去 github 上搜一下出来一大堆。随便选一个然后取后面那串路径，用 ES 自带的命令安装。 如果安装失败了，那么就手动下载该插件的源码包。 解压后直接整个目录 mv 到 ES 的插件安装路径下。 也就是这里: /usr/share/elasticsearch/plugins/ 那如何访问安装好的插件呢？ http://ES\_server\_ip:port/\_plugin/plugin\_name Example: http://127.0.0.1:9200/\_plugin/head/ http://127.0.0.1:9200/\_plugin/kopf/ 这时，ES Master 已经配置好了。 布置 ES DataNode 节点 10.10.1.60安装和系统调优方法同上，插件不用安装，只是配置文件不同。 编写配置文件 # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: bigdata # ------------------------------------ Node ------------------------------------ node.name: server2 node.master: false node.data: true # ----------------------------------- Index ------------------------------------ index.number\_of\_shards: 5 index.number\_of\_replicas: 0 index.refresh\_interval: 120s # ----------------------------------- Paths ------------------------------------ path.data: /home/elk/data,/disk2/elk/data2 path.logs: /var/log/elasticsearch/elasticsearch.log # ----------------------------------- Memory ----------------------------------- bootstrap.mlockall: true indices.fielddata.cache.size: 50mb #------------------------------------ Network And HTTP -------------------------- network.host: 0.0.0.0 http.port: 9200 # ------------------------------------ Translog ---------------------------------- index.translog.flush\_threshold\_ops: 50000 # --------------------------------- Discovery ------------------------------------ discovery.zen.minimum\_master\_nodes: 1 discovery.zen.ping.timeout: 200s discovery.zen.fd.ping\_timeout: 200s discovery.zen.fd.ping.interval: 30s discovery.zen.fd.ping.retries: 6 discovery.zen.ping.unicast.hosts: [&amp;quot;10.10.1.244:9300&amp;quot;,] discovery.zen.ping.multicast.enabled: false # --------------------------------- merge ------------------------------------------ indices.store.throttle.max\_bytes\_per\_sec: 100mb 10.10.1.60 也准备好了。 布置另一台 ES DataNode 节点 10.10.1.90 编写配置文件 # ---------------------------------- Cluster ----------------------------------- # Use a descriptive name for your cluster: cluster.name: bigdata # ------------------------------------ Node ------------------------------------ node.name: server3 node.master: false node.data: true # ----------------------------------- Index ------------------------------------ index.number\_of\_shards: 5 index.number\_of\_replicas: 0 index.refresh\_interval: 120s # ----------------------------------- Paths ------------------------------------ path.data: /home/elk/single path.logs: /var/log/elasticsearch/elasticsearch.log # ----------------------------------- Memory ----------------------------------- bootstrap.mlockall: true indices.fielddata.cache.size: 50mb #------------------------------------ Network And HTTP -------------------------- network.host: 0.0.0.0 http.port: 9200 # ------------------------------------ Translog ---------------------------------- index.translog.flush\_threshold\_ops: 50000 # --------------------------------- Discovery ------------------------------------ discovery.zen.minimum\_master\_nodes: 1 discovery.zen.ping.timeout: 200s discovery.zen.fd.ping\_timeout: 200s discovery.zen.fd.ping.interval: 30s discovery.zen.fd.ping.retries: 6 discovery.zen.ping.unicast.hosts: [&amp;quot;10.10.1.244:9300&amp;quot;,] discovery.zen.ping.multicast.enabled: false # --------------------------------- merge ------------------------------------------ indices.store.throttle.max\_bytes\_per\_sec: 100mb 5、现在三台 ES 节点已经准备就绪，分别启动服务# 10.10.1.244 /etc/init.d/elasticsearch start # 10.10.1.60 /etc/init.d/elasticsearch start # 10.10.1.90 /etc/init.d/elasticsearch start 6、访问 head 插件，查看集群状态 此时 Elasticsearch 集群已经准备完成 二、配置位于架构图中第二层的 ZooKeeper 集群 配置 10.10.1.30 节点 1、安装，配置 zookeeper zookeeper 官网: http://zookeeper.apache.org/ # zookeeper 依赖 java，如果之前没安装过 JDK，则需要安装. rpm -ivh jdk-8u101-linux-x64.rpm # 解压程序 tar xf zookeeper-3.4.9.tar.gz 编写配置文件 # conf/zoo.cfg # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=/u01/zookeeper/zookeeper-3.4.9/data # the port at which the clients will connect clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 server.11=10.10.1.30:2888:3888 server.12=10.10.1.31:2888:3888 server.13=10.10.1.32:2888:3888 # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc\_maintenance # # The number of snapshots to retain in dataDir # autopurge.snapRetainCount=3 # Purge task interval in hours # Set to &amp;quot;0&amp;quot; to disable auto purge feature # autopurge.purgeInterval=1 同步配置文件到其他两台节点 注: zookeeper 集群，每个节点的配置文件都是一样的。所以直接同步过去，不需要做任何修改。 不熟悉 zookeeper 的朋友，可以参考这里: http://tchuairen.blog.51cto.com/3848118/1859494 scp zoo.cfg 10.10.1.31:/usr/local/zookeeper-3.4.9/conf/ scp zoo.cfg 10.10.1.32:/usr/local/zookeeper-3.4.9/conf/ 2、创建 myid 文件 # 10.10.1.30 echo 11 \&amp;gt;/usr/local/zookeeper-3.4.9/data/myid # 10.10.1.31 echo 12 \&amp;gt;/usr/local/zookeeper-3.4.9/data/myid # 10.10.1.32 echo 13 \&amp;gt;/usr/local/zookeeper-3.4.9/data/myid 3、启动服务 &amp; 查看节点状态 # 10.10.1.30 bin/zkServer.sh start bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg Mode: leader # 10.10.1.31 bin/zkServer.sh start bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg Mode: follower # 10.10.1.32 bin/zkServer.sh start bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg Mode: follower 此时 zookeeper 集群配置完成 三、配置位于架构图中第二层的 Kafka Broker 集群Kafka 官网: http://kafka.apache.org/ 不熟悉 Kafka 的朋友可以参考: http://tchuairen.blog.51cto.com/3848118/1855090 配置 10.10.1.30 节点 1、安装，配置 kafka # 解压程序 tar xf kafka\_2.11-0.10.0.1.tgz 编写配置文件 ############################# Server Basics ############################# broker.id=1 ############################# Socket Server Settings ############################# num.network.threads=3 # The number of threads doing disk I/O num.io.threads=8 # The send buffer (SO\_SNDBUF) used by the socket server socket.send.buffer.bytes=102400 # The receive buffer (SO\_RCVBUF) used by the socket server socket.receive.buffer.bytes=102400 # The maximum size of a request that the socket server will accept (protection against OOM) socket.request.max.bytes=104857600 ############################# Log Basics ############################# log.dirs=/usr/local/kafka/kafka\_2.11-0.10.0.1/data num.partitions=6 num.recovery.threads.per.data.dir=1 ############################# Log Flush Policy ############################# # The number of messages to accept before forcing a flush of data to disk #log.flush.interval.messages=10000 # The maximum amount of time a message can sit in a log before we force a flush #log.flush.interval.ms=1000 ############################# Log Retention Policy ############################# log.retention.hours=60 log.segment.bytes=1073741824 log.retention.check.interval.ms=300000 ############################# Zookeeper ############################# zookeeper.connect=10.10.1.30:2181,10.10.1.31:2181,10.10.1.32:2181 zookeeper.connection.timeout.ms=6000 注: 其他两个节点的配置文件也基本相同，只有一个参数需要修改 broker.id 。 它用于唯一标识节点，所以绝对不能相同，不然会节点冲突。 同步配置文件到其他两台节点 scp server.properties 10.10.1.31:/usr/local/kafka/kafka\_2.11-0.10.0.1/config/ scp server.properties 10.10.1.32:/usr/local/kafka/kafka\_2.11-0.10.0.1/config/ # 修改 broker.id # 10.10.1.31 broker.id=2 # 10.10.1.32 broker.id=3 2、配置主机名对应 IP 的解析 vim /etc/hosts 10.10.1.30 server1 10.10.1.31 server2 10.10.1.32 server3 # 记得同步到其他两台节点 3、启动服务 bin/kafka-server-start.sh config/server.properties # 其他两台节点启动方式相同 Kafka+ZooKeeper 集群配置完成 四、配置位于架构图中第二层的 Logstash 服务 配置 10.10.1.30 节点 1、安装，配置 logstash # 解压程序 tar xf logstash-2.3.2.tar.gz 配置 GeoLiteCity ， 用于地图显示 IP 访问的城市 官网地址: http://dev.maxmind.com/geoip/legacy/geolite/ 下载地址: http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz 解压 gunzip GeoLiteCity.dat.gz 编写配置文件 input { beats { port =\&amp;gt; 5044 codec =\&amp;gt;&amp;quot;json&amp;quot; } } filter {if[type]==&amp;quot;nginxacclog&amp;quot;{ geoip { source=\&amp;gt;&amp;quot;clientip&amp;quot;# 与日志中访问地址的 key 要对应 target =\&amp;gt;&amp;quot;geoip&amp;quot; database =\&amp;gt;&amp;quot;/usr/local/logstash/GeoLiteCity.dat&amp;quot; add\_field =\&amp;gt;[&amp;quot;[geoip][coordinates]&amp;quot;,&amp;quot;%{[geoip][longitude]}&amp;quot;] add\_field =\&amp;gt;[&amp;quot;[geoip][coordinates]&amp;quot;,&amp;quot;%{[geoip][latitude]}&amp;quot;] } mutate {convert =\&amp;gt;[&amp;quot;[geoip][coordinates]&amp;quot;,&amp;quot;float&amp;quot;] } } } output { kafka { workers =\&amp;gt; 2 bootstrap\_servers =\&amp;gt;&amp;quot;10.10.1.30:9092,10.10.1.31:9092,10.10.1.32:9092&amp;quot; topic\_id =\&amp;gt;&amp;quot;peiyinlog&amp;quot; } } 2、启动服务 /usr/local/logstash/bin/logstash agent -f logstash\_in\_kafka.conf &amp;amp; 10.10.1.31 节点的这块配置，与上述完全相同。（略） 位于第二层、数据处理层的 Logstash 配置完成 五、配置数据采集层，业务服务器 +Filebeat1、定制 Nginx 日志格式 log\_format json &amp;#39;{&amp;quot;@timestamp&amp;quot;:&amp;quot;$time\_iso8601&amp;quot;,&amp;#39; &amp;#39;&amp;quot;slbip&amp;quot;:&amp;quot;$remote\_addr&amp;quot;,&amp;#39; &amp;#39;&amp;quot;clientip&amp;quot;:&amp;quot;$http\_x\_forwarded\_for&amp;quot;,&amp;#39; &amp;#39;&amp;quot;serverip&amp;quot;:&amp;quot;$server\_addr&amp;quot;,&amp;#39; &amp;#39;&amp;quot;size&amp;quot;:$body\_bytes\_sent,&amp;#39; &amp;#39;&amp;quot;responsetime&amp;quot;:$request\_time,&amp;#39; &amp;#39;&amp;quot;domain&amp;quot;:&amp;quot;$host&amp;quot;,&amp;#39; &amp;#39;&amp;quot;method&amp;quot;:&amp;quot;$request\_method&amp;quot;,&amp;#39; &amp;#39;&amp;quot;requesturi&amp;quot;:&amp;quot;$request\_uri&amp;quot;,&amp;#39; &amp;#39;&amp;quot;url&amp;quot;:&amp;quot;$uri&amp;quot;,&amp;#39; &amp;#39;&amp;quot;appversion&amp;quot;:&amp;quot;$HTTP\_APP\_VERSION&amp;quot;,&amp;#39; &amp;#39;&amp;quot;referer&amp;quot;:&amp;quot;$http\_referer&amp;quot;,&amp;#39; &amp;#39;&amp;quot;agent&amp;quot;:&amp;quot;$http\_user\_agent&amp;quot;,&amp;#39; &amp;#39;&amp;quot;status&amp;quot;:&amp;quot;$status&amp;quot;,&amp;#39; &amp;#39;&amp;quot;devicecode&amp;quot;:&amp;quot;$HTTP\_HA&amp;quot;}&amp;#39;; # 在虚拟主机配置中调用 access\_log /alidata/log/nginx/access/access.log json; 2、安装 Filebeat Filebeat 也是 Elasticsearch 公司的产品，在官网可以下载。 # rpm 包安装 yum install filebeat-1.2.3-x86\_64.rpm -y 3、编写 Filebeat 配置文件 ################### Filebeat Configuration Example ######################### ############################# Filebeat ###################################### filebeat: prospectors: - paths: - /var/log/messages input\_type: log document\_type: messages - paths: - /alidata/log/nginx/access/access.log input\_type: log document\_type: nginxacclog - paths: - /alidata/www/logs/laravel.log input\_type: log document\_type: larlog - paths: - /alidata/www/logs/500\_error.log input\_type: log document\_type: peiyinlar\_500error - paths: - /alidata/www/logs/deposit.log input\_type: log document\_type: lar\_deposit - paths: - /alidata/www/logs/call\_error.log input\_type: log document\_type: call\_error - paths: - /alidata/log/php/php-fpm.log.slow input\_type: log document\_type: phpslowlog multiline: pattern: &amp;#39;^[[:space:]]&amp;#39; negate: true match: after registry\_file: /var/lib/filebeat/registry ############################# Output ########################################## output: logstash: hosts: [&amp;quot;10.26.95.215:5044&amp;quot;] ############################# Shipper ######################################### shipper: name: &amp;quot;host\_6&amp;quot; ############################# Logging ######################################### logging: files: rotateeverybytes: 10485760 # = 10MB 4、启动服务 /etc/init.d/filebeat start 数据采集层，Filebeat 配置完成。 现在业务服务器上的日志数据已经在源源不断的写入缓存了。 六、配置位于架构图中的第三层，数据转发层Logstash 安装上面已经讲过（略） 编写 Logstash 配置文件 # kafka\_to\_es.conf input{ kafka { zk\_connect =\&amp;gt;&amp;quot;10.10.1.30:2181,10.10.1.31:2181,10.10.1.32:2181&amp;quot; group\_id =\&amp;gt;&amp;quot;logstash&amp;quot; topic\_id =\&amp;gt;&amp;quot;peiyinlog&amp;quot; reset\_beginning =\&amp;gt;false consumer\_threads =\&amp;gt; 50 decorate\_events =\&amp;gt;true } } # 删除一些不需要的字段 filter {if[type]==&amp;quot;nginxacclog&amp;quot;{ mutate {remove\_field =\&amp;gt;[&amp;quot;slbip&amp;quot;,&amp;quot;kafka&amp;quot;,&amp;quot;domain&amp;quot;,&amp;quot;serverip&amp;quot;,&amp;quot;url&amp;quot;,&amp;quot;@version&amp;quot;,&amp;quot;offset&amp;quot;,&amp;quot;input\_type&amp;quot;,&amp;quot;count&amp;quot;,&amp;quot;source&amp;quot;,&amp;quot;fields&amp;quot;,&amp;quot;beat.hostname&amp;quot;,&amp;quot;host&amp;quot;,&amp;quot;tags&amp;quot;] } } } output {if[type]==&amp;quot;nginxacclog&amp;quot;{# stdout {codec =\&amp;gt; rubydebug} elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-nginxacclog-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 50000 idle\_flush\_time =\&amp;gt; 10 workers =\&amp;gt; 2 } } if[type]==&amp;quot;messages&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-messages-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 50000 idle\_flush\_time =\&amp;gt; 30 workers =\&amp;gt; 1 } } if[type]==&amp;quot;larlog&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-larlog-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 2000 idle\_flush\_time =\&amp;gt; 10 } } if[type]==&amp;quot;deposit&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-deposit-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 2000 idle\_flush\_time =\&amp;gt; 10 } } if[type]==&amp;quot;phpslowlog&amp;quot;{ elasticsearch {hosts =\&amp;gt;[&amp;quot;10.10.1.90:9200&amp;quot;,&amp;quot;10.10.1.60:9200&amp;quot;] index =\&amp;gt;&amp;quot;logstash-phpslowlog-%{+YYYY.MM.dd}&amp;quot; manage\_template =\&amp;gt;true flush\_size =\&amp;gt; 2000 idle\_flush\_time =\&amp;gt; 10 } } } 启动服务 /usr/local/logstash/bin/logstash agent -f kafka\_to\_es.conf &amp;amp; 数据转发层已经配置完成 这时数据已经陆陆续续的从 kafka 取出，转存到 ES DataNode。 我们登陆到任意一台 kafka 主机，查看数据的缓存和消费情况 七、修改 ES 的索引模版配置 为什么要做这一步呢？ 因为 logstash 写入数据到 ES 时，会自动选用一个索引模版。 我们可以看一下 这个模版其实也挺好，不过有一个参数，我标记出来了。 &quot;refresh_interval&quot;:&quot;5s&quot; 这个参数用于控制，索引的刷新频率。 索引的刷新频率越快，你搜索到的数据就实时。 这里是 5 秒。 一般我们日志场景不需要这么高的实时性。 可以适当降低该参数，提高 ES 索引库的写入速度。 上传自定义模版 curl -XPUT http://10.10.1.244:9200/\_template/logstash2 -d &amp;#39; { &amp;quot;order&amp;quot;:1, &amp;quot;template&amp;quot;:&amp;quot;logstash-\*&amp;quot;, &amp;quot;settings&amp;quot;:{ &amp;quot;index&amp;quot;:{&amp;quot;refresh\_interval&amp;quot;:&amp;quot;120s&amp;quot;} }, &amp;quot;mappings&amp;quot;:{ &amp;quot;\_default\_&amp;quot;:{ &amp;quot;\_all&amp;quot;:{&amp;quot;enabled&amp;quot;:false} } } }&amp;#39; 由于这个自定义模版，我把优先级 order 定义的比 logstash 模版高，而模版的匹配规则又一样，所以这个自定义模版的配置会覆盖原 logstash 模版。 我这里只是简单描述。 如果要详细理解其中道理，请查看我的 ES 调优篇。 八、配置 Kibana 数据展示层10.10.1.244 节点 Kibana 是 ELK 套件中的一员，也属于 elasticsearch 公司，在官网提供下载。 安装tar xf kibana-4.5.3-linux-x64.tar.gz # 很简单，只要解压就可以用。 修改配置文件 # vim kibana-4.5.3-linux-x64/config/kibana.yml # Kibana is served by a back end server. This controls which port to use. server.port: 5601 # The host to bind the server to. server.host: &amp;quot;0.0.0.0&amp;quot; # The Elasticsearch instance to use for all your queries. elasticsearch.url: &amp;quot; # 修改这三个参数就好了 启动服务 打开浏览器访问: http://10.10.1.244:5601/ 定制 Elasticsearch 索引的 Index pattern 默认情况下，Kibana 认为你要访问的是通过 Logstash 导入 Elasticsearch 的数据，这时候你可以用默认的 logstash-* 作为你的 index pattern。 通配符（*）匹配索引名中任意字符任意个数。 选择一个包含了时间戳的索引字段（字段类型为 date 的字段），可以用来做基于时间的处理。Kibana 会读取索引的 映射，然后列出所有包含了时间戳的字段。如果你的索引没有基于时间的数据. 关闭 Index contains time-based events 参数。 如果一个新索引是定期生成，而且索引名中带有时间戳，选择 Use event times to create index names 选项， 然后再选择 Index pattern interval 。这可以提高搜索性能，Kibana 会至搜索你指定的时间范围内的索引。在你用 Logstash 输出数据给 Elasticsearch 的情况下尤其有效。 由于我们的索引是用日期命名，按照每天分割的。 index pattern 如下 数据展示 完 工 !]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 私库 Nexus3 搭建使用]]></title>
    <url>%2F2018%2F06%2F20%2FMaven%E7%A7%81%E5%BA%93Nexus3%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Maven 私库 nexus3 搭建使用docker 安装 sonatype/nexus31. 创建挂载目录 mkdir -p v-nexus/data 并修改目录权限 chown -R 200 v-nexus/data 2. 创建部署脚本 # 默认用户名 admin/admin123 version: &apos;3.2&apos; services: nexus: restart: always image: sonatype/nexus3 ports: #自定义端口 - target: 8081 published: 18081 #只有 worker 能访问该端口 protocol: tcp mode: host #版本要求 3.2 volumes: - &quot;/dockerdata/v-nexus/data:/nexus-data&quot; deploy: replicas: 1 restart_policy: condition: on-failure placement: constraints: [node.hostname == lfadmin] 3. 测试访问http://192.168.1.213:18081/ 然后输入 admin 和 admin123 进行登陆即可 ##win10 下 maven 安装 1. 下载 apache-maven-3.5.4-bin.zip 然后解压 2. 添加环境变量, 新建系统环境变量 Maven_HOME 值为解压路径，编辑 path 环境变量添加 %Maven_HOME%\bin 3. 命令窗口测试 mvn -v，只支持 cmd 4. 修改 apache-maven-3.5.4\conf\settings.xml 文件 &lt;!--jar 本地缓存地址 --&gt; &lt;localRepository&gt;D:\MavenRepository&lt;/localRepository&gt; 完整的 setting.xml 设置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;!-- jar 本地缓存地址 --&gt; &lt;localRepository&gt;D:\MavenRepository&lt;/localRepository&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;servers&gt; &lt;!-- 配置权限, 使用默认用户 --&gt; &lt;server&gt; &lt;!-- 这里的 id 要和项目里的 pom.xml 的 id 一致 --&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;MyNexus&lt;/id&gt; &lt;activation&gt; &lt;jdk&gt;1.4&lt;/jdk&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;!-- 私有库地址 --&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;&gt;Nexus3 Repository&lt;/name&gt; &lt;!-- 注意修改成对应的 IP, 在 nexus 里面复制 public 里面的地址 --&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;!-- snapshots 默认是关闭的，需要手动开启 --&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!-- 插件库地址 --&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 激活 profile--&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;MyNexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;/settings&gt; 6. 在项目的 pom.xml 修改或添加如下配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project ...&gt; .... &lt;!-- 配置 maven 地址 --&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;!-- 这里的 id 要和 maven 里的的 settings.xml 的 id 一致 --&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.1.213:18081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; ... &lt;/project&gt; 7. 编译在 cmd 执行 mvn install 发布上传 jar 执行 mvn deploy，可以到 nexus 地址进行检查 8. 使用私库下载和上传是一样的 nexus3 配置阿里云代理仓库1. 点击Create Repository-&gt;maven2(proxy) 2. 添加名字 aliyun-proxy 设置阿里云 url 地址http://maven.aliyun.com/nexus/content/groups/public 3. 设置阿里云优先级，在 maven-public 里面的 group 把刚刚创建的添加过去并移到 maven-central 上面 4. 设置允许发布 release, 在 maven-release 的 hosted 里面选择 allow redeploy 发布上传 jar 包到 nexus语法： mvn deploy:deploy-file \ -DgroupId=&lt;group-id&gt; \ -DartifactId=&lt;artifact-id&gt; \ -Dversion=&lt;version&gt; \ -Dpackaging=&lt;type-of-packaging&gt; \ -Dfile=&lt;path-to-file&gt; \ -DrepositoryId=&lt; 这里的 id 要和 maven 里的的 settings.xml 的 id 一致 &gt; \ -Durl=&lt;url-of-the-repository-to-deploy&gt; 实战 mvn deploy:deploy-file \ -Dfile=spring-boot-starter-druid-0.0.1-SNAPSHOT.jar \ -DgroupId=cn.binux \ -DartifactId=spring-boot-starter-druid \ -Dversion=0.0.1-SNAPSHOT \ -Dpackaging=jar \ -DpomFile=spring-boot-starter-druid-0.0.1-SNAPSHOT.pom \ -DrepositoryId=nexus-snapshots \ -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ 上传 jar 包到私有 maven 仓库 mvn deploy:deploy-file -Dfile=spring-boot-starter-druid-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-druid -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar -DpomFile=spring-boot-starter-druid-0.0.1-SNAPSHOT.pom -DrepositoryId=nexus-snapshots -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ mvn deploy:deploy-file -Dfile=spring-boot-starter-dubbox-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-dubbox -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar -DpomFile=spring-boot-starter-dubbox-0.0.1-SNAPSHOT.pom -DrepositoryId=nexus-snapshots -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ mvn deploy:deploy-file -Dfile=spring-boot-starter-redis-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-redis -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar -DpomFile=spring-boot-starter-redis-0.0.1-SNAPSHOT.pom -DrepositoryId=nexus-snapshots -Durl=http://192.168.1.213:18081/repository/maven-snapshots/ #这个不是 snapshots 要发布到 releases，注意设置 nexus 为允许发布，看 jar 报后缀，没有 `SNAPSHOT` 就是 release mvn deploy:deploy-file -Dfile=dubbo-2.8.4.jar -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4 -Dpackaging=jar -DrepositoryId=nexus-releases -Durl=http://192.168.1.213:18081/repository/maven-releases/ mvn deploy:deploy-file -Dfile=fastdfs-1.24.jar -DgroupId=org.csource -DartifactId=fastdfs -Dversion=1.24 -Dpackaging=jar -DrepositoryId=nexus-releases -Durl=http://192.168.1.213:18081/repository/maven-releases/ mvn deploy:deploy-file -Dfile=examples-1.0.jar -DgroupId=com.haikang -DartifactId=examples -Dversion=1.0 -Dpackaging=jar -DrepositoryId=nexus-releases -Durl=http://192.168.1.230:18081/repository/maven-releases/ 本地安装 jar 包到本地 maven 仓库 mvn install:install-file -Dfile=spring-boot-starter-druid-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-druid -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar mvn install:install-file -Dfile=spring-boot-starter-dubbox-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-dubbox -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar mvn install:install-file -Dfile=spring-boot-starter-redis-0.0.1-SNAPSHOT.jar -DgroupId=cn.binux -DartifactId=spring-boot-starter-redis -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar mvn install:install-file -Dfile=dubbo-2.8.4.jar -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4 -Dpackaging=jar mvn install:install-file -Dfile=fastdfs-1.24.jar -DgroupId=org.csource -DartifactId=fastdfs -Dversion=1.24 -Dpackaging=jar 问题 下载了找不到包，解决，删除项目重新导入，重新 maven 依赖 刚上传或添加了新的 jar 到私库，无法下载，解决，删除本地仓库的该包目录]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 3 爬取百度经验数据]]></title>
    <url>%2F2018%2F05%2F24%2FPython%203%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%BB%8F%E9%AA%8C%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[安装环境准备 直接使用 win10 的 wsl 沙盒 Ubuntu 系统，自带 python3.5 安装 apt install python3-pip pip3 install rsa 注意事项IndentationError: unexpected indent 检查缩进是否一致，空格和 Tab 符号注意区分 ## 实战 通过 cookie 爬百度数据1. 登陆百度，通过浏览器设置 - 内容管理 -cookie，找到百度的 BDUSS 的内容复制 2. 编写脚本 login.py import requests #需要爬数据的 url url = &apos;http://i.baidu.com/&apos; #浏览器访问网站的 cookie 信息 cookie = {&quot;BDUSS&quot;:&quot;----------------------------------------------------AAAAAAAAAAA----------------AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA--&quot;} #requests 请求，获取登录网站页面的内容 html = requests.get(url,cookies=cookie).content #print(html) #把内容保存为文件 with open(&quot;baidu.html&quot;, &apos;wb&apos;) as f: f.write(html) f.close() 3. 在 Ubuntu bash 执行 python3 login.py，会生成一个文件 baidu.html 在当前目录, 打开如果能看到个人信息就证明获取成功 爬百度翻页数据 上面已经登陆成功了，下面直接用 cookie 进行爬数据会被重定向，还需要添加请求头，以及翻页参数 import requests #需要爬数据的 url url = &apos;https://jingyan.baidu.com/user/nucpage/content&apos; #浏览器访问网站的 cookie 信息 cookie = {&quot;BDUSS&quot;:&quot;-----QAAAAAAAAAAAEAAA--1QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA---&quot;} #提供你所使用的浏览器类型、操作系统及版本、CPU 类型、浏览器渲染引擎、浏览器语言、浏览器插件等信息的标识 user_agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot; # 从那个连接来的 referer=&quot;https://jingyan.baidu.com/user/nucpage/content&quot; # 设置请求头 headers = { &quot;User-Agent&quot;: user_agent, &quot;Referer&quot;: referer } # url 参数 # https://jingyan.baidu.com/user/nucpage/content?tab=exp&amp;expType=published&amp;pn=20 params = { &apos;tab&apos;: &apos;exp&apos;, &apos;expType&apos;: &apos;published&apos;, &apos;pn&apos;: &apos;30&apos; } #requests 请求，获取登录网站页面的内容 html = requests.get(url,cookies=cookie,headers=headers).content #print(html) #把内容保存为文件 with open(&quot;baidu.html&quot;, &apos;wb&apos;) as f: f.write(html) f.close() 最终版爬百度经验的个人经验数据import requests #正则 import re #需要爬数据的 url url = &apos;https://jingyan.baidu.com/user/nucpage/content&apos; #浏览器访问网站的 cookie 信息 cookie = {&quot;BDUSS&quot;:&quot;--AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA-&quot;} #提供你所使用的浏览器类型、操作系统及版本、CPU 类型、浏览器渲染引擎、浏览器语言、浏览器插件等信息的标识 user_agent=&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot; # 从那个连接来的 referer=&quot;https://jingyan.baidu.com/user/nucpage/content&quot; # 设置请求头 headers = { &quot;User-Agent&quot;: user_agent, &quot;Referer&quot;: referer } #requests 请求, 获取发布数量 published = requests.get(url,cookies=cookie,headers=headers).content #&lt;li&gt;&lt;a class=&quot;on&quot; href=&quot;/user/nucpage/content&quot;&gt; 已发布 (505)&lt;/a&gt;&lt;/li&gt; reg=r&apos;&lt;li&gt;&lt;a class=&quot;on&quot; href=&quot;/user/nucpage/content&quot;&gt; 已发布 \((.*?)\)&lt;/a&gt;&lt;/li&gt;&apos; publishedNum=re.search(reg,published.decode(),re.I|re.M|re.S).group(1) #group(0) 匹配的串，group(1) 匹配的串中第一个括号 print(publishedNum) #算页数, 实际篇数 -1 pages=int((int(publishedNum)-1)/20)+1 print(pages) #把内容保存为文件,&apos;w&apos; 是写，&apos;wb&apos; 是写入 byte with open(&quot;jingyan.md&quot;, &apos;w&apos;) as f: for page in range(0,pages): pn=page*20 print(pn) # url 参数 # https://jingyan.baidu.com/user/nucpage/content?tab=exp&amp;expType=published&amp;pn=20 params = { &apos;tab&apos;: &apos;exp&apos;, &apos;expType&apos;: &apos;published&apos;, &apos;pn&apos;: pn } #requests 请求，获取登录网站页面的内容 html = requests.get(url,cookies=cookie,headers=headers,params=params).content #过滤 reg=r&apos;&lt;a class=&quot;f14&quot; target=&quot;_blank&quot; title=(.*?)&gt;&apos; #re.I 使匹配对大小写不敏感 #re.M 多行匹配，影响 ^ 和 $ #re.S 使 . 匹配包括换行在内的所有字符 #这个是查找此字符串中所有符合条件的内容并返回一个列表 list=re.findall(reg,html.decode(),re.I|re.M|re.S) #写入文件并替换为 markdown 格式 for item in list: item=item.replace(&apos;&quot; href=&quot;&apos;,&apos;](https://jingyan.baidu.com&apos;) item=item.replace(&apos;.html&quot;&apos;,&apos;.html)&apos;) item=item.replace(&apos;&quot;&apos;,&apos;[&apos;) f.write(&quot;%s\n&quot; % item) f.close() 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考： Python：网页的抓取、过滤和保存]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-JVM 参数详解]]></title>
    <url>%2F2018%2F04%2F10%2FJava-JVM%2F</url>
    <content type="text"><![CDATA[JVM 基本参数 -Xmx: 运行最大内存（memory maximum） 是指设定程序运行期间最大可占用的内存大小。如果程序运行需要占用更多的内存，超出了这个设置值，就会抛出 OutOfMemory 异常。堆的最大内存数，等同于 -XX:MaxHeapSize -Xms：启动内存(memory startup) 是指设定程序启动时占用内存大小。一般来讲，大点，程序会启动的快一点，但是也可能会导致机器暂时间变慢。堆的初始化初始化大小 -Xmn：(memory nursery/new) 堆中新生代初始及最大大小，如果需要进一步细化，初始化大小用 -XX:NewSize，最大大小用 -XX:MaxNewSize -Xss：(stack size) 线程栈大小，等同于 -XX:ThreadStackSize jvm 设置的值查看 执行 ps -ef | grep tomcat 或ps -ef | grep java输出如下 root 1882 1 0 8 月 02 ? 01:39:42 /root/SoftwareInstall/jdk/bin/java -Djava.util.logging.config.file=/usr/local/tomcat-geoserver/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -Xms3072M -Xmx3072M -Xmn512M -Xss512k -XX:+AggressiveOpts - ..... org.apache.catalina.startup.Bootstrap start 如果没有设置，默认是不会有 -Xms3072M -Xmx3072M -Xmn512M -Xss512k 值打印 docker-compose 设置 jvmenvironment: - JAVA_OPTS= &apos;-Xmx3072m&apos; JVM 问题总结 geoserver 添加图层预览时提示java.lang.OutOfMemoryError: GC overhead limit exceeded 该错误 解决把 -Xmx 设置更大]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-3.0.X 安装 Graphtree【转】]]></title>
    <url>%2F2016%2F12%2F05%2FZabbix-3.0.X%20%E5%AE%89%E8%A3%85Graphtree%2F</url>
    <content type="text"><![CDATA[Zabbix-3.0.X 安装 Graphtreezabbix本文转载http://blog.csdn.net/wh211212/article/details/52735180 Zabbix 中，想要集中展示图像，唯一的选择是 screen，后来zatree 解决了 screen 的问题，但性能不够好。Graphtree 由 OneOaaS 开发并开源出来，用来解决 Zabbix 的图形展示问题，性能较好。 提示：zatree 不支持 3.x 和 3.2 暂时只支持 2.4 一、Graphtree 功能概述 ▲ 集中展示所有分组设备 ▲ 集中展示一个分组图像 ▲ 集中展示一个设备图像 ▲ 展示设备下的 Application ▲ 展示每个应用下的图像 ▲ 展示每个应用下的日志 ▲ 对原声无图的监控项进行绘图 注意事项： 主机和组级别下，默认只显示系统初始的图形 二、Zabbix 版本要求：3.0.x提示：暂时只支持 3.0 版本，根据测试不支持 3.2 版本 1、插件安装 Zabbix-web 目录 提示：如果是 yum 安装并且是 centos7 目录会在 /usr/share/zabbix 可以使用 find 进行查找 cd /usr/local/nginx/html/zabbix 下载 Graphtree 补丁包 wget https://raw.githubusercontent.com/OneOaaS/graphtrees/master/graphtree3-0-1.patch 安装 Linux 下打补丁命令 patch yum -y install patch 打补丁 patch -Np0 &lt; graphtree3-0-1.patch 三、Graphtree 效果图1、删除提示信息vim /usr/local/nginx/html/zabbix/graphtree.right.php 根据自己的路径进行修改 d7d #删除 344-350 行 2、重启载入 Zabbix-web，可以看到 Graphtree 已出效果 转自：Zabbix-3.0.X 安装 Graphtree]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix_sender 介绍及配置【转】]]></title>
    <url>%2F2016%2F11%2F28%2FZabbix_sender%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zabbix_sender 是什么? 有什么作用？ zabbix 获取 key 值 有超时时间，如果自定义的 key 脚本一般需要执行很长时间，这根本没法去做监控，那怎么办呢？这时候就需要使用 zabbix 监控类型 zabbix trapper，配合zabbix_sender 给它传递数据。所以说 zabbix_sender 是更新 items 值 最快的方式 安装 在 centos5 上安装rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/5/x86_64/zabbix-sender-3.0.5-1.el5.x86_64.rpm 在 centos6 上安装 zabbix_senderrpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/6/x86_64/zabbix-sender-3.0.5-1.el6.x86_64.rpm 在 centos7 上安装 zabbix_senderrpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-sender-3.0.5-1.el7.x86_64.rpm 命令解释 zabbix_sender 命令详解 最简易使用方法一: zabbix_sender -z server -s host -k key -o value 最简易使用方法二： zabbix_sender -c config-file -k key -o value 最简易使用方法三： zabbix_sender -z server -i file 更多的使用方法可以man zabbix_sender 主要的使用参数 -c --config &lt;file&gt; zabbix_agent 配置文件绝对路径 -z --zabbix-server &lt;server&gt; zabbix server 的 IP 地址 -p --port &lt;server port&gt; zabbix server 端口. 默认 10051 -s --host &lt;hostname&gt; 主机名，与 zabbix_server web 上主机的 hostname 一致 例如 -I --source-address &lt;IP address&gt; 源 IP -k --key &lt;key&gt; 监控项的 key -o --value &lt;key value&gt;key 值 -i --input-file &lt;input file&gt; 从文件里面读取 hostname、key、value 一行为一条数据，使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来 -r --real-time 将数据实时提交给服务器 -v --verbose 详细模式, -vv 更详细 案例 下面：我们创建一个监控项item zabbix_sender -z 192.168.56.11 -s 192.168.56.100 -k login.users -o 111 如下图所示 检验 -o的值也可以引用命令： [root@muban ~]# zabbix_sender -z 192.168.56.11 -s 192.168.56.100 -k login.users -o $(w|sed &apos;1,2d&apos;|wc -l) 使用 zabbix_sender 批量发送 首先多准备几个 zabbix_trapper 类型的监控项 编写批量列表，每行以 hostname、key、value 的方式 [root@muban ~]# cat f.txt 192.168.56.100 login.users 12 192.168.56.100 login.users1 13 192.168.56.100 login.users2 14 192.168.56.100 login.users3 15 测试 zabbix_sender -z 192.168.56.11 -i f.txt 转自：Zabbix_sender 介绍及配置]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix Web 邮件报警【转】]]></title>
    <url>%2F2016%2F11%2F27%2FZabbix%20Web%20%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[zabbix 3.0 版本系列会造成无法使用 smtp 进行报警我们可以使用邮件报警，可以参考文章Zabbix 使用脚本发送邮件 完整配置邮件步骤如下： 首先点击配置，选择报警媒介，点击邮件[Email] 提示：这里的密码不是 QQ 登陆密码，而是 QQ 邮箱的授权密码 设置收件人邮箱 设置发送邮件动作 此处注意如果没有开启需要开启，要确保状态是 Enabled 这里可以设置脚本内容，我们默认就行 测试 我自己服务器安装 zabbix 3.2(3.2 安装文档)，zabbix 3.2 有默认的网卡监控，我设置一个超过 10M 报警的动作。我们可以看邮件如下 报警邮件 恢复邮件 谁要在说发送不了邮件，我打死他！ 转自：Zabbix Web 邮件报警]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 自动化监控 [十]【转】]]></title>
    <url>%2F2016%2F11%2F25%2FZabbix%203.0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E7%9B%91%E6%8E%A7%20%5B%E5%8D%81%5D%2F</url>
    <content type="text"><![CDATA[自动化分类 所有的自动化都可以分为 2 种 1. 自动注册 Zabbix agnet 自动添加 2. 主动发现 1. 自动发现 Discover 2.zabbix api 因为我们只有 2 台web，为了方便演示。我们将原来添加的 proxy 删掉. 提示： 主动模式下设置自动注册 一、自动注册设置agent 配置文件修改 [root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf LogFileSize=0 StartAgents=0 Server=192.168.56.11 ServerActive=192.168.56.11 Hostname=192.168.56.11 HostMetadata=system.uname #Server IP 地址 HostMetadataItem=system.uname #特征 1. 可以我们自己写一个特征 2. 我们执行一个 key #手写级别大于执行 key 过滤出我们的配置[如下] [root@CentOS6 zabbix]# egrep -v &quot;#|^$&quot; zabbix_agentd.conf PidFile=/var/run/zabbix/zabbix_agentd.pid LogFile=/var/log/zabbix/zabbix_agentd.log LogFileSize=0 StartAgents=0 Server=192.168.56.11 ServerActive=192.168.56.11 Hostname=192.168.56.12 HostMetadata=system.uname Include=/etc/zabbix/zabbix_agentd.d/ 我们先不重启，因为重启就生效了。我们需要设置一个规则. 注意自动发现必须要设置 ServerActive 让客户端启动主动去寻找服务端 提示，zabbix-agent 起来的时候去找 server，这时候就会产生一个事件，然后我们可以基于这个事件来完成一个动作 提示： zabbix-agent 起来的时候回去找 Server，这时候就会产生一个事件，然后我们可以基于这个事件来完成一个动作。 我们需要选中，然后在进行创建 如果选项匹配到 Linux，为什么匹配 Linux 呢？ 因为 Linux 可以在输入任何命令都可以生成 [root@linux-node2 ~]# uname Linux [root@linux-node2 ~]# uname -a Linux linux-node2.example.com 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux 提示： 需要点击小的 Add 才可以继续操作 设置操作 我们先点击Add，在选择Host 我们在添加一个主机组，随便选一个就可以。 我们在添加一个模板 解释： 这样设置后我发现你这台主机我会给你设置一个主机组和一个模板。并且是 Linux 最后我们选择 Add 修改完之后我们在 重启 一下 [root@linux-node2 ~]# systemctl restart zabbix-agent.service 如果还没有出来，我们可以稍等一会 自动注册完! ————————分割线———————- 二、自动发现设置 因为我们的服务器只用了 2 台，所以昨晚 自动注册 我们在把它停掉。要不总会影响我们 我们在删除刚刚添加的主机 自动发现可以去扫描 IP 地址范围（需要手动设置）进行发现的动作 官方说明： https://www.zabbix.com/documentation/3.0/manual/discovery/network_discovery 创建 Zabbix 自动发现（生产一般不用） 唯一的标识我们可以设置 IP 地址，或者 key 值 然后我们创建一个Action(动作) 现在它自己就添加上去了 三、API 介绍 Zabbix 提供了一个丰富的 API，Zabbix 提供的 API 有2种功能。 一个是管理 一个是查询 请求方法 POST我们可以进行访问查看 无法打开，我们需要进行 POST 请求才可以。官方说明文档：https://www.zabbix.com/documentation/3.0/manual/api curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;user.login&quot;, &quot;params&quot;: { &quot;user&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;123456&quot; }, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool -d 请求的内容 -H 类型 id 名字，类似一个标识 user 我们登陆用的是 zhangsan 默认是 Admin password 默认是 zabbix，我们修改为 123456 了 [root@linux-node1 ~]# curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; &gt; { &gt; &quot;jsonrpc&quot;: &quot;2.0&quot;, &gt; &quot;method&quot;: &quot;user.login&quot;, &gt; &quot;params&quot;: { &gt; &quot;user&quot;: &quot;zhangsan&quot;, &gt; &quot;password&quot;: &quot;123456&quot; &gt; }, &gt; &quot;id&quot;: 1 &gt; }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool -------------------------- 分割线 ------------------------ 下面是返回的结果！！！！！！！！！！！！！！！！！！！！！！ { &quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot; } 例如：我们获取所有主机的列表 官方文档：https://www.zabbix.com/documentation/3.0/manual/api/reference/host/get curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;host.get&quot;, &quot;params&quot;: {&quot;output&quot;: [&quot;host&quot;] }, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 提示： auth 里面填写的是我们刚刚返回的 result 里面的值, 如果我们在 [&quot;hostid&quot;] 加上 id 就会显示id。想全显示主机名就直接写host [root@linux-node1 ~]# curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;host.get&quot;, &quot;params&quot;: {&quot;output&quot;: [&quot;host&quot;] }, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool { &quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: [ { &quot;host&quot;: &quot;Zabbix server&quot;, &quot;hostid&quot;: &quot;10084&quot; }, { &quot;host&quot;: &quot;linux-node1.example.com&quot;, &quot;hostid&quot;: &quot;10105&quot; }, { &quot;host&quot;: &quot;linux-node1.example.com1&quot;, &quot;hostid&quot;: &quot;10107&quot; }, { &quot;host&quot;: &quot;linux-node2.example.com&quot;, &quot;hostid&quot;: &quot;10117&quot; } ] } 对比图 例如：如何获取模板 官方文档：https://www.zabbix.com/documentation/3.0/manual/api/reference/template/get curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;template.get&quot;, &quot;params&quot;: {&quot;output&quot;: &quot;extend&quot;}, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 默认太多不发了，看图！ 过滤 过滤主机有 OS LINUX 的模板 curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;template.get&quot;, &quot;params&quot;: { &quot;output&quot;: &quot;extend&quot;, &quot;filter&quot;: { &quot;host&quot;: [&quot;Template OS Linux&quot;] } }, &quot;auth&quot;: &quot;d8286f586348b96b6b0f880db3db8a02&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 效果图如下！ 我们提供一个快速认证的 Python 脚本 链接：http://pan.baidu.com/s/1gf0pQwF 密码：m7dq 脚本内容如下 [root@linux-node1 ~]# cat zabbix_auth.py #!/usr/bin/env python # -*- coding:utf-8 -*- import requests import json url = &apos;http://192.168.56.11/zabbix/api_jsonrpc.php&apos; post_data = { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;user.login&quot;, &quot;params&quot;: { &quot;user&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;123123&quot; }, &quot;id&quot;: 1 } post_header = {&apos;Content-Type&apos;: &apos;application/json&apos;} ret = requests.post(url, data=json.dumps(post_data), headers=post_header) zabbix_ret = json.loads(ret.text) if not zabbix_ret.has_key(&apos;result&apos;): print &apos;login error&apos; else: print zabbix_ret.get(&apos;result&apos;) 我们可以执行一下进行查看 提示： 需要修改里面的 用户名 和密码！ # 安装 python 环境 [root@linux-node1 ~]# yum install python-pip -y [root@linux-node1 ~]# pip install requests You are using pip version 7.1.0, however version 8.1.2 is available. You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. Collecting requests Downloading requests-2.11.1-py2.py3-none-any.whl (514kB) 100% |████████████████████████████████| 516kB 204kB/s Installing collected packages: requests Successfully installed requests-2.11.1 ################################################ ################################################ ################################################ 执行结果 [root@linux-node1 ~]# python zabbix_auth.py 5b21317186f2a47404214556c5c1d846 四、案例：使用 API 进行自动添加主机 首先我们需要删除主机和自动发现 我们使用 API 来实现自动添加监控主机 使用 API 添加主机：https://www.zabbix.com/documentation/3.0/manual/api/reference/host/create curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; { &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;host.create&quot;, &quot;params&quot;: { &quot;host&quot;: &quot;Zabbix agent 192&quot;, &quot;interfaces&quot;: [ { &quot;type&quot;: 1, &quot;main&quot;: 1, &quot;useip&quot;: 1, &quot;ip&quot;: &quot;192.168.56.12&quot;, &quot;dns&quot;: &quot;&quot;, &quot;port&quot;: &quot;10050&quot; } ], &quot;groups&quot;: [ {&quot;groupid&quot;: &quot;8&quot;} ], &quot;templates&quot;: [ {&quot;templateid&quot;: &quot;10001&quot;} ] }, &quot;auth&quot;: &quot;5b21317186f2a47404214556c5c1d846&quot;, &quot;id&quot;: 1 }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool 用户组 ID 获取方法 模板 IP 查看方法 执行结果如下： [root@linux-node1 ~]# curl -s -X POST -H &apos;Content-Type:application/json-rpc&apos; -d&apos; &gt; { &gt; &quot;jsonrpc&quot;: &quot;2.0&quot;, &gt; &quot;method&quot;: &quot;host.create&quot;, &gt; &quot;params&quot;: { &gt; &quot;host&quot;: &quot;Zabbix agent 192&quot;, &gt; &quot;interfaces&quot;: [ &gt; { &gt; &quot;type&quot;: 1, &gt; &quot;main&quot;: 1, &gt; &quot;useip&quot;: 1, &gt; &quot;ip&quot;: &quot;192.168.56.12&quot;, &gt; &quot;dns&quot;: &quot;&quot;, &gt; &quot;port&quot;: &quot;10050&quot; &gt; } &gt; ], &gt; &quot;groups&quot;: [ &gt; { &gt; &quot;groupid&quot;: &quot;8&quot; &gt; } &gt; ], &gt; &quot;templates&quot;: [ &gt; { &gt; &quot;templateid&quot;: &quot;10001&quot; &gt; } &gt; ] &gt; }, &gt; &quot;auth&quot;: &quot;5b21317186f2a47404214556c5c1d846&quot;, &gt; &quot;id&quot;: 1 &gt; }&apos; http://192.168.56.11/zabbix/api_jsonrpc.php | python -m json.tool { &quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: { &quot;hostids&quot;: [&quot;10118&quot;] } } 查看 Zabbix 页面 提示： 里面的主机名 / 模板 都是我们设置好的 Zabbix 完！ 转自：Zabbix 3.0 自动化监控 [十]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 分布式监控 [九]【转】]]></title>
    <url>%2F2016%2F11%2F21%2FZabbix%203.0%20%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7%20%5B%E4%B9%9D%5D%2F</url>
    <content type="text"><![CDATA[Zabbix Proxy是一个类似于代理的服务，可以代替 Zabbix-server 获取 zabbix-agent信息。其中 数据 存到本地（Proxy 有自己的数据库）然后在发送给 Server，这样可以保证数据不丢失 Zabbix-server -----&gt;Zabbix-Proxy -----&gt;Zabbix-Server 地址：https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies Zabbix Proxy 使用场景 常用于多机房情况或者监控主机特别多，几千台左右。这时候使用Zabbix Proxy 可以减轻服务器server 的压力，还可以减轻 Zabbix 的维护。 最常用的特点是适用于 多机房 、 网络不稳定 的时候，因为如果直接由 Zabbix-server 发送信息可能 agent 没有收到，但是直接使用 Zabbix-Proxy 就不会遇到这个问题。 Zabbix 官方说明（分布式监控）Proxy 有如下功能 地址： Distributed monitoring NO - 中文解释 1. 没有 Web 界面 2. 本身不做任何告警通知（告警通知都是 Server 做） 小结： Zabbix Proxy 可以有多个，用来代理 Zabbix server 来运行。Proxy会将所有数据暂存于本地, 然后同一转发到 Zabbix Server 上 Proxy 只需要一条 TCP 链接，可以连接到 Zabbix-server 上即可。所以防火墙只需要添加一条 Zabbix Proxy 即可 我们可以参考上面的Zabbix Proxy 图 Proxy 是需要使用单独的 数据库 ，所以不能将Server 和Agent放在一起 Proxy 说明：https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies 安装文档：https://www.zabbix.com/documentation/3.0/manual/installation/install 官方文档使用的是源码安装，因为方便我们使用 yum 安装，因为我们只有 2 台，所以就用 agent 当做 Proxy [root@linux-node2 ~]# yum install -y zabbix-proxy zabbix-proxy-mysql mariadb-server 我们需要启动 MySQL [root@linux-node2 ~]# systemctl start mariadb.service 我们还需要创建一个库 mysql create database zabbix_proxy character set utf8; grant all on zabbix_proxy.* to zabbix_proxy@localhost identified by &apos;zabbix_proxy&apos;; 我们需要导入数据 [root@linux-node2 ~]# cd /usr/share/doc/zabbix-proxy-mysql-3.0.5/ [root@linux-node2 zabbix-proxy-mysql-3.0.5]# zcat schema.sql.gz | mysql -uzabbix_proxy -p zabbix_proxy Enter password: #密码是：zabbix_proxy 是我们数据库授权的密码 检查数据库 mysql show databases; use zabbix_proxy; show tables; #查看是否含有数据 我们需要修改 proxy 的配置文件 [root@linux-node2 zabbix-proxy-mysql-3.0.5]# vim /etc/zabbix/zabbix_proxy.conf Server=192.168.56.11 Hostname=Zabbix proxy DBName=zabbix_proxy #数据库名称 DBUser=zabbix_proxy #用户名 DBPassword=zabbix_proxy #用户密码 配置文件中没有配置的内容如下：（有需要可以配置） # ProxyLocalBuffer=0 #数据保留的时间（小时为单位） # ProxyOfflineBuffer=1 #连不上 Server，数据要保留多久（小时为单位，默认 1 小时） # DataSenderFrequency=1 #数据的发送时间间隔（默认是 1 秒） # StartPollers=5 #启动的线程数 # StartIPMIPollers=0 #启动 IPMI 的线程数 从这往下都是性能的监控，就不一次说明了。 上面都有中文注释 过滤修改过的配置如下： [root@linux-node2 zabbix-proxy-mysql-3.0.5]# grep &apos;^[a-Z]&apos; /etc/zabbix/zabbix_proxy.conf Server=192.168.56.11 Hostname=Zabbix proxy LogFile=/var/log/zabbix/zabbix_proxy.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_proxy.pid DBName=zabbix_proxy DBUser=zabbix_proxy DBPassword=zabbix_proxy SNMPTrapperFile=/var/log/snmptrap/snmptrap.log Timeout=4 ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 启动 [root@linux-node2 ~]# systemctl start zabbix-proxy 查看 proxy 进程 [root@linux-node2 ~]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:33060.0.0.0:* LISTEN 15685/mysqld tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 15924/zabbix_proxy tcp6 0 0 :::44589:::*LISTEN 9052/java tcp6 0 0 :::8080 :::*LISTEN 9052/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 :::8888 :::*LISTEN 9052/java tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::39743:::*LISTEN 9052/java tcp6 0 0 :::10051:::*LISTEN 15924/zabbix_proxy tcp6 0 0 127.0.0.1:8005 :::*LISTEN 9052/java tcp6 0 0 :::8009 :::*LISTEN 9052/java Zabbix-proxy 监控 10051 端口，因为是代理就必须跟 Server 的端口相同，对于 Agent Proxy 就是 Server Zabbix Web 添加 点击 Add 即可 我们需要将这台主机的 Server 设置为 Proxy编辑 192.168.56.12 这台主机，需要将 Server 的IP 地址修改成自己的 因为现在是主动模式，我们只需要修改主动模式的 Server 即可 [root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf ServerActive=192.168.56.12 #配置文件修改完需要重启 [root@linux-node2 ~]# systemctl restart zabbix-agent 这时候我们就可以看到那个 proxy 都管理了那些机器, 做到方便管理的机制 proxy 简单的理解就是一个 Server 完！ 转自：Zabbix 3.0 分布式监控 [九]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 主备模式 [八]【转】]]></title>
    <url>%2F2016%2F11%2F20%2FZabbix%203.0%20%E4%B8%BB%E5%A4%87%E6%A8%A1%E5%BC%8F%20%5B%E5%85%AB%5D%2F</url>
    <content type="text"><![CDATA[监控常遇到的问题？ 1. 监控主机多，性能跟不上，延迟大 2. 多机房，防火墙因素 Zabbix 轻松解决以上问题，Nagios 不太好解决的问题。 Zabbix 模式介绍： 1、被动模式 2、主动模式 默认是被动模式，我们可以通过以下方式查看监控项是什么模式 因为我们使用的是模板，无法进行修改。我们可以修改配置文件或者新建 item 的时候设置。 注意： 1、当监控主机超过 300+，建议使用主动模式（此处是一个经验值，要根据服务器的硬件来进行考虑） 2、还需要保证 Queue 对列里面没有延迟的主机 Queue 对列介绍 如果此处的延迟主机有点多的话，我们就需要将被动模式修改为主动模式. 主动模式设置 将 192.168.56.12 监控设置为主动模式 1、修改配置文件 为了方便模拟，我们将 node2(192.168.56.12)从 Zabbix 删除从新添加 [root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf #Server=192.168.56.11 #我们需要注释 Server，因为这个是被动模式用的 StartAgents=0 #设置为 0 之后就不会 TCP 端口，之前监听 TCP 端口是因为 Server 要去问 agent 信息所以需要开启 ServerActive=192.168.56.11 #此处可以是 IP 或者是域名，他会连接 10051 端口 Hostname=linux-node2.example.com #唯一识别符，我们需要修改成我们本机的主机名。如果我们不设置，它默认会通过 item 来获取 [root@linux-node2 ~]# systemctl restart zabbix-agent.service 保存重启 保存重启之后我们可以查看我们监听的一些端口，因为我们关闭的被动模式所以不会在监听 zabbix 端口了 [root@linux-node2 ~]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp6 0 0 :::44589:::*LISTEN 9052/java tcp6 0 0 :::8080 :::*LISTEN 9052/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 :::8888 :::*LISTEN 9052/java tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::39743:::*LISTEN 9052/java tcp6 0 0 127.0.0.1:8005 :::*LISTEN 9052/java tcp6 0 0 :::8009 :::*LISTEN 9052/java 我们可以查看日志，进行检查 [root@linux-node2 ~]# tailf /var/log/zabbix/zabbix_agentd.log 14932:20161011:084303.210 **** Enabled features **** 14932:20161011:084303.210 IPv6 support: YES 14932:20161011:084303.210 TLS support: YES 14932:20161011:084303.210 ************************** 14932:20161011:084303.210 using configuration file: /etc/zabbix/zabbix_agentd.conf 14932:20161011:084303.210 agent #0 started [main process] 14933:20161011:084303.227 agent #1 started [collector] 14934:20161011:084303.227 agent #2 started [active checks #1] 14934:20161011:084303.271 no active checks on server [192.168.56.11:10051]: host [linux-node2.example.com] not found 14934:20161011:084503.415 no active checks on server [192.168.56.11:10051]: host [linux-node2.example.com] not found 日志解释： zabbix—agent设置完主动模式后，会去主动问 server 需求。相当于入职刚入职运维需要老大进行分配任务。并且以后就会根据这个任务清单进行执行 因为我们还没有配置server，所以现在会出现错误 Zabbix-web 设置 我们需要添加 zabbix-agent 添加模板 ，zabbix 没有提供主动模式的模板。所以我们需要克隆一下 OS Linux 找到 OS Linux 模板，移动到最下面 点击复制 我们从新进行设置名称 修改我们刚刚添加的模板名为OS Linux Active 我们点击刚刚创建模板的 item 然后选择最下方 Update 结果如下： 在次查看模板，发现 zabbix 还依赖一个模板。我们需要把它也改了或者是删掉。 我们添加主机 添加模板 # 提示：我们已经可以获取到数据了，但是发现 zabbix 这个模块发红。可能是由于我们没有修改他的依赖造成的 如下图： 可能是通过 agent.ping 来获取信息, 没有看过源码 所以不太清楚，我研究它 zabbix 主备模式完成 转自：Zabbix 3.0 主备模式 [八]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 监控 Web [七]【转】]]></title>
    <url>%2F2016%2F11%2F15%2FZabbix%203.0%20%E7%9B%91%E6%8E%A7Web%20%5B%E4%B8%83%5D%2F</url>
    <content type="text"><![CDATA[Zabbix 默认自带一个 web 监控 我们可以从 Monitoring---&gt;Web 进行查看 按照前面的文章，我们在 192.168.56.12 上面已经开启了一个 Tomcat 端口为 8080. 如果没有的小伙伴可以阅读 [Zabbix 3.0 生产案例 [四] 一、检查 首先我们需要检查 192.168.56.12 是否有 tomcat，是否可以运行。能否访问 1. 查看进程 [root@linux-node2 ~]# ps -ef|grep java root 8048 25468 0 10:31 pts/000:00:00 grep --color=auto java root 42757 1 0 Sep26 pts/000:38:59 /usr/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8888 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=192.168.56.12 -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start 2. 查看端口 [root@linux-node2 ~]# lsof -i:8080 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java42757 root 48u IPv6 379379 0t0 TCP *:webcache (LISTEN) 3. 测试是否可以访问 8080 端口 [root@linux-node2 ~]# curl -I 192.168.56.11:8080 HTTP/1.1 200 OK Server: nginx/1.10.1 Date: Mon, 10 Oct 2016 05:08:18 GMT Content-Type: text/html Content-Length: 612 Last-Modified: Mon, 19 Sep 2016 01:59:49 GMT Connection: keep-alive ETag: &quot;57df4695-264&quot; Accept-Ranges: bytes 二、Zabbix Web 界面配置 提示： 监控 Web 不依赖于 agent，是server 直接发送请求的 提示： 这里名字叫做 Web 场景，因为我们可以设置触发上面 3 个选项后，才进行报警 提示： 字符串里面可以添加一些字符串，当请求下来有这个字符串就是正常，没有就是不正常。但是最常用的还是状态 然后我们选择Add 比较坑的一点是，我们新添加了一个 Web 监控。zabbix 默认没有给我们安装触发器 三、触发器添加 Web 监控中默认不含有触发器，所以需要手动添加 点右上角，进行创建触发器 四、触发器报警测试1、停掉 tomcat，要想返回值不是 200 停掉 tomcat 是最简单的 [root@linux-node2 ~]# /usr/local/tomcat/bin/shutdown.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 检查 [root@linux-node2 ~]# ps aux|grep tomcat root 8723 0.0 0.0 112648 976 pts/1R+ 12:21 0:00 grep --color=auto tomcat 报警如下： 回复如上 邮件报警设置可以访问 Zabbix 3.0 生产案例 [五]我们还可以优化动作[Actions] Zabbix 就是一个万能的什么都可以监控，只要我们有 key。什么都可以监控key 我们可以使用脚本，程序等等等 转自：Zabbix 3.0 监控 Web [七]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 监控 MySQL [六]【转】]]></title>
    <url>%2F2016%2F11%2F15%2FZabbix%203.0%20%E7%9B%91%E6%8E%A7MySQL%20%5B%E5%85%AD%5D%2F</url>
    <content type="text"><![CDATA[Mysql 监控 zabbix 自带了一个监控 mysql 的模板，但是真正监控 mysql 的并不是 zabbix 自带的模板。而是 percona 公司的一个监控 mysql 模板 percona 官网： www.percona.com Percona 组成介绍 1、php 脚本 用来数据采集2、shell 脚本 用来调用采集信息3、zabbix 配置文件4、zabbix 模板文件 安装文档：https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html percona 利用的是 php 来获取 mysql 的相关信息，所以如果我们想使用 percona 插件监控 mysql 就需要在 agent 端安装php。在安装文档上有写哦~ 安装步骤： 查看上面的链接也可以进行安装 我们安装在 zabbix-server 上，因为上面有一个 MySQL [root@linux-node1 web]# yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm [root@linux-node1 web]# yum install percona-zabbix-templates php php-mysql -y #percona 插件是通过 php 去获取 mysql 的参数，所以我们要安装 php 和 php-mysql 我们可以查看它都安装了那些软件 [root@linux-node1 web]# rpm -ql percona-zabbix-templates /var/lib/zabbix/percona /var/lib/zabbix/percona/scripts /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh #shell 脚本 /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php #php 获取 mysql 信息 /var/lib/zabbix/percona/templates /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf #zabbix 配置文件 /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml #zabbix 模板文件 在 percona 组成我们已经说过了，此处只是略微介绍。 我们将 zabbix 模板下载下来 [root@linux-node1 web]# sz /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml 然后我们需要将模板通过 web 界面导入到 zabbix 中 提示：如果出现错误，可能是 zabbix 3.0 版本的问题。我们这里提供了一个生产的模板 下载链接： https://pan.baidu.com/s/1TgsPR3qjWyxjwKYQrz6fWQ密码:u09h 然后从新上传即可 复制配置文件 [root@linux-node1 web]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/ [root@linux-node1 web]# ls /etc/zabbix/zabbix_agentd.d/ #安装完软件包后会在 /var/lib/zabbix/percona/templates/ 目录下产生一个配置文件，我们将它拷贝，因为在前面的博文中，我们已经修改过 zabbix 的配置文件[Include=/etc/abbix/zabbix_agentd.d/] 所以将配置文件放在这个目录下，zabbix 就会自己在这个目录下查找相关信息 [root@linux-node1 web]# systemctl restart zabbix-agent.service 重启一下！ 下面就应该配置与 MySQL 的连接 在/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf创建一个文件 [root@linux-node1 ~]# cat /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf &lt;?php $mysql_user = &apos;root&apos;; $mysql_pass = &apos;&apos;; #用户名密码可以自己创建，有密码写密码，没密码为空就好了 提示： 正常这里的用户我们应该创建一个专门用来监控的，由于我这里是测试环境。就不浪费时间了 测试 查看是否可以获取到值，随便找一个测试 [root@linux-node1 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf 选择一个肯定有值的 key [root@linux-node1 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf|grep gm UserParameter=MySQL.read-views,/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gm 测试结果如下： [root@linux-node1 ~]# cd /var/lib/zabbix/percona/scripts/ [root@linux-node1 scripts]# ./get_mysql_stats_wrapper.sh gm 1 [root@linux-node1 scripts]# ./get_mysql_stats_wrapper.sh gw 9736342 可以获取到值，说明没有问题 温馨提示： shell 脚本中数据库的路径是 localhost，如果我们没有授权 localhost 会获取不到值 [root@linux-node1 scripts]# cat get_mysql_stats_wrapper.sh HOST=localhost RES=`HOME=~zabbix mysql -e &apos;SHOW SLAVE STATUS\G&apos; | egrep &apos;(Slave_IO_Running|Slave_SQL_Running):&apos; | awk -F: &apos;{print $2}&apos; | tr &apos;\n&apos; &apos;,&apos;` #mysql 是通过命令来获取的，如果环境变量不一样 也可能造成影响 Zabbix_Web 界面配置 模板已经上传到 zabbix 中，这时候我们就需要进行设置了 提示： 我们还需要授权 /tmp 下的一个文件，因为默认情况下 zabbix 在文件中获取的值 修改完就可以获取值了，所以我们还需要测试 结果如下图 思想： 如果出现错误我们需要先查看 shell 的脚本，因为 shell 是去调用 php。 错误的因素有很多，最简单的方法就是用 shell 后面加上 key 看看是否可以有值。 其中报错最多的地方就是 php 和 mysql 连接的问题，还有我们 mysql 授权的一些问题。 MYSQL 监控 完！ 转载自：Zabbix 3.0 监控 MySQL [六]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 生产案例 [五]【转】]]></title>
    <url>%2F2016%2F11%2F12%2FZabbix%203.0%20%E7%94%9F%E4%BA%A7%E6%A1%88%E4%BE%8B%20%5B%E4%BA%94%5D%2F</url>
    <content type="text"><![CDATA[上面我们说到了监控 TCP 和 Nginx 状态，但是光是监控是没有任何作用的。监控完我们不知道跟没监控没啥区别，下面我们进行 监控项 的讲解 1. 触发器 首先我们给 Nginx 添加触发器1. 选择Configuration---&gt;Hosts 2. 找到我们相对应的主机进入 3. 选择主机中的 Triggers—&gt; 添加(Create trigger) 我们设置一个事件 我们选择 Insert，然后选择Add 即可 4. 查看报警状态 因为我们设置的级别大于 1 就报警，默认 Nginx 是 0，随便访问以下就是 1. 所以肯定就会报警。报警邮件可以根据我们前面 [Zabbix 3.0 部署监控 [三]]文章进行设置 报警邮件如下： 我们可以查看这个事件的相关过程 以上就是我们添加的一个触发器报警步骤 Zabbix 默认触发器的预值比较低，我们需要调大。这个在面试过程中会被问到 我们进行修改默认模板 路径下图： 我们可以看到默认是大于 300 进行报警, 我们点进去修改即可 根据实际情况进行修改，我们设置 600 即可。同时触发器支持多个条件进行报警，如 or all 等，只需要在上面的值后面继续添加即可。 我们修改完之后 还有一个有警告显示磁盘不够，因为是虚拟机我们不予理会，我们可以查看到恢复之后的邮件 2. 脚本发送邮件 提示： Zabbix 邮件报警是 3.0 才有的，以前不支持用户名密码。所以早期都是使用脚本进行发送邮件报警。 由于时间关系我们就不进行写了请下载发送邮件的 python 脚本：链接：http://pan.baidu.com/s/1gfkGrgZ 密码：6bsh 脚本注释： Python 脚本中三个相关的参数 receiver = sys.argv[1] #收件人地址 subject = sys.argv[2] #发送邮件的主题 mailbody = sys.argv[3] #发送邮件的内容 smtpserver = &apos;smtp.exmail.qq.com&apos; #邮件服务器地址，本脚本使用的是企业邮箱 username = &apos;username&apos; #用户名 password = &apos;password&apos; #密码 sender = username #发送人名称 我们如果要写一个发送邮件的脚本，需要支持三个参数 1、收件人 2、标题 3、内容 自定义告警脚本 我们也可以使用shell 写一个最简单的 脚本存放路径：我们可以在配置文件中查看 [root@linux-node1 web]# vim /etc/zabbix/zabbix_server.conf AlertScriptsPath=/usr/lib/zabbix/alertscripts 提示： 这行配置文件定义了邮件脚本的存放路径，因为它默认会从 usr/lib/zabbix/alertscripts 查找邮件脚本 [root@linux-node1 web]# vim /usr/lib/zabbix/alertscripts/sms.sh #!/bin/bash ALTER_TO=$1 ALTER_TITLE=$2 ALTER_BODY=$3 echo $ALTER_TO &gt;&gt; /tmp/sls.log echo $ALTER_TITLE &gt;&gt; /tmp/sms.log echo $ALTER_BODY &gt;&gt; /tmp/sms.log 我们可以写完之后进行检测，如果这里有信息说明已经调用这个脚本。 如果我们有短信通道将里面的内容换一下即可，短信通道都是有售后的 修改权限 [root@linux-node1 web]# chmod +x /usr/lib/zabbix/alertscripts/sms.sh [root@linux-node1 web]# ll /usr/lib/zabbix/alertscripts/sms.sh -rwxr-xr-x 1 root root 152 Oct 8 20:26 /usr/lib/zabbix/alertscripts/sms.sh 我们写的脚本是短信报警，首先你需要有一个短信通道，我们可以使用阿里云大鱼，本次我们使用文件追加的形式来模拟. Zabbix 页面设置 点击右上角创建报警介质 点击最下面的 Add 提示：先点击小的 Update 在点最下面的Update 我们还需要修改报警媒介 找到相对应的用户，点击。 接下来就需要我们触发报警了 上面我们设置的连接数是大于 1，所以我们多刷新几次就可以了 这里显示发送完成，我们去日志进行查看 13122323232 为发送的手机号 PROBLEM： 为主题信息 Nginx Active 监控项 Original……..：为故障信息，2 代表连接数是 2 提示： 因为中国的短信收费是 70 个字符 2 毛，字母也算是。所以我们发送邮件的报警信息就需要简介明了一点 优化图如下： 修改后如下： 设置完成之后最好数一下，不要超过 70 个字符 http://www.alidayu.com/ 有兴趣的同学可以自己了解一下阿里大鱼，可以提供短信通道、语音、验证码等业务。 短信通道比较出名的几款产品： 亿美软通 阿里大鱼 腾讯云也有 微信报警 短信报警和邮件报警已经说过了，我们简单的说一下微信报警 因为在很早之前就说过，个人服务号和订阅号不支持直接跟订阅用户进行沟通。如果是企业号可以直接获取到一个类似 key，拿着这个 key 直接 curl 就可以了发了。 具体内容可以进行百度或者谷哥搜索。 扩展： 除了以上三种报警，还有 钉钉报警 以前还有 QQ 报警、 飞信报警，但是现在已经不开源了 提示： 上面那三行最好不要删除，在生产环境中追加到一个文件中。记录发送邮件的信息 转载自：Zabbix 3.0 生产案例 [五]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 生产案例 [四]（转）]]></title>
    <url>%2F2016%2F11%2F10%2FZabbix%203.0%20%E7%94%9F%E4%BA%A7%E6%A1%88%E4%BE%8B%20%5B%E5%9B%9B%5D%2F</url>
    <content type="text"><![CDATA[Zabbix 生产案例实战 一、项目规划 1、主机分组： 交换机 Nginx Tomcat MySQL 2、监控对象识别： 1、使用 SNMP 监控交换机 2、使用 IPMI 监控服务器硬件 3、使用 Agent 监控服务器 4、使用 JMX 监控 Java 应用 5、监控 MySQL 6、监控 Web 状态 7、监控 Nginx 状态 3、操作步骤：SNMP 监控 1.1 在交换机上开启Snmpconfig t snmp-server community public ro end 提示：如果不知道我们可以百度 ####1.2 在 Zabbix 上添加SNMP 监控 步骤：Configuration---&gt;Hosts---&gt; 设置 1.3 Host 页面设置 1.4 Templates 模板设置 设置 SNMP 团体名称 Macros 宏 这里的设置要跟我们创建的 SNMP 的设置相同 因为 Zabbix 监控的时候依赖团体名称 1.5 生产图片 Zabbix 会自动给我们进行检测端口，每个端口都会添加一个网卡的流量图，每个端口都会加上一个触发器。（端口的状态 ） 还会帮我们添加VLAN 的一个监控 1.6 案例图 含有有进口和出口流量 提示：此图是 Zabbix SNMP 模板自动生成的 IPMI 监控 2.1 添加 IPMIConfiguration---&gt;Hosts---&gt; 选择主机 ---&gt; 设置 IPMI 端口及主机 ---&gt; 用户名密码 因为 IMP 容易超时，建议使用自定义 item，本地执行ipmitool 命令来获取数据 JMX 监控 Zabbix 默认提供了一个监控 JMX, 通过 java gateway 来监控 java 地址：https://www.zabbix.com/documentation/3.2/manual/appendix/config/zabbix_java JAVA GATEWAY需要独立安装，相当于一个网关，因为 zabbix_server 和 zabbix-agent 不可以直接获取 java 信息。所以需要一个代理来获取 zabbix java Gateway不存任何数据, 只是一个简单的代理 1、安装[root@linux-node1 ~]# yum install -y zabbix-java-gateway java-1.8.0 提示：java-gateway 需要 java 环境 2、配置 修改 java-gateway [root@linux-node1 ~]# vim /etc/zabbix/zabbix_java_gateway.conf # LISTEN_IP=&quot;0.0.0.0&quot; 监听的 IP 地址 # LISTEN_PORT=10052 监听的端口 PID_FILE=&quot;/var/run/zabbix/zabbix_java.pid&quot; 存放 pid 路径 # START_POLLERS=5 开通几个进程, 默认是 5。你有多少 java 进行可以设置多少个，也可以设置 java 进程的一半。 TIMEOUT=3 超时时间 1-30，如果网络环境差，超时时间就修改长一点 我们默认就可以了，不进行修改 3、启动[root@linux-node1 ~]# systemctl start zabbix-java-gateway.service 4、端口、进程查看 我们可以进行进程的查看 [root@linux-node1 ~]# netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:33060.0.0.0:* LISTEN 10439/mysqld tcp0 0 0.0.0.0:80800.0.0.0:* LISTEN 33484/nginx: master tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1054/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2484/master tcp0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 76482/zabbix_agentd tcp0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 34572/zabbix_server tcp0 0 127.0.0.1:199 0.0.0.0:* LISTEN 11143/snmpd tcp6 0 0 :::80 :::*LISTEN 10546/httpd tcp6 0 0 :::22 :::*LISTEN 1054/sshd tcp6 0 0 ::1:25 :::*LISTEN 2484/master tcp6 0 0 :::10050:::*LISTEN 76482/zabbix_agentd tcp6 0 0 :::10051:::*LISTEN 34572/zabbix_server tcp6 0 0 :::10052:::*LISTEN 13465/java 10052 zabbix-java-gateway默认端口已经起来了！ 它是一个 java 应用，需要安装 jdk [root@linux-node1 ~]# ps -aux|grep java root 13465 0.4 3.4 2248944 34060 ? Sl 19:17 0:01 java -server -Dlogback.configurationFile=/etc/zabbix/zabbix_java_gateway_logback.xml -classpath lib:lib/android-json-4.3_r3.1.jar:lib/logback-classic-0.9.27.jar:lib/logback-core-0.9.27.jar:lib/slf4j-api-1.6.1.jar:bin/zabbix-java-gateway-3.0.4.jar -Dzabbix.pidFile=/var/run/zabbix/zabbix_java.pid -Dzabbix.timeout=3 -Dsun.rmi.transport.tcp.responseTimeout=3000 com.zabbix.gateway.JavaGateway root 13584 0.0 0.0 112648 972 pts/0S+ 19:21 0:00 grep --color=auto java 5、通知 zabbix-server 我们需要通知 zabbix-server，java-gateway 在哪里 修改配置文件 [root@linux-node1 ~]# vim /etc/zabbix/zabbix_server.conf 编辑 zabbix-server 来指定 zabbix-java-gateway JavaGateway=192.168.56.11 #IP 地址是安装 java-gateway 的服务器 # JavaGatewayPort=10052 端口，默认就可以 StartVMwareCollectors=5 预启动多少个进程[zabbix---&gt;java-gateway 的数量] 6、重启 zabbix-server[root@linux-node1 ~]# systemctl restart zabbix-server.service 7、准备 apache我们安装 tomcat-8 版本 官网：http://tomcat.apache.org下载软件包 [root@linux-node2 src]# wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.5/bin/apache-tomcat-8.5.5.tar.gz 我们将 tomcat 安装在 apache 服务器上，来模拟监控 jvm [root@linux-node2 src]# tar xf apache-tomcat-8.5.5.tar.gz [root@linux-node2 src]# mv apache-tomcat-8.5.5 /usr/local/ [root@linux-node2 src]# ln -s /usr/local/apache-tomcat-8.5.5/ /usr/local/tomcat [root@linux-node2 src]# yum install -y java-1.8.0#tomcat 需要在 java 环境运行 [root@linux-node2 src]# /usr/local/tomcat/bin/startup.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar Tomcat started. 在 web2 上面查看运行状态 [root@linux-node2 src]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 10088/zabbix_agentd tcp6 0 0 :::8080 :::*LISTEN 25750/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::10050:::*LISTEN 10088/zabbix_agentd tcp6 0 0 127.0.0.1:8005 :::*LISTEN 25750/java tcp6 0 0 :::8009 :::*LISTEN 25750/java JMX 三种类型： 1. 无密码认证 2. 用户面密码认证 3.ssl 开启 JMX 远程监控 官方文档：http://tomcat.apache.org/tomcat-8.0-doc/monitoring.html我们创建一个无密码认证 [root@linux-node2 src]# vim /usr/local/tomcat/bin/catalina.sh CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8888 #端口号 -Dcom.sun.management.jmxremote.ssl=false #SSL 关闭 -Dcom.sun.management.jmxremote.authenticate=false #用户密码验证关闭 -Djava.rmi.server.hostname=192.168.56.12&quot; #监控的主机 修改完成后重启 tomcat 可以使用 ./shutdown.sh 或者使用kill 的方式 [root@linux-node2 src]# /usr/local/tomcat/bin/shutdown.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 中间可以使用 px -aux|grep java 查看是否被杀死 [root@linux-node2 src]# /usr/local/tomcat/bin/startup.sh Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME:/usr Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar Tomcat started. 我们 JMX 端口设置为 8888 [root@linux-node2 src]# netstat -lntup Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1073/sshd tcp0 0 127.0.0.1:250.0.0.0:* LISTEN 2498/master tcp0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 10088/zabbix_agentd tcp6 0 0 :::8080 :::*LISTEN 26226/java tcp6 0 0 :::22 :::*LISTEN 1073/sshd tcp6 0 0 :::8888 :::*LISTEN 26226/java tcp6 0 0 ::1:25 :::*LISTEN 2498/master tcp6 0 0 :::10050:::*LISTEN 10088/zabbix_agentd tcp6 0 0 :::38532:::*LISTEN 26226/java tcp6 0 0 127.0.0.1:8005 :::*LISTEN 26226/java tcp6 0 0 :::8009 :::*LISTEN 26226/java tcp6 0 0 :::38377:::*LISTEN 26226/java 我们可以在 windows 上面安装 jdk ，使用命令行来监控 java 我们下载安装，具体步骤不说了，然后我们找到 jconsole.exe 文件运行 填写安装 JMX 的服务器 因为在配置文件中我们设置的是无密码认证，所以这里不需要输入密码直接连接。端口号我们设置的是 8888 连接即可 这样我们就可以在图形化监控 tomcat 提示：按照现在观察，java-gateway 已经安装成功，我们可以加入到 zabbix 中 找我们要添加的主机 填写安装 java-gateway 的主机 我们还需要设置一个模板 这个模板就是我们自带的一个监控 JMX 的模板，然后我们点击Update. 更新 我们需要等待一会才可以出图 提示：可以在 Zabbix-server 上使用 zabbix-get 获取某一台机器的某一个 key , 效果图如下：需要等待一会 手动检测监控状态 Zabbix-Server 操作： [root@linux-node1 ~]# yum install -y zabbix-get Key： 我们随便找一个 key，然后我们复制后面的 key [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k jmx[&quot;java.lang:type=Runtime&quot;,Uptime] ZBX_NOTSUPPORTED: Unsupported item key. 提示：未支持的 key，现在并不能获取到这个 key 因为没有获取到这个值，所以不会显示。我们可以获取别的试一下 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.079323 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.075377 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.075377 [root@linux-node1 ~]# zabbix_get -s 192.168.56.12 -k system.cpu.util[,user] 0.073547 小结： Zabbix 其实就是通过 zabbix_get 获取到的这个值进行比较的 日志 开启 zabbix debug 模式 [root@linux-node2 tomcat]# systemctl restart zabbix-agent ### Option: DebugLevel # Specifies debug level: # 0 - basic information about starting and stopping of Zabbix processes # 1 - critical information # 2 - error information # 3 - warnings # 4 - for debugging (produces lots of information) # 5 - extended debugging (produces even more information) DebugLevel=4 如果及别是 4 就是 debug 模式，修改完配置文件之后需要重启生效 Zabbix 生产案例1. 开启 Nginx 监控 2. 编写脚本来进行数据采集 3. 设置用户自定义参数 4. 重启 zabbix-agent 5. 添加 item 6. 创建图形 7. 创建触发器 8. 创建模板 实践步骤 脚本编写： 我们这里提供已经写好的脚本, 链接：https://pan.baidu.com/s/19JrCetaRZYGY_mvq4CyoJQ 密码：94us 需要修改一下 zabbix-agent 的配置文件 vim /etc/zabbix/zabbix_agentd.conf 修改 Include 设置, 这样我们可以把脚本放在这个目录下。配置就是.conf 结尾 Include=/etc/zabbix/zabbix_agentd.d/*.conf 3. 添加权限及测试脚本 [root@linux-node1 zabbix_agentd.d]# chmod +x zabbix_linux_plugin.sh [root@linux-node1 zabbix_agentd.d]# sh zabbix_linux_plugin.sh Usage: zabbix_linux_plugin.sh {tcp_status key|memcached_status key|redis_status key|nginx_status key} 提示： 这个脚本要用 zabbix 用户执行的权限，因为都是 zabbix 用户在执行，监控 TCP 会在 /tmp/ 目录生成一个文件用于监控使用 4. 修改 nginx 配置文件 提示：nginx 默认路径是 /usr/local/nginx 编译安装需要查看安装路径 [root@linux-node1 zabbix_agentd.d]# vim /usr/local/nginx/conf/nginx.conf location /nginx_status { stub_status on; allow 127.0.0.1; access_log off; } 因为脚本的 url 是 nginx_status 所以我们配置文件也要这样修改 测试脚本 [root@linux-node1 zabbix_agentd.d]# curl 192.168.56.11:8080/nginx_status Active connections: 1 server accepts handled requests 2823682 2823682 2821835 Reading: 0 Writing: 1 Waiting: 0 [root@linux-node1 zabbix_agentd.d]# ./zabbix_linux_plugin.sh nginx_status 8080 active 1 [root@linux-node1 zabbix_agentd.d]# ./zabbix_linux_plugin.sh nginx_status 8080 reading 0 [root@linux-node1 zabbix_agentd.d]# ./zabbix_linux_plugin.sh nginx_status 8080 handled 2823688 设置 Key，首先是Key 的名称 [root@linux-node1 zabbix_agentd.d]# cat linux.conf UserParameter=linux_status[*],/etc/zabbix/zabbix_agentd.d/zabbix_linux_plugin.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot; [*]代表一个传参，可以将后面的 $1,$2,$3 引入进行 ，后面是脚步本的路径 需要重启 agent [root@linux-node1 zabbix_agentd.d]# systemctl restart zabbix-agent 我们使用 zabbix_get 进行测试 [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -k linux_status[nginx_status,8080,active] 1 [-k] 就是指定 key 不细说了 [*] * 的作用在 web 界面配置 item 会显示出来 5.Zabbix web 界面设置 我们需要添加 item，因为要加好多。我们就使用模板的方式进行添加 提示：我们写一下注释然后选择 Add 即可 找到我们的模板 我们创建 item 创建 各参数前文都有讲解不细说！ 修改完成吼点击 Add 添加完成后我们要复制很多个用来监控 Nginx status 的所有状态，所以我们使用克隆。来克隆多个进行设置 点进我们的 item，然后拖到最下面选择克隆 填一些基本的修改即可，例如下： 添加完成如下图： item 添加完成我们还需要添加一个图形，用于展示，找到图形路径。点击创建 因为我们主机还没有加入我们的模板，所以我们这里是没有数据的 下面将模板加入到主机中 修改模板 查看结果如下： 6. 导出模板 因为设置模板比较麻烦，我们可以将模板导出 导出之后我们需要修改名称就可以了 7. 导入模板 我们需要导出自然需要导入，操作如下： 点击添加即可 提示： 模板之间的名称不可以相同 以上就是 Nginx 完整的监控使用8. 导入 TCP 模板 加入模板的步骤跟刚刚加入 Nginx 的一样，这里我们就使用模板了。下载链接：http://pan.baidu.com/s/1i54ULjJ 密码：25lh我们导入模板即可 导入完成之后我们可以查看模板 在里面我们可以见到 TCP 的 11 种状态，这个 item 是我们需要根据我们脚本进行同步的。 我们可以随便点击一个进行查看，其中这里的 key 要和脚本的相同 我们在两台服务器都加载这个模板 步骤和上面的一样 添加完成 查看脚本需要等待 1 分钟，这主要看我们设置的获取值的时间而定。我们可以查看图形 更多内容请看下集！~ 转载自：Zabbix 3.0 生产案例 [四]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 字符集乱码及 Centos7 补全设置 [转]]]></title>
    <url>%2F2016%2F11%2F10%2FZabbix%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B9%B1%E7%A0%81%E5%8F%8ACentos7%E8%A1%A5%E5%85%A8%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Centos 补全安装软件包 [root@linux-node1 ~]# yum install -y bash-completion 从新打开窗口即可 操作： 1. 找到本地 C:\Windows\Fonts\simkai.ttf（楷体）上传到服务器 zabbix 网站目录 fonts 目录下。 [root@localhost /]# whereis zabbix zabbix: /usr/lib/zabbix /etc/zabbix /usr/share/zabbix [root@localhost /]# cd /usr/share/zabbix [root@localhost zabbix]# ll |grep fonts drwxr-xr-x. 3 root root75 Jun 12 14:04 fonts [root@localhost zabbix]# cd fonts/ [root@localhost fonts]# ll total 30176 drwxr-xr-x. 2 root root 26 Jun 12 14:01 fonts_bak -rw-r--r--. 1 root root 720012 Jun 12 14:03 graphfont.ttf -rw-r--r--. 1 root root 11785184 Jun 11 2009 simkai.ttf -rw-r--r--. 1 root root 18387092 Jun 12 14:04 uming.ttf [root@localhost fonts]# 2. 修改 zabbix php 配置文件 [root@localhost /]# find -name defines.inc.php ./usr/share/zabbix/include/defines.inc.php [root@localhost fonts]# cd /usr/share//zabbix/ [root@localhost zabbix]# ll |grep include drwxr-xr-x. 4 root root 4096 Jun 12 14:37 include #从网上抄的，不适合本机 sed -i &apos;s/DejaVuSans/simkai/g&apos; ./include/defines.inc.php #自己修改的，做了两次，后发现界面上文字没有了。 sed -i &apos;s/graphfont/simkai/g&apos; ./include/defines.inc.php sed -i &apos;s/fonts/simkai/g&apos; ./include/defines.inc.php #检查 defines.inc.php 文件 [root@localhost zabbix]# vim defines.inc.php #查找到“simkai”关键字，修改 ZBX_FONTPATH&apos;（红色标记部分） // the maximum period to display history data for the latest data and item overview pages in seconds // by default set to 86400 seconds (24 hours) define(&apos;ZBX_HISTORY_PERIOD&apos;, 86400); define(&apos;ZBX_WIDGET_ROWS&apos;, 20); define(&apos;ZBX_FONTPATH&apos;, realpath(&apos;/usr/share/zabbix/fonts/&apos;)); // where to search for font (GD &gt; 2.0.18) define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;simkai&apos;); // font file name /simkai define(&apos;ZBX_FLAG_DISCOVERY_NORMAL&apos;, 0x0); define(&apos;ZBX_FLAG_DISCOVERY_RULE&apos;, 0x1); define(&apos;ZBX_FLAG_DISCOVERY_PROTOTYPE&apos;, 0x2); define(&apos;ZBX_FLAG_DISCOVERY_CREATED&apos;,0x4); define(&apos;EXTACK_OPTION_ALL&apos;, 0); define(&apos;EXTACK_OPTION_UNACK&apos;, 1); define(&apos;EXTACK_OPTION_BOTH&apos;,2); define(&apos;TRIGGERS_OPTION_RECENT_PROBLEM&apos;,1); define(&apos;TRIGGERS_OPTION_ALL&apos;, 2); define(&apos;TRIGGERS_OPTION_IN_PROBLEM&apos;,3); define(&apos;ZBX_ACK_STS_ANY&apos;, 1); define(&apos;ZBX_ACK_STS_WITH_UNACK&apos;,2); define(&apos;ZBX_ACK_STS_WITH_LAST_UNACK&apos;, 3); define(&apos;EVENTS_OPTION_NOEVENT&apos;, 1); define(&apos;EVENTS_OPTION_ALL&apos;, 2); define(&apos;EVENTS_OPTION_NOT_ACK&apos;, 3); define(&apos;ZBX_FONT_NAME&apos;, &apos;simkai&apos;); define(&apos;ZBX_AUTH_INTERNAL&apos;, 0); define(&apos;ZBX_AUTH_LDAP&apos;, 1); define(&apos;ZBX_AUTH_HTTP&apos;, 2); #重启 zabbix 服务 service zabbix-server restart 提示：如果我们找不到配置文件可以使用以下方法 [root@linux-node1 ~]# find / -type f -name &quot;defines.inc.php&quot; /usr/share/zabbix/include/defines.inc.php 将字体导入到 /usr/share/zabbix/fonts 效果图如下 图一，修改前 图一，修改后 转载自：Zabbix 字符集乱码及 Centos7 补全设置]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 部署监控 [三]（转）]]></title>
    <url>%2F2016%2F10%2F11%2FZabbix%203.0%20%E9%83%A8%E7%BD%B2%E7%9B%91%E6%8E%A7%20%5B%E4%B8%89%5D%20%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Dashboard 首页信息介绍 Status of Zabbix（Zabbix 状态）介绍 Zabbix server is running #Zabbix 服务器是否运行 Number of hosts (enabled/disabled/templates) #主机数量（已启用 / 已禁用 / 模板） Number of items (enabled/disabled/not supported) #监控项数量（已启用 / 已禁用 / 不支持） Number of triggers (enabled/disabled [problem/ok]) #触发器数量（已启用 / 已禁用 / 问题 / 正常） Number of users (online) #用户数（线上） Required server performance, new values per second #要求的主机性能，每秒新值 此处需要注意的事项如下：1、需要时刻关注那些主机数量中已禁用的（例如：那一天有一台监控有问题，顺手关闭了。没有打开 结果后期导致监控出现问题） 2、监控项数量里面最好不要放置已禁用，要么删除这个监控项或者不让他报警。尽量不要给他禁用 3、触发器只禁用几个没什么大问题，但是如果一下禁用几十个不方便进行管理 4、正式环境最好划分主机组，可以按照业务划分，类型划分。那个出现问题都方便查看处理 Latest data 最新数据介绍 加入监控 刚刚之前我们一直使用的是一台服务器，因为不方便解释。我们新添加一台服务器 加入监控的几个步骤： 1、安装软件 2、修改配置 1、设置 yum 源[root@linux-node2 ~]# rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm 2、安装软件包[root@linux-node2 ~]# yum install -y zabbix-agent 3、修改配置文件[root@linux-node2 ~]# vim /etc/zabbix/zabbix_agentd.conf Server=192.168.56.11 ServerActive=192.168.56.11 #提示：这里的 IP 地址改成 Server 端的 IP 地址 4、启动[root@linux-node2 ~]# systemctl start zabbix-agent[root@linux-node2 ~]# netstat -lntup|grep zabbixtcp0 0 0.0.0.0:10050 0.0.0.0: LISTEN 10088/zabbix_agentdtcp6 0 0 :::10050:::LISTEN 10088/zabbix_agentd 5、web 界面设置 克隆~ 步骤：我们随便点击一个进去。拉到最下面有一个全部克隆 剩下的我们就改一下就可以了 模板修改 其他的就没有什么可以配置的，模板主要是添加 Template OS Linux。然后我们选择Add 即可 创建完成如下： 新添加的 IP 如上述所示 Maps 优化设置 上次只是简单的连接线的设置，这次我们进行深入设置 路径：Monitoring---&gt;Maps---&gt;Edit map进行修改 我们点击 Zabbix server 没有设置主机的，选择Host 修改linux-node2。 提示：此处我们修改了 2 台主机，这个可以根据业务需求进行设置 我们新添加一台，然后进行连接。Ctrl + 主机 然后点击 Link：Add 例如我们想查看他们的 流量带宽 首先，他们必须要连接在一起，然后点击 Links 选项后面的 Edit 进行编辑 我们可以在 Label 表里面写监控项的值 我们可以在 Configuration---&gt;Hosts---&gt;items 中查看到 括号内写入发下： {linux-node2.example.com:net.if.out[eth0].last(0)} linux-node2.example.com= 主机名 net.if.out=key 值 last（0）= 获取最新的一个数据 现在我们就可以实时的监控流量 切记需要update 保存如下图显示 如何让 Zabbix 报警 我们可以先打开Events 查看事件 zabbix 事件有很多类型 Trigger= 触发器的事件 Disovery= 自动发现事件 还有内部的事件以及自动注册的事件 我们可以选择 主机，查看相对应的事件 Zabbix的报警可以当做事件通知，当这个事件发生时。zabbix进行通知（报警） 事件报警分为 2 种方式： 1、怎么通知 2、通知给谁 Zabbix 通知方式：Zabbix 通知方式通过 Actions 进行通知 Zabbix默认有一个，我们可以点开进行查看 条件设置 操作设置 温馨提示：保存的时候需要先点击下方小的 Update 否则就木有啦, 这里的步骤可以让报警邮件发送的级别、例如：先发送给 运维、项目经理、项目总监 等 例如如下： 刚刚的填写完成，现在提示的是 1-2 发送的人 我们可以点击下面的 New 在添加几个 模拟设置，当报警 1-2 次时候发送给 XX，2-4次发送给XX。 依次叠加 我们需要配置报警媒介类型，用于发送邮件 温馨提示：3.0之前发送邮件需要启动邮件相关服务来进行安全认证，3.0之后默认自带安全认证 我们以 qq 邮箱为例 我们还需要配置 用户 的邮箱，因为上面已经选择发送给那个 用户。接下来就改配置用户的邮箱 我们点开之后选择Media（报警媒介进行设置）如果看不懂英文我们可以设置中文 然后我们选择下方的Add 设置收件人地址 小结：步骤就不截图了，可以调成中文，按照步骤来。 1、报警媒介 2、动作（active）配置（操作–编辑） 注意点小的 update 3、创建用户群组（注意权限） 4、创建用户（权限和报警媒介设置）权限只能按照用户组分配（我们可以选择用户 / 管理员 / 超级管理员） 提示：添加新主机后，要注意确认权限分配 我们的使用 QQ 邮箱需要开启 SNMP 和一个授权码。 填写发件人密码时需要设置授权码为密码 邮件结果如下：异常 因为我们开启了正常之后继续发送邮件，所以正常之后邮件如下 提示：当异常时它会一直发邮件，直到服务正常或者匹配规则到时 转载自：Zabbix 3.0 部署监控 [三]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 部署监控 [二]（转）]]></title>
    <url>%2F2016%2F10%2F11%2FZabbix%203.0%20%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%20%5B%E4%BA%8C%5D%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、添加监控主机及设置1. 创建主机 Agent 可以干一些 SNMP 无法干的事情，例如自定义监控项snmp 相关文章：http://www.abcdocker.com/abcdocker/1376 这里我们先不着急点add，还需要设置其他选项 点击监控模板 zabbix 监控是由 监控项 组成（cpu使用率监控就是一个 监控项 / 内存使用率 就是一个监控项），如果是 100 台服务器就需要监控 模板 了。只需要将监控项和模板 关联 起来即可 举个例子：我们上面主机使用的是 SNMP，就可以直接搜索SNMP。提示：有的模板需要自己定义 温馨提示：请点击下面的小add 然后在点大的。否则会出现问题哦 IPMI如果有的话，需要在这里写上 用户名 和密码 宏定义，这个宏其实就是一个变量。我们给可以给变量附一个值 因为我们设置的是 SNMP，SNMP 有一个团体名。并且可以设置定义 团体名是中间的abcdocker，具体的可以看http://www.abcdocker.com/abcdocker/1376 [root@localhost ~]# cat /etc/snmp/snmpd.conf rocommunity abcdocker 192.168.56.11 值：{$SNMP_COMMUNITY} 主机资产设置分为 3 中 1、关闭 Disabled2、手动 Manual3、自动 Automatic （自动代表的是你在定义监控项的时候，他有一个小箭头，勾上之后监控项的值就会填写在这里） 我们这设置好模板就可以选择add 了 等 SNMP 变绿就好了 现在的状态是用 SNMP 进行监控了，我们只是添加了一个 SNMP OS LINUX 的模板，但是出现了 4 个。这 4 个链接。可以和多个 模板 连起来用 进入监控项，下面这个菜单是过滤搜索用的 下面全都是模板 我们可以随便点击一个，这里我们新建一个监控项 点击创建 类型选择 Zabbix agent 被动 Zabbix agent (active 主动模式) Simple check 简单检测 SNMPv1 agent …… 在 Key 这行点击 Select 可以进行选择 我们随便选择一个，例如 agent.version。查看 agent 的版本Numeric 是无符号整数型 2. 图形说明Configuration----hosts----Graphs 绘图靠的是 监控项，我们可以随便打开一个看看 颜色等都是可以随意设置 3、聚合图形 screens 设置 提示 ：因为咱们用的版本是 3.0 当 2.4 的时候需要在Configuration---- 下面来创建screens 创建 Screens 我们创建一个 2*2 命名为test screens 的screens 然后我们点进去 点击 编辑 点击 Change 进行设置 多添加几个之后就是以下结果 二、监控案例 [自定义监控项] 例如 ：我们自己添加一个监控项来进行监控当前的活动连接数nginx 安装地址：http://www.abcdocker.com/abcdocker/1376Nginx 状态模块配置如下，过于简单不说了 [root@localhost ~]# cat /usr/local/nginx/conf/nginx.conf listen 8080; location /status { stub_status on; access_log off; allow 192.168.56.0/24; deny all; } 修改 nginx 端口并重启 测试：http://192.168.56.11:8080/status 解释说明：使用 zabbix 来监控活动连接数，通过 status 状态模块为前提 , 我们现在命令取出我们想要的值，例如： [root@localhost ~]# curl -s http://192.168.56.11:8080/status|grep Active|awk -F &quot;[]&quot; &apos;{print $3}&apos; 1 因为我们是监控他的活动连接数，他的活动连接数为1 [root@linux-node1 ~]# vim /etc/zabbix/zabbix_agentd.conf Include=/etc/zabbix/zabbix_agentd.d/ 提示： 如果想要加自定义监控项，不要在配置文件中写入，可以在 Include 里面定义的目录写上 , 只要我们写在 Include 目录下，都可以识别到 [root@linux-node1 ~]# cd /etc/zabbix/zabbix_agentd.d/ [root@linux-node1 zabbix_agentd.d]# ls userparameter_mysql.conf #默认有一个 MySQL 的，我们可以参考 MySQL 的进行操作 UserParameter=mysql.ping,HOME=/var/lib/zabbix mysqladmin ping | grep -c alive #提示，前面是 key 的名称 后面的 key 的命令 UserParameter=mysql.version,mysql -V 我们自己编辑一个文件 [root@linux-node1 zabbix_agentd.d]# cat nginx.conf UserParameter=nginx.active,/usr/bin/curl -s http://192.168.56.11:8080/status|grep Active|awk -F &quot;[]&quot; &apos;{print $3}&apos; 提示，此处配置文件的名字可以随便起 如果是多个命令可以写一个 脚本 ，命令最好写 绝对路径 ！这个过程其实就是我们定义监控的过程，前面是key 的名字，后面是命令 修改完配置文件之后需要重启zabbix-agent [root@linux-node1 zabbix_agentd.d]# systemctl restart zabbix-agent 配置完成之后先在 server 端测试，是否可以获取到 agent 上的值。不要着急添加 , 我们现在只用了 1 台服务器，本机是 server 也是 agent。然后使用 zabbix-get 进行 测试 [root@linux-node1 zabbix_agentd.d]# yum list|grep zabbix zabbix-agent.x86_64 3.0.4-1.el7@zabbix zabbix-release.noarch 3.0-1.el7 installed zabbix-server-mysql.x86_64 3.0.4-1.el7@zabbix zabbix-web.noarch 3.0.4-1.el7@zabbix zabbix-web-mysql.noarch 3.0.4-1.el7@zabbix python-pyzabbix.noarch 0.7.3-2.el7epel uwsgi-stats-pusher-zabbix.x86_642.0.13.1-2.el7 epel zabbix-get.x86_64 3.0.4-1.el7zabbix 查看 zabbix_get [root@linux-node1 zabbix_agentd.d]# yum install -y zabbix-get zabbix-get使用参数如下： [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -p 10050 -k &quot;nginx.active&quot; -s 指定我们要查看的服务器 -p 端口，可以不加。默认是 10050 -k 监控项的名称（根据上面的配置来定义的） 更多参数：zabbix_get --help 错误案例： 如果出现如下错误，大致意思是拒绝连接 [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -p 10050 -k &quot;nginx.active&quot; zabbix_get [24234]: Check access restrictions in Zabbix agent configuration 解决方法： [root@linux-node1 ~]# vim /etc/zabbix/zabbix_agentd.conf Server= 192.168.56.11 因为我们当时只允许本机 127.0.0.1 进行连接。所以会出现这样问题 [root@linux-node1 ~]# systemctl restart zabbix-agent 修改完配置文件都要 重启 提示： zabbix-agent 的配置文件中指定允许那个 server 连接，那个才可以进行连接。 [root@linux-node1 zabbix_agentd.d]# zabbix_get -s 192.168.56.11 -p 10050 -k &quot;nginx.active&quot; 1 正确结果如上！提示：如果在 zabbix-agent 上面修改了，还需要在网页上进行修改 在 /etc/zabbix/zabbix-agent.conf 上面指定的 Server 是谁，就只会允许谁通过。如果有多个 ip 可以使用逗号进行分割 添加 item 找到一个安装zabbix-agent，点击 点击items 然后添加Create item（创建 item） Data type：数据类型，这里我们选择 Decimal。其他的基本上用不上 Units：单位 超过 1 千就写成 1k 了。 可以在这里做一个单位的设置。默认就可以 Use custom multiplier：如果这里面设置了一个数，得出来的结果都需要乘以文本框设定的值 Update interval（in sec）:监控项刷新时间间隔（一般不要低于 60 秒） Custom intervals:创建时间间隔（例如：1 点 -7 点每隔多少秒进行监控）格式大致为：周，时，分 History storage period: 历史数据存储时间（根据业务来设置，默认就可以） Trend storage period: 趋势图要保存多久 New application: 监控项的组 application: 选择一个监控项组 Populates host inventory field: 资产，可以设定一个监控项。把获取的值设置在资产上面 描述！必须要写。 要不你就是不负责任 添加自定义监控项小结： 1、添加用户自定义参数（在 /etc/zabbix/zabbix.agent.d/ 定义了一个 nginx.conf 步骤如上） 2、重启zabbix-agent 3、在 Server 端使用 zabbix_get 测试 获取（命令如上） 4、在 web 界面创建item（监控项） 自定义图形 Name：名字 Width：宽度 Height：高度 Graph type：图形类型 其他 默认 即可 然后我们点击 Add 添加 Items 监控项，找到我们刚刚设置的服务器 然后找到我们刚刚添加的 监控项 还可以选择颜色，添加其他的很多设置。不细说 点击 Prewview 可以进行预览，如果出现字符乱码可以阅读我们另一篇文章（zabbix 默认不支持中文）, 确定没有问题，选择下方 Add 即可 出现我们添加的 需要在 Monitoring---&gt;Graphs---&gt; 选择我们添加的主机即可 接下来我们需要进行 测试 ： 测试前： 使用 ab 测试工具进行测试，设置 100 万 并发进行访问 [root@linux-node1 ~]# ab -c 1000 -n 1000000 http://192.168.56.11:8080/ This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 192.168.56.11 (be patient) 测试后： 我们可以查看 zabbix 监控图标 我们中间设置了间隔 60 秒，说明每隔 60 秒 我们进行获取一次, 我们可以设置它的方式显示 找到 Graph 选择类型，Stacked是堆叠显示，其他的大家可以自行百度。不细说 堆叠显示如下： 如果我们想加多个图形都显示在一张图上，可以进行如下操作 找到Graphs 找到我们设置的图形 点击添加即可 我们可以让多个图标显示在一个图片上 点击我们创建一个聚合图形（screens） 点击进去 点击编辑 选择 item 添加的地方，因为上面创建聚合图形的时候我们选择了 2X2 所以这里会显示 2 个 找到相对应的添加即可 我们可以多添加几个 结果如上图显示 除了显示图片还可以显示其他内容 Action log：日志 Clock：时间 Data overview：数据概述 Graph：图形 History of events：历史事件 Host group issues：主机组问题 Host issues：主机问题 Hosts info：主机信息 Plain text：文本 Map：架构图 Screen：屏幕 Server info：服务器信息 Simple graph：简单的图 Simple graph prototype：简单的原型图 System status：系统状态 Triggers info：触发器信息 Tiggers overview：概述 URL：URL 地址 例如我们输入一个 URL： 我们还可以自定义一个Maps，一张架构图。操作如下： 第二步：选择编辑Edit map 因为他默认图片比较小，我们可以点击下方，进行调整图片大小。 点击右上角 编辑，然后我们点中图中的服务器即可 我们模拟有 2 台服务器 然后我们选中新添加的服务器进行修改 点击 Apply 就可以了。按住 Ctrl 点中 zabbix server 和另一台服务器 然后我们点击左上方的Link：他们就连接起来了 温馨提示：修改完成后需要点击保存 [update] 如果不点后果就是从新在做一遍~ 未完！ 转载自：Zabbix 3.0 部署监控 [二] | abcdocker 运维博客]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix 3.0 基础介绍 [一]（转）]]></title>
    <url>%2F2016%2F10%2F10%2FZabbix%203.0%20%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%20%5B%E4%B8%80%5D%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摘要 本文主要讲述 Zabbix 的简介以及 Zabbix 安装及页面设置 Zabbix 3.0 基础介绍 [一]一、Zabbix 介绍zabbix 简介 Zabbix 是一个高度集成的网络监控解决方案，可以提供企业级的开源分布式监控解决方案，由一个国外的团队持续维护更新，软件可以自由下载使用，运作团队靠提供收费的技术支持赢利 zabbix 是一个基于 Web 界面的，提供分布式系统监控以及网络监视功能的企业级的开源解决方案。 zabbix 能监视各种网络参数，保证服务器系统的安全运营，并提供灵活的通知机制以让系统管理员快速定位 / 解决存在的各种问题 zabbix 主要由 2 部分构成 zabbix server 和 zabbix agent，可选组建 zabbix proxy zabbix server 可以通过 SNMP，zabbix agent，fping 端口监视等方法对远程服务器或网络状态完成监视，数据收集等功能。同时支持 Linux 以及 Unix 平台，Windows 平台只能安装客户端 Zabbix 功能 ①具备常见的商业监控软件所具备的功能（主机的性能监控、网络设备性能监控、数据库、性能监控、FTP 等通用协议监控、多种告警方式、详细的报表图表绘制） ②支持自动发现网络设备和服务器（可以通过配置自动发现服务器规则来实现） ③支持自动发现（low discovery）key 实现动态监控项的批量监控（需写脚本） ④支持分布式，能集中展示、管理分布式的监控点 ⑤扩展性强，server 提供通用接口（api 功能），可以自己开发完善各类监控（根据相关接口编写程序实现）编写插件容易，可以自定义监控项，报警级别的设置。 ⑥数据收集 可用和性能检测 支持 snmp(包括 trapping and polling)，IPMI，JMX，SSH，TELNET 自定义的检测 自定义收集数据的频率 服务器 / 代理和客户端模式 灵活的触发器 可以定义非常灵活的问题阈值，称为触发器，从后端数据库的参考值 高可定制的报警 发送通知，可定制的报警升级，收件人，媒体类型 通知可以使用宏变量有用的变量 自动操作包括远程命令 实时的绘图功能 监控项实时的将数据绘制在图形上面 WEB 监控能力 ZABBIX 可以模拟鼠标点击了一个网站，并检查返回值和响应时间 Api 功能 应用 api 功能，可以方便的和其他系统结合，包括手机客户端的使用。 更多功能请查看http://www.zabbix.com/documentation.php Zabbix 版本 Zabbix 3.0 Manual Zabbix 2.4 Manual Zabbix 2.2 Manual Zabbix 2.0 Manual 下载地址：http://www.zabbix.com/documentation.php 本次采用 yum 安装，安装 zabbix3.0. 使用 Centos7 Zabbix 优缺点 优点 1、开源，无软件成本投入 2、Server 对设备性能要求低 3、支持设备多，自带多种监控模板 4、支持分布式集中管理，有自动发现功能，可以实现自动化监控 5、开放式接口，扩展性强，插件编写容易 6、当监控的 item 比较多服务器队列比较大时可以采用被动状态，被监控客户端主动从 7、server 端去下载需要监控的 item 然后取数据上传到 server 端。这种方式对服务器的负载比较小。 8、Api 的支持，方便与其他系统结合 缺点 需在被监控主机上安装 agent，所有数据都存在数据库里，产生的数据据很大, 瓶颈主要在数据库。 Zabbix 监控原理 Zabbix 通过 C/S 模式采集数据，通过 B/S 模式在 web 端展示和配置。 被监控端：主机通过安装 agent 方式采集数据，网络设备通过 SNMP 方式采集数据 Server 端：通过收集 SNMP 和 agent 发送的数据，写入数据库（MySQL，ORACLE 等），再通过 php+apache 在 web 前端展示。 Zabbix 运行条件 Server：Zabbix Server 需运行在 LAMP（Linux+Apache+Mysql+PHP）环境下（或者 LNMP），对硬件要求低 Agent：目前已有的 agent 基本支持市面常见的 OS，包含 Linux、HPUX、Solaris、Sun、windows SNMP：支持各类常见的网络设备SNMP(Simple Network Management Protocol, 简单网络管理协议 Zabbix 监控过程逻辑图 Zabbix 监控类型 硬件监控：适用于物理机、远程管理卡（iDRAC），IPMI（只能平台管理接口） ipmitools:MegaCli（查看 Raid 磁盘） 系统监控: 监控 cpt：lscpu、uptime、top、vmstat 1 、mpstat 1、htop 监控内存： free -m 监控硬盘：df -h、iotop 监控网络：iftop、netstat、ss 应用服务监控：nfs、MySQL、nginx、apache、php、rsync 更详细的监控类型可以参考：http://www.abcdocker.com/abcdocker/1376 引入 Zabbix所有监控范畴，都可以整合到 Zabbix 中 硬件监控：Zabbix、IPMI、lnterface 系统监控：Zabbix、Agent、Interface Java 监控：Zabbix、JMX、lnterface 网络设备监控：Zabbix、SNMP、lnterface 应用服务监控：Zabbix、Agent、UserParameter MySQL 数据库监控：percona-monitoring-plulgins URL 监控：Zabbix Web 监控 ## 二、Zabbix 环境配置 1、环境信息 [root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@localhost ~]# uname -r 3.10.0-327.28.3.el7.x86_64 2、yum 安装 阿里云 yum 源已经提供了 zabbix3.0，因此我们需要使用官方 yum 源。官方 yum 源下载会比较慢 [root@localhost ~]# rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm 问题：为什么要下载 release 版本的 zabbix？ [root@localhost ~]# ls /etc/yum.repos.d/ CentOS-Base.repo CentOS-Media.repo epel.repo.rpmnew CentOS-CR.repo CentOS-Sources.repo epel-testing.repo CentOS-Debuginfo.repo CentOS-Vault.repo zabbix.repo CentOS-fasttrack.repo epel.repo 因为下载这个版本会在 yum.repos.d 下面生成一个 zabbix.repo 的文件 3、安装相关软件包 [root@localhost ~]# yum install zabbix-server zabbix-web zabbix-server-mysql zabbix-web-mysql mariadb-server mariadb -y 注：如果 Server 端也需要监控则需要安装 zabbix-agent 提示：在 Centos7 中，mysql 改名为 mariadb 4、修改 PHP 时区设置 [root@localhost ~]# sed -i &apos;s@# php_value date.timezone Europe/Riga@php_value date.timezone Asia/Shanghai@g&apos; /etc/httpd/conf.d/zabbix.conf #要注意需要改的配置文件是 /etc/httpd/conf.d/zabbix.conf 而不是 /etc/php.ini， 三、数据库设置1. 启动数据库 [root@localhost ~]# systemctl start mariadb 2. 创建 zabbix 数据库及用户 mysql create database zabbix character set utf8 collate utf8_bin; grant all on zabbix.* to zabbix@&apos;localhost&apos; identified by &apos;123456&apos;; exit 3. 导入数据 [root@localhost ~]# cd /usr/share/doc/zabbix-server-mysql-3.0.4/ [root@localhost zabbix-server-mysql-3.0.4]# ll total 1836 -rw-r--r-- 1 root root 98 Jul 22 11:05 AUTHORS -rw-r--r-- 1 root root 687803 Jul 22 11:05 ChangeLog -rw-r--r-- 1 root root 17990 Jul 22 11:06 COPYING -rw-r--r-- 1 root root 1158948 Jul 24 02:59 create.sql.gz -rw-r--r-- 1 root root 52 Jul 22 11:06 NEWS -rw-r--r-- 1 root root 188 Jul 22 11:05 README [root@localhost zabbix-server-mysql-3.0.4]# zcat create.sql.gz |mysql -uzabbix -p123456 zabbix 我们使用 zcat，专门查看 sql.gz 包。和 cat 基本相似 4. 修改 zabbix 配置文件 [root@localhost zabbix-server-mysql-3.0.4]# vim /etc/zabbix/zabbix_server.conf DBHost=localhost #数据库所在主机 DBName=zabbix #数据库名 DBUser=zabbix #数据库用户 DBPassword=123456 #数据库密码 5. 启动 zabbix 及 apache [root@localhost ~]# systemctl start zabbix-server [root@localhost ~]# systemctl start httpd 注意：如果没有启动成功，要看一下是不是 80 端口被占用 6.Web 界面安装 master访问地址：http://192.168.56.11/zabbix/setup.php 点击 Next step 进行安装 首先要确保没有no，如果时区没有改好会提示我们进行修改 账号密码都是我们刚刚在配置文件中设置的，端口默认就是 3306 为我们的 zabbix 起个名字，一会在右上角会显示 最后是展示我们的配置信息，可以查看到哪里有错误 点击 Finish 提示：登录上去之后请立即修改密码 7. 配置 zabbix-agent 端 [root@localhost ~]# vim /etc/zabbix/zabbix_agentd.conf Server=127.0.0.1 修改 Server 端的 IP 地址（被动模式 IP 地址） ServerActive=127.0.0.1 主动模式，主动向 server 端报告 [root@localhost ~]# systemctl start zabbix-agent 查看端口号 [root@localhost ~]# netstat -lntp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 7806/mysqld tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1062/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2208/master tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 11511/zabbix_agentd tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 11335/zabbix_server tcp 0 0 127.0.0.1:199 0.0.0.0:* LISTEN 2692/snmpd tcp6 0 0 :::80 :::* LISTEN 11408/httpd tcp6 0 0 :::22 :::* LISTEN 1062/sshd tcp6 0 0 ::1:25 :::* LISTEN 2208/master tcp6 0 0 :::443 :::* LISTEN 11408/httpd tcp6 0 0 :::10050 :::* LISTEN 11511/zabbix_agentd tcp6 0 0 :::10051 :::* LISTEN 11335/zabbix_server 10051 为 server 端口，10050 为 agent 端口 四、Web 界面配置 找到 Configuration—-&gt;Hosts 添加一台监控主机 开启后，如果出现错误我们可以看一下 zabbix 的日志 [root@localhost ~]# ls /var/log/zabbix/zabbix_ zabbix_agentd.log zabbix_server.log 当 ZBX 变成绿色的时候，说明监控成功。因为我们没有配置 SNMP、JMX、IPMI 等。所以我发监控 因为我们现在只安装了一台服务器，所以只有一个主机。我们可以查看现在这台主机的 CPU 等及基本的信息 点击 Monitoring—–Graphs，选择我们要监控的内容 我们选择可以随便选择一个进行查看信息 例如：我们查看 CPU 的负载 某一段时间内，CPU 正在处理以及等待 CPU 处理的进程数的之和。Load Average 是从另一个角度来体现 CPU 的使用状态的。 这些监控其实就是 zabbix 在数据库查找数据，然后使用 jd 进行画图Zabbix 性能依赖于 mysql 数据库 五、Zabbix 页面安全设置1、设置默认账号密码 设置完中文 六、Zabbix 菜单说明Zabbix 上方的菜单简单介绍说明 Doshboard 下面可以设置你想设置的图形，添加方法如下： 这时，就可以找到你喜爱的了，直接打开 screens 其实就是一个聚合图形，可以把多个图片合在一起。然后放在大屏幕上，供别人查看 maps 就是一个架构图 Status of Zabbix 就是一个状态栏 第一行是 Server 是否运行 [yes] 和后面的运行地址 第二行监控的机器 （启用的 / 关闭的 / 模板） 第三行监控项 （启用的 / 关闭的 / 不支持的） 第四行触发器的状态 （启用的 / 关闭的 /【故障 / 正常】） 第五行 当前用户数量 （在线数量） 第六行 zabbix 每秒可以收到的一个新值 告警的级别 我们可以设置报警响铃，让他在前端响 我们首页的监控列表是可以随意拖动的 我们还可以将它关闭，并且设置刷新时间 Zabbix 基础完! 转载自：Zabbix 3.0 基础介绍 [一] | abcdocker 运维博客]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 主题内接入网页在线联系功能]]></title>
    <url>%2F2015%2F02%2F26%2FHexo%20NexT%E4%B8%BB%E9%A2%98%E5%86%85%E6%8E%A5%E5%85%A5%E7%BD%91%E9%A1%B5%E5%9C%A8%E7%BA%BF%E8%81%94%E7%B3%BB%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[之前有访问过一些大佬的个人博客，里面有个在线联系功能，看着不错，所以也试着在自己的站点上接入了此功能。 注册 首先在 DaoVoice 注册个账号，点击 -&gt;邀请码 是2e5d695d。 完成后，会得到一个app_id，后面会用到： 修改 head.swig修改 /themes/next/layout/_partials/head.swig 文件，添加内容如下： {% if theme.daovoice %} (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice") daovoice('init', {app_id: "{{theme.daovoice_app_id}}" }); daovoice('update'); {% endif %} 位置贴图： 主题配置文件 在_config.yml文件中添加内容： # Online contact daovoice: true daovoice_app_id: # 这里填你刚才获得的 app_id 聊天窗口配置 附上我的聊天窗口的颜色、位置等设置信息： 至此，网页的在线联系功能已经完成，重新 hexo g，hexo d 上传 GitHub 后，页面上就能看到效果了。 就比如说你现在往右下角看看(～￣▽￣)～ ，欢迎撩我（滑稽）。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 主题内加入动态背景]]></title>
    <url>%2F2015%2F02%2F25%2FHexo%20NexT%E4%B8%BB%E9%A2%98%E5%86%85%E5%8A%A0%E5%85%A5%E5%8A%A8%E6%80%81%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[主题内新添加内容 _layout.swig 找到 themes\next\layout\_layout.swig 文件，添加内容：在 &lt;body&gt; 里添加： &lt;div class=&quot;bg_content&quot;&gt; &lt;canvas id=&quot;canvas&quot;&gt;&lt;/canvas&gt; &lt;/div&gt; 仍是该文件，在末尾添加： &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/dynamic_bg.js&quot;&gt;&lt;/script&gt; dynamic_bg.js 在 themes\next\source\js\src 中新建文件dynamic_bg.js，代码链接中可见：dynamic_bg.js custom.styl在 themes\next\source\css\_custom\custom.styl 文件末尾添加内容： .bg_content { position: fixed; top: 0; z-index: -1; width: 100%; height: 100%; } 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考： Hexo NexT 主题内加入动态背景]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSSFS 实现阿里云 OSS 文件系统数据共享]]></title>
    <url>%2F2015%2F01%2F24%2FOSSFS%E5%AE%9E%E7%8E%B0%E9%98%BF%E9%87%8C%E4%BA%91OSS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[阿里云 ESC 服务器挂载 OSS 文件系统 ossfs 能让您在 Linux/Mac OS X 系统中把 Aliyun OSS bucket 挂载到本地文件 系统中，您能够便捷的通过本地文件系统操作 OSS 上的对象，实现数据的共享。 阿里云 oss 官方：ossfs 挂载，您可以理解为把挂载的 bucket 当做一个 ecs 目录来操作的，存储文件到挂载的 bucket 中是占用的这个 bucket 的内存，不会占用您 ecs 的内存。 安装 下载文件 ossfs_1.80.3_centos7.0_x86_64.rpm 到阿里云 安装sudo yum localinstall ossfs_1.80.3_centos7.0_x86_64.rpm 写入 oss 配置echo my-bucket:my-access-key-id:my-access-key-secret &gt; /etc/passwd-ossfs, 例： echo ossfs-xuan:LTAIw5M5SHnIoNcm:ci1Oj7*******ZqDziBj &gt; /etc/passwd-ossfs 更改配置文件权限chmod 640 /etc/passwd-ossfs 创建挂载目录mkdir /ossfs 挂载ossfs ossfs-xuan /ossfs -ourl=oss-cn-shenzhen-internal.aliyuncs.com 额外的命令# 允许 linux 其他用户对改 oss 文件系统进行操作 ossfs ossfs-xuan /ossfs -ourl=oss-cn-shenzhen-internal.aliyuncs.com -o allow_other #卸载挂载 oss 目录 umount /ossfs 可能出现的错误 InvalidBucketName 错误可以看出 BucketName 重复了 ossfs: bad request &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;Error&gt; &lt;Code&gt;InvalidBucketName&lt;/Code&gt; &lt;Message&gt;The specified bucket is not valid.&lt;/Message&gt; &lt;RequestId&gt;5A93BFD701A3E286AC09FDDD&lt;/RequestId&gt; &lt;HostId&gt;ossfs-xuan.ossfs-xuan.oss-cn-shenzhen-internal.aliyuncs.com&lt;/HostId&gt; &lt;BucketName&gt;ossfs-xuan.ossfs-xuan&lt;/BucketName&gt; &lt;/Error&gt; 解决：-ourl=oss-cn-shenzhen-internal.aliyuncs.com不需要带BucketName]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7.4 安装 GlusterFS]]></title>
    <url>%2F2015%2F01%2F23%2FCentOS7.4%E5%AE%89%E8%A3%85GlusterFS%2F</url>
    <content type="text"><![CDATA[介绍 Gluster 是一个大尺度文件系统。 主要功能 简单卷 distribute volume 分布式卷，两台主机的磁盘融合一个磁盘 stripe volume 条带卷，一个文件分成数据块存储到不同的地方 replica volume 复制卷，一个文件分别保存到两台主机 复合卷 1+2，1+3，2+3，1+2+3 总结常用命令gluster peer status #查看集群各主机连接状态 gluster volume list# 查看挂载卷信息 gluster volume list #查看卷列表 #创建挂在卷，force 忽略在 root 目录创建挂在卷的警告 gluster volume create swarm-volume replica 3 worker:/xuan/docker/gluster-volume home:/xuan/docker/gluster-volume xuanps:/xuan/docker/gluster-volume force gluster volume start swarm-volume #启动 gluster volume stop swarm-volume #停止 gluster volume delete swarm-volume #删除 ，了文件还会保留 #挂载本地目录到 glusterfs 卷（swarm-volume），在本地目录添加的会自动同步到其他挂载卷 #eg 在本机 mnt 添加文件，其他 volume-name 目录也会添加 mount [- 参数] [设备名称] [挂载点] mount -t glusterfs worker:/swarm-volume /mnt/ umount worker:/swarm-volume #卸载了就不会同步了 #重置，删除所有数据 systemctl stop glusterd rm -rf /var/lib/glusterd/ systemctl start glusterd #删除节点 gluster peer detach home 安装 准备工作： 三台局域网主机（centos7 修改主机名 ） hostnameip备注xuanpsleft-aligned10.14.0.1 workercentered10.14.0.4homeright-aligned10.14.0.5 三台都需要安装 GlusterFS # 搜索 glusterfs 可安装的版本 yum search centos-release-gluster #安装最新长期稳定版本 (Long Term Stable) 的 gluster 软件 yum -y install centos-release-gluster #安装 glusterfs-server yum --enablerepo=centos-gluster*-test install glusterfs-server glusterfs -V #测试 systemctl enable glusterd #开机启动 systemctl start glusterd #启动 systemctl status glusterd #查看是否正常运行 #修改 hosts 不然不能通过主机名连接到对方 vim /etc/hosts #---------- 三台都要添加如下设置 -------------------------- 10.14.0.1 xuanps 10.14.0.4 worker 10.14.0.5 home #------------------------------------------------------ #从 xuanps 上执行下面两条，其他主机不用执行 gluster peer probe worker gluster peer probe home #三台都执行该命令是否都是 connected gluster peer status #查看挂载卷信息 gluster volume info #创建挂在卷，force 忽略在 root 目录创建挂在卷的警告 gluster volume create volume-name replica 3 worker:/xuan/docker/gluster-volume/test home:/xuan/docker/gluster-volume/test xuanps:/xuan/docker/gluster-volume/test force #启动 gluster volume start volume-name #启动 nfs 同步，测试需验证，这里要不要开启 gluster volume set volume-name nfs.disable off #挂载本地目录到 glusterfs 卷（volume-name），在本地目录添加的会自动同步到其他挂载卷 #eg 在本机 mnt 添加文件，其他 volume-name 目录也会添加 mount -t glusterfs worker:/volume-name /mnt/ 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考 官方文档 centos 官方安装手册 基于 GlusterFS 实现 Docker 集群的分布式存储]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7.4 安装 OpenVpn]]></title>
    <url>%2F2015%2F01%2F22%2FCentOS7.4%E5%AE%89%E8%A3%85OpenVpn%2F</url>
    <content type="text"><![CDATA[openvpn service 安装与配置1. 下载脚本 wget https://git.io/vpn -O openvpn-install.sh# 添加执行权限 chmod +x openvpn-install.sh #总结 wget https://git.io/vpn -O openvpn-install.sh &amp;&amp; bash openvpn-install.sh 2. 运行脚本./openvpn-install.sh, 设置如下 监听地址设置为空 IP address: Protocol:[2]TCP Port:1194 不选 DNS: client name: client_k2 External IP : 112.74.51.136 3. 配置服务端 vim /etc/openvpn/server.conf# 指定 ip, 所以记录 ip 没效果屏蔽 ;ifconfig-pool-persist ipp.txt ;push &quot;redirect-gateway def1 bypass-dhcp&quot; #推送服务器路由 push &quot;route 10.14.0.0 255.255.255.0&quot; #推送 k2 客户端子网路由到所有客户端除了 ccd 里面申明了该路由的客户端 push &quot;route 192.168.123.0 255.255.255.0&quot; #添加服务器路由，访问客户端 K2 的 192.168.123.0 子网通过网关 10.14.0.2(k2 客户端 ip) route 192.168.123.0 255.255.255.0 10.14.0.2 #添加客户端配置目录，启用之后，每个客户端必须指定 ip，否正有可能访问不了其他客户端的子网 client-config-dir ccd #客户端访问客户端 client-to-client 4. 配置客户端路由 mkdir /etc/openvpn/ccd 和 vim /etc/openvpn/ccd/client_k2# 设置该客户端的 vpn 的 ip 是 10.14.0.2, 子网掩码必须是 255.255.255.0，如果启用 ccd，必须配置 ifconfig-push 10.14.0.2 255.255.255.0 #申明 192.168.123.0 是自己的子网，并且让子网也可以访问 vpn 服务器，申明之后不会推送该路由到该客户端 iroute 192.168.123.0 255.255.255.0 route 192.168.123.0 255.255.255.0 5. 添加客户端./openvpn-install.shSelect an option[1-4]:1 (add a new user) client name: client_worker # 编辑配置文件 vim /etc/openvpn/server.conf #重启生效 systemctl restart openvpn@server.service systemctl enable openvpn@server.service #注释掉客户端的 #setenv opt block-outside-dns 6. 下载 ovpn 文件，并修改配置，注释调 #setenv opt block-outside-dns 7. 常用命令# 重启生效 systemctl restart openvpn@server.service #使能服务 systemctl enable openvpn@server.service #ssh 下载文件 scp root@112.74.51.136:/root/client_xuan_ubuntu.ovpn ./ openvpn client 安装与配置1. 安装yum update #更新 yum install vim #安装 vim yum install epel-release #添加 epel 源 yum clean all # 可选 yum update # 可选 yum makecache # 可选 yum install openvpn iptables-services #安装 openvpn scp root@112.74.51.136:~/client_vm.ovpn /etc/openvpn/client/ #下载客户端配置 #注释掉客户端的 vim /etc/openvpn/client/client_vm.ovpn #setenv opt block-outside-dns #----------------------- 废弃 ------------------------------------------------ openvpn --daemon --cd /etc/openvpn/client --config client_vm.ovpn --log-append /etc/openvpn/openvpn.log #启动 tail -100f /etc/openvpn/openvpn.log #查看日志 ps -ef | grep openvpn #查看 openvpn 进程 kill &lt;pid&gt; #杀死进程 #--------------------- 废弃结束 ------------------------------------------------------ #openvpn-client 启动服务，反斜杠转义字符，实际名称是 openvpn-client@.service vim /lib/systemd/system/openvpn-client\@.service #修改 ExecStart=/usr/sbin/openvpn --suppress-timestamps --nobind --config %i.conf #为 ExecStart=/usr/sbin/openvpn --daemon --config %i.ovpn --log-append /etc/openvpn/openvpn.log #防止已经启动，@符号后面等效与 %i, 所以这里为客户端配置的名字 systemctl restart openvpn-client@client_vm #开机启动 systemctl enable openvpn-client@client_vm 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考 官网 脚本 github 官网 Nyr/openvpn-install openvpn 的一个一键安装脚本“openvpn-install”让 openvpn 重放光彩（需翻墙） How to Configure OpenVPN Server on CentOS 7.3 使用 OpenVPN 互联多地机房及 Dokcer 跨主机 / 机房通讯 扩大 OpenVPN 使用范围，包含服务器或客户端子网中的其他计算机]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 修改网卡为 eth0]]></title>
    <url>%2F2015%2F01%2F22%2FCentOS7%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E4%B8%BAeth0%2F</url>
    <content type="text"><![CDATA[使用 CentOS-7 最直观的变化就是服务管理了。这里介绍一下。 services 使用了 systemd 来代替 sysvinit 管理 systemd 是 Linux 下的一种 init 软件，由 Lennart Poettering 带头开发，并在 LGPL 2.1 及其后续版本许可证下开源发布。其开发目标是提供更优秀的框架以表示系统服务间的依赖关系，并依此实现系统初始化时服务的并行启动，同时达到降低 Shell 的系统开销的效果，最终代替现在常用的 System V 与 BSD 风格 init 程序。与多数发行版使用的 System V 风格 init 相比，systemd 采用了以下新技术：采用 Socket 激活式与总线激活式服务，以提高相互依赖的各服务的并行运行性能；用 cgroups 代替 PID 来追踪进程，以此即使是两次 fork 之后生成的守护进程也不会脱离 systemd 的控制。从设计构思上说，由于 systemd 使用了 cgroup 与 fanotify 等组件以实现其特性，所以只适用于 Linux。systemd 的服务管理程序：systemctl 是主要的工具，它融合之前 service 和 chkconfig 的功能于一体。可以使用它永久性或只在当前会话中启用 / 禁用服务。 启动一个服务：systemctl start postfix.service 关闭一个服务：systemctl stop postfix.service 重启一个服务：systemctl restart postfix.service 显示一个服务的状态：systemctl status postfix.service 在开机时启用一个服务：systemctl enable postfix.service 在开机时禁用一个服务：systemctl disable postfix.service 查看服务是否开机启动：systemctl is-enabled postfix.service;echo $? 查看已启动的服务列表：systemctl list-unit-files|grep enabled CentOS7 修改网卡为 eth0编辑网卡信息[root@linux-node2~]# cd /etc/sysconfig/network-scripts/ #进入网卡目录 [root@linux-node2network-scripts]# mv ifcfg-eno16777728 ifcfg-eth0 #重命名网卡名称 [root@linux-node2network-scripts]# cat ifcfg-eth0 #编辑网卡信息 TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no NAME=eth0 #name 修改为 eth0 ONBOOT=yes IPADDR=192.168.56.12 NETMASK=255.255.255.0 GATEWAY=192.168.56.2 DNS1=192.168.56.2 修改 grub[root@linux-node2~]# cat /etc/sysconfig/grub #编辑内核信息, 添加红色字段的 GRUB_TIMEOUT=5 GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=&quot;console&quot; GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rhgb net.ifnames=0 biosdevname=0 quiet&quot; GRUB_DISABLE_RECOVERY=&quot;true&quot; [root@linux-node2~]# grub2-mkconfig -o /boot/grub2/grub.cfg #生成启动菜单 Generatinggrub configuration file ... Foundlinux image: /boot/vmlinuz-3.10.0-229.el7.x86_64 Foundinitrd image: /boot/initramfs-3.10.0-229.el7.x86_64.img Foundlinux image: /boot/vmlinuz-0-rescue-1100f7e6c97d4afaad2e396403ba7f61 Foundinitrd image: /boot/initramfs-0-rescue-1100f7e6c97d4afaad2e396403ba7f61.img Done 也可以在开机启动加载安装系统界面设置。 验证是否修改成功[root@linux-node2~]# reboot #必须重启系统生效 [root@linux-node2~]# yum install net-tools #默认 centos7 不支持 ifconfig 需要看装 net-tools 包 [root@linux-node2~]# ifconfig eth0 #在次查看网卡信息 eth0:flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.56.12 netmask 255.255.255.0 broadcast 192.168.56.255 inet6 fe80::20c:29ff:fe5c:7bb1 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:5c:7b:b1 txqueuelen 1000 (Ethernet) RX packets 152 bytes 14503 (14.1 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 98 bytes 14402 (14.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 设置主机名解析[root@linux-node1 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.56.11 linux-node1 linux-node1.example.com 192.168.56.12 linux-node2 linux-node2.example.com centos 7 修改主机名的方法 hostnamectl 命令 在 7 版本中，hostname 有三种形式 静态 (Static host name) 动态 (Transient/dynamic host name) 别名(Pretty host name) 查询主机名 hostnamectl 或 hostctl status 查询主机名 hostnamectl status [--static|--transient|--pretty] 修改 hostname hostnamectl set-hostname servername [--static|--transient|--pretty] 删除 hostname hostnamectl set-hostname &quot;&quot; hostnamectl set-hostname &quot;&quot; --static hostnamectl set-hostname &quot;&quot; --pretty 修改配置文件 hostname name vim /etc/hostname 通过 nmtui 修改，之后重启 hostnamed systemctl restart systemd-hostnamed 通过 nmcui 修改，之后重启 hostnamed nmcli general hostname servername systemctl restart systemd-hostnamed 安装 EPEL 仓库和常用命令[root@linux-node1 ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm [root@linux-node1 ~]# yum install -y net-tools vim lrzsz tree screen lsof tcpdump 关闭 NetworkManager 和防火墙[root@linux-node1 ~]# systemctl stop firewalld #关闭防火墙 [root@linux-node1 ~]# systemctl disable firewalld #设置开机不启动 [root@linux-node1 ~]# systemctl stop NetworkManager 关闭 SELinux[root@linux-node1 ~]# vim /etc/sysconfig/selinux SELINUX=disabled #修改为 disabled 检查结果如下 [root@linux-node1 ~]# getsebool getsebool: SELinux is disabled 更新系统并重启[root@linux-node1 ~]# yum update -y &amp;&amp; reboot centos7 设置开机脚本 新建开机脚本vim /root/Dropbox/save/bootstartscript.sh # 添加开机启动脚本 #开机启动 dropbox dropbox start -d 添加开机脚本到启动文件vim /etc/rc.d/rc.local # 开机启动脚本 /bin/sh /root/Dropbox/save/bootstartscript.sh 设置启动脚本生效 chmod +x /etc/rc.d/rc.local]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos 7/6 内核版本由 3.10.0 升级至 4.12.4 方法]]></title>
    <url>%2F2015%2F01%2F21%2FCentos7%E5%86%85%E6%A0%B8%E7%94%B13.10%E5%8D%87%E7%BA%A7%E8%87%B34.12%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[【写在前面】公司打算上 Docker 服务，目前需要安装运行环境，Docker 新的功能除了需要 Centos 7 系统之外，内核的版本高低也决定着使用的效果，所以在此记录下系统内核版本升级过程。注：对于线上环境的内核版本还需要根据实际情况谨慎选择，越新的版本未来可能遇到的问题越多，此文只是记录升级方法而已。 【文章内容】关于内核版本的定义： 版本性质：主分支 ml(mainline)，稳定版(stable)，长期维护版 lt(longterm) 版本命名格式为 “A.B.C”： 数字 A 是内核版本号 ：版本号只有在代码和内核的概念有重大改变的时候才会改变，历史上有两次变化： 第一次是 1994 年的 1.0 版，第二次是 1996 年的 2.0 版，第三次是 2011 年的 3.0 版发布，但这次在内核的概念上并没有发生大的变化 数字 B 是内核主版本号：主版本号根据传统的奇 - 偶系统版本编号来分配：奇数为开发版，偶数为稳定版 数字 C 是内核次版本号：次版本号是无论在内核增加安全补丁、修复 bug、实现新的特性或者驱动时都会改变 一、查看那系统内核版本uname -r 3.10.0-514.el7.x86_64 cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) 二、升级内核Centos 6 和 Centos 7 的升级方法类似，只不过就是选择的 YUM 源或者 rpm 包不同罢了，下面主要是 Centos 7 的安装方法，中间也会有对于 Centos 6 升级的方法提示。 方法一： Centos 6 YUM 源：http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpmCentos 7 YUM 源：http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 升级内核需要先导入 elrepo 的 key，然后安装 elrepo 的 yum 源： rpm -import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 仓库启用后，你可以使用下面的命令列出可用的内核相关包，如下图： yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available 上图可以看出，长期维护版本 lt 为 4.4，最新主线稳定版 ml 为 4.12，我们需要安装最新的主线稳定内核，使用如下命令：(以后这台机器升级内核直接运行这句就可升级为最新稳定版) yum -y --enablerepo=elrepo-kernel install kernel-ml.x86_64 kernel-ml-devel.x86_64 方法二： 对于一些无法上网的服务器，或者需要安装指定版本内核的需求，我们可以把 kernel image 的 rpm 包下载下来安装，下载地址如下： 下载指定版本 kernel： http://rpm.pbone.net/index.php3?stat=3&amp;limit=1&amp;srodzaj=3&amp;dl=40&amp;search=kernel 下载指定版本 kernel-devel：http://rpm.pbone.net/index.php3?stat=3&amp;limit=1&amp;srodzaj=3&amp;dl=40&amp;search=kernel-devel 官方 Centos 6: http://elrepo.org/linux/kernel/el6/x86_64/RPMS/ 官方 Centos 7: http://elrepo.org/linux/kernel/el7/x86_64/RPMS/ 将 rpm 包下载上传到服务器上，使用下面的命令安装即可： yum -y install kernel-ml-devel-4.12.4-1.el7.elrepo.x86_64.rpm yum -y install kernel-ml-4.12.4-1.el7.elrepo.x86_64.rpm 方法三： 还可以通过源码包编译安装，这种方式可定制性强，但也比较复杂，有需要的可自行查找资料安装，下面只给出各系统版本内核源码包的下载地址：https://www.kernel.org/pub/linux/kernel/ 三、修改 grub 中默认的内核版本 内核升级完毕后，目前内核还是默认的版本，如果此时直接执行 reboot 命令，重启后使用的内核版本还是默认的 3.10，不会使用新的 4.12.4，首先，我们可以通过命令查看默认启动顺序： awk -F\&apos; &apos;$1==&quot;menuentry &quot; {print $2}&apos; /etc/grub2.cfg CentOS Linux (4.12.4-1.el7.elrepo.x86_64) 7 (Core) CentOS Linux (3.10.0-514.el7.x86_64) 7 (Core) CentOS Linux (0-rescue-a43cc2091b4557f1fd10a52ccffa5db2) 7 (Core) 由上面可以看出新内核 (4.12.4) 目前位置在 0，原来的内核 (3.10.0) 目前位置在 1，所以如果想生效最新的内核，还需要我们修改内核的启动顺序为 0： vim /etc/default/grub 注：Centos 6 更改的文件相同，使用命令确定新内核位置后，然后将参数 default 更改为 0 即可。 接着运行 grub2-mkconfig 命令来重新创建内核配置，如下： grub2-mkconfig -o /boot/grub2/grub.cfg 四、重启系统并查看系统内核reboot 系统启动完毕后，可以通过命令查看系统的内核版本，如下： uname -r 4.12.4-1.el7.elrepo.x86_64 到此，Centos 7 内核升级完毕。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT 主题添加点击爱心效果]]></title>
    <url>%2F2015%2F01%2F20%2FHexo%20NexT%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E7%82%B9%E5%87%BB%E7%88%B1%E5%BF%83%E6%95%88%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[给 NexT 主题内添加页面点击出现爱心的效果 创建 js 文件 在/themes/next/source/js/src下新建文件 clicklove.js，接着把该链接下的代码拷贝粘贴到clicklove.js 文件中。代码如下： !function(e,t,a){function n(){c(&quot;.heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: &apos;&apos;;width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}&quot;),o(),r()}function r(){for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText=&quot;left:&quot;+d[e].x+&quot;px;top:&quot;+d[e].y+&quot;px;opacity:&quot;+d[e].alpha+&quot;;transform:scale(&quot;+d[e].scale+&quot;,&quot;+d[e].scale+&quot;) rotate(45deg);background:&quot;+d[e].color+&quot;;z-index:99999&quot;);requestAnimationFrame(r)}function o(){var t=&quot;function&quot;==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e){t&amp;&amp;t(),i(e)}}function i(e){var a=t.createElement(&quot;div&quot;);a.className=&quot;heart&quot;,d.push({el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()}),t.body.appendChild(a)}function c(e){var a=t.createElement(&quot;style&quot;);a.type=&quot;text/css&quot;;try{a.appendChild(t.createTextNode(e))}catch(t){a.styleSheet.cssText=e}t.getElementsByTagName(&quot;head&quot;)[0].appendChild(a)}function s(){return&quot;rgb(&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;,&quot;+~~(255*Math.random())+&quot;)&quot;}var d=[];e.requestAnimationFrame=function(){return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e){setTimeout(e,1e3/60)}}(),n()}(window,document); 修改_layout.swig在 \themes\next\layout\_layout.swig 文件末尾添加： &lt;!-- 页面点击小红心 --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/clicklove.js&quot;&gt;&lt;/script&gt;]]></content>
      <categories>
        <category>Hexo Next</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何整理个人资料]]></title>
    <url>%2F2015%2F01%2F20%2F%E5%A6%82%E4%BD%95%E6%95%B4%E7%90%86%E4%B8%AA%E4%BA%BA%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[序言 在现如今信息爆炸的时代，资料整理的方法显得越来越重要。好的资料整理方法可以让收集的资料发挥出它应有的价值，否则便和没有收集无异。 在平时工作学习中，看到好的技术文档或文章忍不住把它放到收藏夹或使用印象笔记类似的工具裁剪到笔记里，想着日后细细品读。可大多数是没有日后的，这便造成了收集的资料越来越多，越来越混乱，有时候还整理下，但随着数量的增多，发现整理这些东西也是需要很大的时间成本的。这些资料没有发挥其应用的价值，但还舍不得删掉。 之前一直想整理自己的知识体系，想着形成自己的一个知识库，可以随时翻阅。当需要用到哪方便的知识时，可以通过翻阅很快的回忆起来，立即上手。近几年有写博客的习惯，把一些读书笔记和技术的使用过程记录了下来，发挥了些知识库的作用。但总感觉不是那么完美，最近查了下资料，看了些有关资料和个人知识系统整理的文章，有些想法，梳理下加深印象。 整体流程 整个过程应该是这样的： 资料的收集 在现如今网络如此遍历，资料的获取已经不成问题。而如何有效的获取，成为关键。即如何在海一样的信息中，找到我们需要的。现如今我的资料收集方法如下：•搜索引擎 通过搜索引擎关键字，找到自己需要的资料。关键字很重要，必要的时候可以直接使用英文搜索。•微信公众号 通过平时碎片化的阅读，可收集到一些自己认为有价值的文章。•各技术社区 现如今国内各技术社区活跃，文章水平残次不齐。推荐先根据标题略读，发现好的文章后再精度。我们会发现一些高质量文章的产出作者，我们可以订阅他们，之后可重点关注他们的文章。 整理分类 根据我自己的资料，大致分如下几种：•新技术的文档：各种框架文档•技术学习文章：微信公众号文章、各技术社区文章•技术问题：stackoverflow/ 技术问题解决记录•大牛博客•其他工具性网址资料•产出的联系或功能代码 针对以上资料，该如何整理呢？ 工欲善其事必先利其器，整理以上众多资料，整理方法及使用工具如下：•xmind 构建自己的知识体系脑图，作为整个知识库的索引。•evernote 主要存储技术文章和不能公开的自己产出的文档笔记。可按语言和功能所属划分类别，再为文章打好 tag 便于检索。建立临时笔记本暂存未读完的或不知归类的文章，待后续阅读整理。•bookmarks 主要存储技术文档链接、牛人博客地址、工具性网址。同样分好类别，便于检索。•百度云盘 存储开源 pdf 书籍，方便各设备同步。•github 存储自己的周边项目。•博客 产出自己的想法和收获。 消化，产出价值 以上资源分类保存好后，便是消化产出价值了。 第一，在此阶段重要的还是整理，通过阅读我们知道了每篇文章的价值，是否需要留存待日后查询。 原则如下： •可以在网络上轻易找到的，直接删除 •过期的资料直接删除 第二，除了平时碎片化时间的阅读，还需要沉下心来花大块的时间，系统的来学习某项技术。 如何高效的学习消化，日后再整理篇，本篇暂不展开。 通过以上各流程方法，便构建了自己的知识库。完成了以下目标：•梳理自己的知识图谱•通过知识库，可以方便的回忆起某特定技术使用方法。•形成自己的 QA•记录下自己学习的周边项目，作为工作参考 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考 如何有效的进行资料整理？ 信息爆炸的时代，如何静心学习？]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 文件的常用编写语法]]></title>
    <url>%2F2015%2F01%2F19%2Fmarkdown%E5%B8%B8%E7%94%A8%E7%BC%96%E5%86%99%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[序言:很久没有写博客了，感觉只要是不写博客，人就很变得很懒，学的知识点感觉还是记不住，渐渐地让我明白，看的越多，懂的越少（你这话不是有毛病吗？应该是看的越多，懂的越多才对），此话怎讲，当你在茫茫的前端知识库里面东看看，西看看的时候，很快就被海量的知识给淹没了，根本就不知道哪些是对的，哪些是错的，感觉好像这个也懂了，那个也懂了，但是真正写起来，脑子又一片空白，又好像什么都不懂，这种状态时有发生，这就叫不懂装懂，最根本的原因就是看的太多，写的太少，所以为了改掉这样毛病，把被动学习变成主动学习，接下来的日子，多写写，即使是写一些学习工作中遇到的坑也是好的，没事翻出来看看，还可以加深印象，好了，废话到处！ 起因：因为现在的前端基本上都用上了前端构建工具，那就难免要写一些 readme 等等的说明性文件，但是这样的文件一般都是.md 的文件，编写的语法自然跟其他格式的文件有所区别，置于为什么要用这种格式的文件，不要问我，我也不知道，大家都这么用，跟着用就对了，如果有大神知道的，不妨告知小弟，本文也是我学习写 markdown 文件的一个笔记吧，仅供参考！ 正文：1、标题的几种写法：第一种： 前面带 #号，后面带文字，分别表示 h1-h6, 上图可以看出，只到 h6，而且 h1 下面会有一条横线，注意，# 号后面有空格 第二种： 这种方式好像只能表示一级和二级标题，而且 = 和 - 的数量没有限制，只要大于一个就行 第三种： 这里的标题支持 h1-h6，为了减少篇幅，我就偷个懒，只写前面二个，这个比较好理解，相当于标签闭合，注意，标题与 #号要有空格 那既然 3 种都可以使用，可不可以混合使用呢？我试了一下，是可以的，但是为了让页面标签的统一性，不建议混合使用，推荐使用第一种，比较简洁，全面 为了搞清楚原理，我特意在网上搜一下在线编写 markdown 的工具，发现实际上是把这些标签最后转化为 html 标签，如图： 在线地址请看这里： http://tool.oschina.net/markdown/ （只是想看看背后的转换原理，没有广告之嫌） 2、列表 我们都知道，列表分为有序列表和无序列表，下面直接展示 2 种列表的写法： 可以看到，无序列表可以用 ， + ， — 来创建，用在线编辑器看，实际上是转换成了 ul&gt;li ，所以使用哪个都可以，推荐使用 吧 有序列表就相对简单一点，只有这一种方式，注意，数字后面的点只能是英文的点，特别注意，有序列表的序号是根据第一行列表的数字顺序来的，比如说： 第一组本来是 3 2 1 倒序，但是现实 3 4 5 ，后面一组 序号是乱的， 但是还是显示 3 4 5 ，这点必须注意了 3、区块引用 比如说，你想对某个部分做的内容做一些说明或者引用某某的话等，可以用这个语句 无序列表下方的便是引用，可以有多种用途，看你的需求了，用法就是在语句前面加一个 &gt; ，注意是英文的那个右尖括号，注意空格 引用因为是一个区块，理论上是应该什么内容都可以放，比如说：标题，列表，引用等等，看看下图： 将上面的代码稍微改一下，全部加上引用标签，就变成了一个大的引用，还有引用里面还有引用，那引用嵌套引用还没有别的写法呢？ 上图可以看出，想要在上一次引用中嵌套一层引用，只需多加一个 &gt;，理论上可以无限嵌套，我就不整那么多了，注意：多层嵌套的 &gt; 是不需要连续在一起的，只要在一行就可以了，中间允许有空格，但是为了好看，还是把排版搞好吧 4、华丽的分割线 分割线可以由 * - _（星号，减号，底线）这 3 个符号的至少 3 个符号表示，注意至少要 3 个，且不需要连续，有空格也可以 应该看得懂吧，但是为了代码的排版好看，你们自己定规则吧，前面有用到星号，建议用减号 5、链接 支持 2 种链接方式：行内式和参数式，不管是哪一种，链接文字都是用 [方括号] 来标记。 上图可知，行内式的链接格式是：链接的文字放在 [] 中，链接地址放在随后的（）中，举一反三，经常出现的列表链接就应该这样写： 链接还可以带 title 属性，好像也只能带 title，带不了其他属性，注意，是链接地址后面空一格，然后用引号引起来 这是行内式的写法，参数式的怎么写： 这就好理解了，就是把链接当成参数，适合多出使用相同链接的场景，注意参数的对应关系，参数定义时，这 3 种写法都可以： 还支持这种写法，如果你不想混淆的话： 其实还有一种隐式链接的写法，但是我觉得那种写法不直观，所以就不写了，经常用的一般就上面 2 种，如果你想了解隐式链接，可以看我文章最后放出的参考地址 6、图片 图片也有 2 种方式：行内式和参数式， 用法跟链接的基本一样，唯一的不同就是，图片前面要写一个！（这是必须的），没什么好说的 7、代码框 这个就比较重要了，很多时候都需要展示出一些代码 如果代码量比较少，只有单行的话，可以用单反引号包起来，如下： 要是多行这个就不行了，多行可以用这个： 多行用三个反引号，如果要写注释，可以在反引号后面写 8、表格 这个写的有点麻烦，注意看 从这 3 种不同写法看，表格的格式不一定要对的非常起，但是为了好看，对齐肯定是最好的，第一种的分割线后面的冒号表示对齐方式，写在左边表示左对齐，右边为右对齐，两边都写表示居中，还是有点意思的，不过现实出来的结果是，表格外面并没有线框包起来，不知道别人的怎么弄的 9、强调 一个星号或者是一个下划线包起来，会转换为 倾斜，如果是 2 个，会转换为 加粗 10、转义 就不一一列举了，基本上跟 js 转义是一样的 11、删除线 常用的基本上就这些了，如果还有一些常用的，可以跟我留言，我补充上去，我觉得图文并茂才是高效学习的正确姿势，但愿为你的学习带来帮助！ 以上整理主要参照下面的文档，如涉及侵权请联系本人，进行删除。 参考文献： Markdown 语法说明 (简体中文版) 认识与入门 Markdown]]></content>
      <categories>
        <category>技术工具</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
